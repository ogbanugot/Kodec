{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SOM_STL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ogbanugot/Kodec/blob/master/SOM_STL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ZYL609BU7UH6",
        "colab_type": "code",
        "outputId": "e630370b-8b4d-4415-a46f-4ffb9d53405e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131322 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zputc_nv7VBv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RtliDu7x7YU7",
        "colab_type": "code",
        "outputId": "2ada2d26-a468-4d84-b919-b88e78d67f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tK-5JivlsA8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cb75c266-263a-492e-e1ff-efdcaa5c0efb"
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2qcBnVuwsFA_",
        "colab_type": "code",
        "outputId": "d179fdc5-f04c-44ab-bbed-bbc1b549aca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "\n",
        "import keras.backend as K\n",
        "from keras import callbacks\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense, Input\n",
        "from keras.initializers import VarianceScaling\n",
        "from keras.engine.topology import Layer, InputSpec\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from drive.minisom.minisom import MiniSom\n",
        "from sklearn.metrics import accuracy_score, normalized_mutual_info_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MI1Rp06evHFo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_stl(data_path='./data/stl'):\n",
        "    # get labels\n",
        "    y1 = np.fromfile(data_path + '/train_y.bin', dtype=np.uint8) - 1\n",
        "    y2 = np.fromfile(data_path + '/test_y.bin', dtype=np.uint8) - 1\n",
        "    y = np.concatenate((y1, y2))\n",
        "    \n",
        "    # get data\n",
        "    x1 = np.fromfile(data_path + '/train_X.bin', dtype=np.uint8)\n",
        "    x1 = x1.reshape((int(x1.size/3/96/96), 3, 96, 96)).transpose((0, 3, 2, 1))\n",
        "    x2 = np.fromfile(data_path + '/test_X.bin', dtype=np.uint8)\n",
        "    x2 = x2.reshape((int(x2.size/3/96/96), 3, 96, 96)).transpose((0, 3, 2, 1))\n",
        "    x = np.concatenate((x1, x2)).astype(float)\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iedmO22gtsVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from drive.minisom.datasets import load_stl\n",
        "#, extract_vgg16_features\n",
        "\n",
        "x, y = load_stl(data_path='drive/minisom/data/stl')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z6f_dkmEiT-Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1 = x[0:3250, :]\n",
        "x2 = x[3250:6500, :]\n",
        "x3 = x[6500:9750, :]\n",
        "x4 = x[9750:13000, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eeYkMlutk__v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04d677dd-ac4b-437d-ca61-b8b667569e2e"
      },
      "cell_type": "code",
      "source": [
        "x4.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3250, 96, 96, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "aFoCK4xEftDK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_vgg16_features(x):\n",
        "    from keras.preprocessing.image import img_to_array, array_to_img\n",
        "    from keras.applications.vgg16 import preprocess_input, VGG16\n",
        "    from keras.models import Model\n",
        "\n",
        "    # im_h = x.shape[1]\n",
        "    im_h = 224\n",
        "    model = VGG16(include_top=True, weights='imagenet', input_shape=(im_h, im_h, 3))\n",
        "    feature_model = Model(model.input, model.get_layer('fc1').output)\n",
        "    print('extracting features...')\n",
        "    x = preprocess_input(x)  # data - 127. #data/255.#\n",
        "    features = feature_model.predict(x)\n",
        "    print('Features shape = ', features.shape)\n",
        "    \n",
        "    # scale to [0,1]\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    features = MinMaxScaler().fit_transform(features)\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8oHwiJ-0e1wq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "bf98d049-964a-4910-876e-3b3af3b2e28b"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from keras import backend as K\n",
        "# im_h = x.shape[1]\n",
        "im_h = 224\n",
        "x_array = []\n",
        "for im in x1:\n",
        "  image  = array_to_img(im, scale=False).resize((im_h, im_h))\n",
        "  image = img_to_array(image)\n",
        "  x_array.append(image)\n",
        "\n",
        "x1_array = np.asarray(x_array)\n",
        "x1 = extract_vgg16_features(x1_array)\n",
        "K.clear_session()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "extracting features...\n",
            "Features shape =  (3250, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tWu99ffUr6OO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FSrw73_mlzJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "106a8fe8-d15c-4222-e7bd-c5e71fd73058"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "# im_h = x.shape[1]\n",
        "im_h = 224\n",
        "x_array = []\n",
        "for im in x2:\n",
        "  image  = array_to_img(im, scale=False).resize((im_h, im_h))\n",
        "  image = img_to_array(image)\n",
        "  x_array.append(image)\n",
        "  \n",
        "x2_array = np.asarray(x_array)\n",
        "x2 = extract_vgg16_features(x2_array)\n",
        "K.clear_session()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "extracting features...\n",
            "Features shape =  (3250, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wZrRsGDlqOct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "# im_h = x.shape[1]\n",
        "im_h = 224\n",
        "x_array = []\n",
        "for im in x3:\n",
        "  image  = array_to_img(im, scale=False).resize((im_h, im_h))\n",
        "  image = img_to_array(image)\n",
        "  x_array.append(image)\n",
        "  \n",
        "x3_array = np.asarray(x_array)\n",
        "x3 = extract_vgg16_features(x3_array)\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kgGCONuErb_s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "# im_h = x.shape[1]\n",
        "im_h = 224\n",
        "x_array = []\n",
        "for im in x4:\n",
        "  image  = array_to_img(im, scale=False).resize((im_h, im_h))\n",
        "  image = img_to_array(image)\n",
        "  x_array.append(image)\n",
        "  \n",
        "x4_array = np.asarray(x_array)\n",
        "x4 = extract_vgg16_features(x4_array)\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8SIpW-U4e2q3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_x, val_x, train_y, val_y = train_test_split(x, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IGvm6GdRvOHl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training the SOM\n",
        "som = MiniSom(x = 30, y = 30, input_len = 2000, sigma = 4, learning_rate = 0.5, neighborhood_function='triangle')\n",
        "som.pca_weights_init(train_x)\n",
        "som.train_random(data = train_x, num_iteration = 5000)\n",
        "\n",
        "err = som.quantization_error(train_x)\n",
        "print(err)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qO9EzpXjKSF-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "map_dim = 30\n",
        "plt.figure(figsize=(14, 14))\n",
        "for x, t in zip(train_x, train_y):\n",
        "    winnin_position = som.winner(x)\n",
        "    plt.text(winnin_position[0], \n",
        "             winnin_position[1]+np.random.rand()*.9, \n",
        "             t,\n",
        "             color=plt.cm.rainbow(t / 4.))\n",
        "\n",
        "plt.xticks(range(map_dim))\n",
        "plt.yticks(range(map_dim))\n",
        "plt.grid()\n",
        "plt.xlim([0, map_dim])\n",
        "plt.ylim([0, map_dim])\n",
        "plt.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "san0KvR1mZN5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualizing the training results\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "wmap = {}\n",
        "im = 0\n",
        "for x, t in zip(train_x, train_y):  # scatterplot\n",
        "    w = som.winner(x)\n",
        "    wmap[w] = im\n",
        "    plt. text(w[0]+.5,  w[1]+.5,  str(t),\n",
        "              color=plt.cm.rainbow(t / 10.), fontdict={'weight': 'bold',  'size': 11})\n",
        "    im = im + 1\n",
        "plt.axis([0, som.get_weights().shape[0], 0,  som.get_weights().shape[1]])\n",
        "plt.savefig('drive/minisom/som_reuters.png')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WcMhNykYmcJ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get test mappings \n",
        "mappings = som.win_map(val_x)\n",
        "numbers = mappings[(8,1)]\n",
        "numbers = numbers[0]\n",
        "#plot number\n",
        "two_d = (np.reshape(numbers, (28, 28))).astype(np.uint8)\n",
        "plt.imshow(two_d, interpolation='nearest')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vBO4LOAxm_PD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualizing the test results\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "wmap = {}\n",
        "im = 0\n",
        "for x, t in zip(val_x, val_y):  # scatterplot\n",
        "    w = som.winner(x)\n",
        "    wmap[w] = im\n",
        "    plt. text(w[0]+.5,  w[1]+.5,  str(t),\n",
        "              color=plt.cm.rainbow(t / 10.), fontdict={'weight': 'bold',  'size': 11})\n",
        "    im = im + 1\n",
        "plt.axis([0, som.get_weights().shape[0], 0,  som.get_weights().shape[1]])\n",
        "plt.savefig('som_digts.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGuTvazUOGWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(wmap[(2,2)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1XhXbNWOmfUC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Getting Labels for clusters on test set\n",
        "winlabel = {}\n",
        "for x, t in zip(val_x, val_y):  \n",
        "    w = som.winner(x)\n",
        "    winlabel[w] = t\n",
        "    \n",
        "#prediction on the test set\n",
        "pred  = []\n",
        "for x in val_x:    \n",
        "    wt = som.winner(x)\n",
        "    number = winlabel[wt]\n",
        "    pred.append(number)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4EFeILekO4H-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(normalized_mutual_info_score(val_y, pred))\n",
        "print(accuracy_score(val_y, pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yLfqLo2x9tIK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# saving the some in the file som.p\n",
        "with open('drive/minisom/som_reuters.p', 'wb') as outfile:\n",
        "    pickle.dump(som, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mBhdtqXw-ESI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#load some here\n",
        "with open('drive/minisom/som_reuters.p', 'rb') as infile:\n",
        "    som = pickle.load(infile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddXd0-CHA8M1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now instead of directly applying SOM on the problem, \n",
        "# we will first use an autoencoder to decrease the dimensionality of the data and extract useful information. \n",
        "# This will then pass on the information to the SOM algorithm.\n",
        "\n",
        "\n",
        "# this is our input placeholder\n",
        "input_img = Input(shape=(2000,))\n",
        "\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(500, activation='relu')(input_img)\n",
        "encoded = Dense(500, activation='relu')(encoded)\n",
        "encoded = Dense(2000, activation='relu')(encoded)\n",
        "encoded = Dense(10, activation='sigmoid')(encoded)\n",
        "\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(2000, activation='relu')(encoded)\n",
        "decoded = Dense(500, activation='relu')(decoded)\n",
        "decoded = Dense(500, activation='relu')(decoded)\n",
        "decoded = Dense(2000)(decoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xN8PRuE9BOw_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XbpglWMUBU1p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  this model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SNuzme7YBdtX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train autoencoder\n",
        "autoencoder.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TBDMTJWER_Gb",
        "colab_type": "code",
        "outputId": "a27f6f26-68a5-4f78-8060-b083b971366f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18042
        }
      },
      "cell_type": "code",
      "source": [
        "train_history = autoencoder.fit(train_x, train_x, epochs=1000, batch_size=2048, validation_data=(val_x, val_x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/500\n",
            "8000/8000 [==============================] - 3s 425us/step - loss: 0.9939 - val_loss: 0.9766\n",
            "Epoch 2/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.9671 - val_loss: 0.9574\n",
            "Epoch 3/500\n",
            "8000/8000 [==============================] - 0s 62us/step - loss: 0.9566 - val_loss: 0.9548\n",
            "Epoch 4/500\n",
            "8000/8000 [==============================] - 0s 62us/step - loss: 0.9540 - val_loss: 0.9520\n",
            "Epoch 5/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.9513 - val_loss: 0.9496\n",
            "Epoch 6/500\n",
            "8000/8000 [==============================] - 1s 63us/step - loss: 0.9490 - val_loss: 0.9479\n",
            "Epoch 7/500\n",
            "8000/8000 [==============================] - 1s 64us/step - loss: 0.9476 - val_loss: 0.9472\n",
            "Epoch 8/500\n",
            "8000/8000 [==============================] - 0s 62us/step - loss: 0.9469 - val_loss: 0.9484\n",
            "Epoch 9/500\n",
            "8000/8000 [==============================] - 1s 63us/step - loss: 0.9478 - val_loss: 0.9465\n",
            "Epoch 10/500\n",
            "8000/8000 [==============================] - 1s 64us/step - loss: 0.9462 - val_loss: 0.9464\n",
            "Epoch 11/500\n",
            "8000/8000 [==============================] - 1s 63us/step - loss: 0.9454 - val_loss: 0.9445\n",
            "Epoch 12/500\n",
            "8000/8000 [==============================] - 1s 64us/step - loss: 0.9439 - val_loss: 0.9436\n",
            "Epoch 13/500\n",
            "8000/8000 [==============================] - 0s 62us/step - loss: 0.9426 - val_loss: 0.9422\n",
            "Epoch 14/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.9414 - val_loss: 0.9412\n",
            "Epoch 15/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.9403 - val_loss: 0.9404\n",
            "Epoch 16/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.9392 - val_loss: 0.9393\n",
            "Epoch 17/500\n",
            "8000/8000 [==============================] - 0s 62us/step - loss: 0.9379 - val_loss: 0.9379\n",
            "Epoch 18/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.9362 - val_loss: 0.9360\n",
            "Epoch 19/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.9340 - val_loss: 0.9340\n",
            "Epoch 20/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.9320 - val_loss: 0.9320\n",
            "Epoch 21/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.9303 - val_loss: 0.9316\n",
            "Epoch 22/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.9293 - val_loss: 0.9295\n",
            "Epoch 23/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.9277 - val_loss: 0.9278\n",
            "Epoch 24/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.9260 - val_loss: 0.9261\n",
            "Epoch 25/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.9239 - val_loss: 0.9236\n",
            "Epoch 26/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.9209 - val_loss: 0.9204\n",
            "Epoch 27/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.9172 - val_loss: 0.9161\n",
            "Epoch 28/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.9128 - val_loss: 0.9128\n",
            "Epoch 29/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.9087 - val_loss: 0.9079\n",
            "Epoch 30/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.9048 - val_loss: 0.9055\n",
            "Epoch 31/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.9020 - val_loss: 0.9028\n",
            "Epoch 32/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8992 - val_loss: 0.9007\n",
            "Epoch 33/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8968 - val_loss: 0.8986\n",
            "Epoch 34/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8945 - val_loss: 0.8966\n",
            "Epoch 35/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8921 - val_loss: 0.8943\n",
            "Epoch 36/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8897 - val_loss: 0.8922\n",
            "Epoch 37/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8884 - val_loss: 0.8918\n",
            "Epoch 38/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8866 - val_loss: 0.8882\n",
            "Epoch 39/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8833 - val_loss: 0.8852\n",
            "Epoch 40/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8802 - val_loss: 0.8828\n",
            "Epoch 41/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.8772 - val_loss: 0.8801\n",
            "Epoch 42/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8742 - val_loss: 0.8771\n",
            "Epoch 43/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8713 - val_loss: 0.8755\n",
            "Epoch 44/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8686 - val_loss: 0.8720\n",
            "Epoch 45/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8658 - val_loss: 0.8695\n",
            "Epoch 46/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8626 - val_loss: 0.8672\n",
            "Epoch 47/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8596 - val_loss: 0.8645\n",
            "Epoch 48/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8566 - val_loss: 0.8621\n",
            "Epoch 49/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.8535 - val_loss: 0.8595\n",
            "Epoch 50/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8502 - val_loss: 0.8566\n",
            "Epoch 51/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8479 - val_loss: 0.8572\n",
            "Epoch 52/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8464 - val_loss: 0.8535\n",
            "Epoch 53/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8425 - val_loss: 0.8495\n",
            "Epoch 54/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8388 - val_loss: 0.8469\n",
            "Epoch 55/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8355 - val_loss: 0.8442\n",
            "Epoch 56/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8323 - val_loss: 0.8422\n",
            "Epoch 57/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8295 - val_loss: 0.8390\n",
            "Epoch 58/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8260 - val_loss: 0.8365\n",
            "Epoch 59/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8230 - val_loss: 0.8344\n",
            "Epoch 60/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8213 - val_loss: 0.8335\n",
            "Epoch 61/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8182 - val_loss: 0.8309\n",
            "Epoch 62/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8153 - val_loss: 0.8279\n",
            "Epoch 63/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8124 - val_loss: 0.8255\n",
            "Epoch 64/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8096 - val_loss: 0.8228\n",
            "Epoch 65/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8067 - val_loss: 0.8212\n",
            "Epoch 66/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.8044 - val_loss: 0.8191\n",
            "Epoch 67/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.8017 - val_loss: 0.8170\n",
            "Epoch 68/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7994 - val_loss: 0.8157\n",
            "Epoch 69/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7975 - val_loss: 0.8149\n",
            "Epoch 70/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7969 - val_loss: 0.8121\n",
            "Epoch 71/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7937 - val_loss: 0.8114\n",
            "Epoch 72/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.7914 - val_loss: 0.8095\n",
            "Epoch 73/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7895 - val_loss: 0.8075\n",
            "Epoch 74/500\n",
            "8000/8000 [==============================] - 0s 57us/step - loss: 0.7868 - val_loss: 0.8061\n",
            "Epoch 75/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7844 - val_loss: 0.8046\n",
            "Epoch 76/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7822 - val_loss: 0.8032\n",
            "Epoch 77/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7808 - val_loss: 0.8038\n",
            "Epoch 78/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7804 - val_loss: 0.8023\n",
            "Epoch 79/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7783 - val_loss: 0.8012\n",
            "Epoch 80/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7763 - val_loss: 0.7994\n",
            "Epoch 81/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7740 - val_loss: 0.7977\n",
            "Epoch 82/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.7716 - val_loss: 0.7961\n",
            "Epoch 83/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7694 - val_loss: 0.7951\n",
            "Epoch 84/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7676 - val_loss: 0.7942\n",
            "Epoch 85/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7662 - val_loss: 0.7932\n",
            "Epoch 86/500\n",
            "8000/8000 [==============================] - 0s 62us/step - loss: 0.7639 - val_loss: 0.7914\n",
            "Epoch 87/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7624 - val_loss: 0.7907\n",
            "Epoch 88/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7604 - val_loss: 0.7897\n",
            "Epoch 89/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7591 - val_loss: 0.7885\n",
            "Epoch 90/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7576 - val_loss: 0.7896\n",
            "Epoch 91/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7586 - val_loss: 0.7878\n",
            "Epoch 92/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7561 - val_loss: 0.7863\n",
            "Epoch 93/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7542 - val_loss: 0.7850\n",
            "Epoch 94/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7522 - val_loss: 0.7837\n",
            "Epoch 95/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7503 - val_loss: 0.7826\n",
            "Epoch 96/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7486 - val_loss: 0.7818\n",
            "Epoch 97/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7469 - val_loss: 0.7807\n",
            "Epoch 98/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7452 - val_loss: 0.7801\n",
            "Epoch 99/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7436 - val_loss: 0.7791\n",
            "Epoch 100/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.7431 - val_loss: 0.7795\n",
            "Epoch 101/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7421 - val_loss: 0.7780\n",
            "Epoch 102/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.7405 - val_loss: 0.7765\n",
            "Epoch 103/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7387 - val_loss: 0.7761\n",
            "Epoch 104/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7374 - val_loss: 0.7754\n",
            "Epoch 105/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7360 - val_loss: 0.7747\n",
            "Epoch 106/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7348 - val_loss: 0.7743\n",
            "Epoch 107/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7341 - val_loss: 0.7736\n",
            "Epoch 108/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7329 - val_loss: 0.7726\n",
            "Epoch 109/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7315 - val_loss: 0.7720\n",
            "Epoch 110/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7300 - val_loss: 0.7710\n",
            "Epoch 111/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7292 - val_loss: 0.7707\n",
            "Epoch 112/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7278 - val_loss: 0.7707\n",
            "Epoch 113/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7269 - val_loss: 0.7691\n",
            "Epoch 114/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7255 - val_loss: 0.7693\n",
            "Epoch 115/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7254 - val_loss: 0.7690\n",
            "Epoch 116/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7240 - val_loss: 0.7677\n",
            "Epoch 117/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.7229 - val_loss: 0.7671\n",
            "Epoch 118/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7217 - val_loss: 0.7669\n",
            "Epoch 119/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.7207 - val_loss: 0.7661\n",
            "Epoch 120/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7203 - val_loss: 0.7660\n",
            "Epoch 121/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.7187 - val_loss: 0.7652\n",
            "Epoch 122/500\n",
            "8000/8000 [==============================] - 0s 57us/step - loss: 0.7177 - val_loss: 0.7642\n",
            "Epoch 123/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.7164 - val_loss: 0.7639\n",
            "Epoch 124/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.7158 - val_loss: 0.7639\n",
            "Epoch 125/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.7156 - val_loss: 0.7627\n",
            "Epoch 126/500\n",
            "8000/8000 [==============================] - 0s 56us/step - loss: 0.7139 - val_loss: 0.7631\n",
            "Epoch 127/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.7132 - val_loss: 0.7623\n",
            "Epoch 128/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.7127 - val_loss: 0.7618\n",
            "Epoch 129/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7114 - val_loss: 0.7617\n",
            "Epoch 130/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.7104 - val_loss: 0.7608\n",
            "Epoch 131/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7095 - val_loss: 0.7600\n",
            "Epoch 132/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7083 - val_loss: 0.7599\n",
            "Epoch 133/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7077 - val_loss: 0.7599\n",
            "Epoch 134/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7080 - val_loss: 0.7594\n",
            "Epoch 135/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7066 - val_loss: 0.7598\n",
            "Epoch 136/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7064 - val_loss: 0.7593\n",
            "Epoch 137/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.7058 - val_loss: 0.7581\n",
            "Epoch 138/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7042 - val_loss: 0.7577\n",
            "Epoch 139/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7031 - val_loss: 0.7568\n",
            "Epoch 140/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7021 - val_loss: 0.7569\n",
            "Epoch 141/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7018 - val_loss: 0.7580\n",
            "Epoch 142/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.7020 - val_loss: 0.7563\n",
            "Epoch 143/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.7008 - val_loss: 0.7565\n",
            "Epoch 144/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6999 - val_loss: 0.7563\n",
            "Epoch 145/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6993 - val_loss: 0.7550\n",
            "Epoch 146/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6984 - val_loss: 0.7553\n",
            "Epoch 147/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6977 - val_loss: 0.7551\n",
            "Epoch 148/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6969 - val_loss: 0.7549\n",
            "Epoch 149/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6961 - val_loss: 0.7544\n",
            "Epoch 150/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6960 - val_loss: 0.7539\n",
            "Epoch 151/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6955 - val_loss: 0.7540\n",
            "Epoch 152/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6944 - val_loss: 0.7540\n",
            "Epoch 153/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6940 - val_loss: 0.7535\n",
            "Epoch 154/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6937 - val_loss: 0.7536\n",
            "Epoch 155/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6935 - val_loss: 0.7528\n",
            "Epoch 156/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6923 - val_loss: 0.7525\n",
            "Epoch 157/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6916 - val_loss: 0.7528\n",
            "Epoch 158/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6915 - val_loss: 0.7521\n",
            "Epoch 159/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6904 - val_loss: 0.7513\n",
            "Epoch 160/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6897 - val_loss: 0.7515\n",
            "Epoch 161/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6889 - val_loss: 0.7511\n",
            "Epoch 162/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6885 - val_loss: 0.7508\n",
            "Epoch 163/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6879 - val_loss: 0.7506\n",
            "Epoch 164/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6874 - val_loss: 0.7516\n",
            "Epoch 165/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.6877 - val_loss: 0.7509\n",
            "Epoch 166/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6864 - val_loss: 0.7497\n",
            "Epoch 167/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6863 - val_loss: 0.7504\n",
            "Epoch 168/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6853 - val_loss: 0.7498\n",
            "Epoch 169/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6851 - val_loss: 0.7501\n",
            "Epoch 170/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6844 - val_loss: 0.7491\n",
            "Epoch 171/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6837 - val_loss: 0.7494\n",
            "Epoch 172/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6830 - val_loss: 0.7487\n",
            "Epoch 173/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6823 - val_loss: 0.7484\n",
            "Epoch 174/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6818 - val_loss: 0.7481\n",
            "Epoch 175/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6817 - val_loss: 0.7483\n",
            "Epoch 176/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6814 - val_loss: 0.7489\n",
            "Epoch 177/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6808 - val_loss: 0.7478\n",
            "Epoch 178/500\n",
            "8000/8000 [==============================] - 0s 62us/step - loss: 0.6803 - val_loss: 0.7482\n",
            "Epoch 179/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6796 - val_loss: 0.7476\n",
            "Epoch 180/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6799 - val_loss: 0.7479\n",
            "Epoch 181/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6795 - val_loss: 0.7477\n",
            "Epoch 182/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.6789 - val_loss: 0.7471\n",
            "Epoch 183/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6785 - val_loss: 0.7464\n",
            "Epoch 184/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6778 - val_loss: 0.7467\n",
            "Epoch 185/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6771 - val_loss: 0.7475\n",
            "Epoch 186/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6769 - val_loss: 0.7461\n",
            "Epoch 187/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6764 - val_loss: 0.7461\n",
            "Epoch 188/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6755 - val_loss: 0.7457\n",
            "Epoch 189/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6752 - val_loss: 0.7466\n",
            "Epoch 190/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6752 - val_loss: 0.7461\n",
            "Epoch 191/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6746 - val_loss: 0.7463\n",
            "Epoch 192/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6752 - val_loss: 0.7472\n",
            "Epoch 193/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6748 - val_loss: 0.7454\n",
            "Epoch 194/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6735 - val_loss: 0.7456\n",
            "Epoch 195/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6732 - val_loss: 0.7446\n",
            "Epoch 196/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6725 - val_loss: 0.7445\n",
            "Epoch 197/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6719 - val_loss: 0.7445\n",
            "Epoch 198/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6714 - val_loss: 0.7443\n",
            "Epoch 199/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6707 - val_loss: 0.7441\n",
            "Epoch 200/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6704 - val_loss: 0.7437\n",
            "Epoch 201/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6701 - val_loss: 0.7443\n",
            "Epoch 202/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6697 - val_loss: 0.7439\n",
            "Epoch 203/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6698 - val_loss: 0.7449\n",
            "Epoch 204/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6697 - val_loss: 0.7431\n",
            "Epoch 205/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6688 - val_loss: 0.7434\n",
            "Epoch 206/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6684 - val_loss: 0.7432\n",
            "Epoch 207/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6677 - val_loss: 0.7431\n",
            "Epoch 208/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6675 - val_loss: 0.7427\n",
            "Epoch 209/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6671 - val_loss: 0.7431\n",
            "Epoch 210/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6671 - val_loss: 0.7426\n",
            "Epoch 211/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6668 - val_loss: 0.7436\n",
            "Epoch 212/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6674 - val_loss: 0.7429\n",
            "Epoch 213/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6675 - val_loss: 0.7425\n",
            "Epoch 214/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6664 - val_loss: 0.7430\n",
            "Epoch 215/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6657 - val_loss: 0.7422\n",
            "Epoch 216/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6651 - val_loss: 0.7424\n",
            "Epoch 217/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6648 - val_loss: 0.7416\n",
            "Epoch 218/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6647 - val_loss: 0.7420\n",
            "Epoch 219/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6642 - val_loss: 0.7420\n",
            "Epoch 220/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6637 - val_loss: 0.7416\n",
            "Epoch 221/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6632 - val_loss: 0.7418\n",
            "Epoch 222/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6629 - val_loss: 0.7410\n",
            "Epoch 223/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6625 - val_loss: 0.7419\n",
            "Epoch 224/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6624 - val_loss: 0.7411\n",
            "Epoch 225/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6621 - val_loss: 0.7423\n",
            "Epoch 226/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6622 - val_loss: 0.7420\n",
            "Epoch 227/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6620 - val_loss: 0.7415\n",
            "Epoch 228/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6611 - val_loss: 0.7409\n",
            "Epoch 229/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6607 - val_loss: 0.7408\n",
            "Epoch 230/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6609 - val_loss: 0.7413\n",
            "Epoch 231/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6601 - val_loss: 0.7408\n",
            "Epoch 232/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6600 - val_loss: 0.7403\n",
            "Epoch 233/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6597 - val_loss: 0.7407\n",
            "Epoch 234/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6598 - val_loss: 0.7405\n",
            "Epoch 235/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6593 - val_loss: 0.7404\n",
            "Epoch 236/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6586 - val_loss: 0.7406\n",
            "Epoch 237/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6582 - val_loss: 0.7400\n",
            "Epoch 238/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6585 - val_loss: 0.7404\n",
            "Epoch 239/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6588 - val_loss: 0.7403\n",
            "Epoch 240/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6583 - val_loss: 0.7402\n",
            "Epoch 241/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.6576 - val_loss: 0.7399\n",
            "Epoch 242/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6574 - val_loss: 0.7400\n",
            "Epoch 243/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6573 - val_loss: 0.7396\n",
            "Epoch 244/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6567 - val_loss: 0.7399\n",
            "Epoch 245/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6565 - val_loss: 0.7401\n",
            "Epoch 246/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6566 - val_loss: 0.7398\n",
            "Epoch 247/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6558 - val_loss: 0.7386\n",
            "Epoch 248/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6555 - val_loss: 0.7398\n",
            "Epoch 249/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6553 - val_loss: 0.7387\n",
            "Epoch 250/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6551 - val_loss: 0.7396\n",
            "Epoch 251/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6551 - val_loss: 0.7397\n",
            "Epoch 252/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6545 - val_loss: 0.7386\n",
            "Epoch 253/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6540 - val_loss: 0.7383\n",
            "Epoch 254/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6535 - val_loss: 0.7390\n",
            "Epoch 255/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6538 - val_loss: 0.7392\n",
            "Epoch 256/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6535 - val_loss: 0.7382\n",
            "Epoch 257/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6532 - val_loss: 0.7391\n",
            "Epoch 258/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6534 - val_loss: 0.7392\n",
            "Epoch 259/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6534 - val_loss: 0.7395\n",
            "Epoch 260/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6532 - val_loss: 0.7388\n",
            "Epoch 261/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6532 - val_loss: 0.7393\n",
            "Epoch 262/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6522 - val_loss: 0.7381\n",
            "Epoch 263/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6525 - val_loss: 0.7385\n",
            "Epoch 264/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6515 - val_loss: 0.7376\n",
            "Epoch 265/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6512 - val_loss: 0.7380\n",
            "Epoch 266/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6506 - val_loss: 0.7378\n",
            "Epoch 267/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6504 - val_loss: 0.7375\n",
            "Epoch 268/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6502 - val_loss: 0.7379\n",
            "Epoch 269/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.6501 - val_loss: 0.7383\n",
            "Epoch 270/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6502 - val_loss: 0.7383\n",
            "Epoch 271/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6502 - val_loss: 0.7373\n",
            "Epoch 272/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6499 - val_loss: 0.7382\n",
            "Epoch 273/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6498 - val_loss: 0.7378\n",
            "Epoch 274/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6492 - val_loss: 0.7378\n",
            "Epoch 275/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.6491 - val_loss: 0.7372\n",
            "Epoch 276/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6487 - val_loss: 0.7379\n",
            "Epoch 277/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6485 - val_loss: 0.7369\n",
            "Epoch 278/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6483 - val_loss: 0.7374\n",
            "Epoch 279/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6480 - val_loss: 0.7377\n",
            "Epoch 280/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6476 - val_loss: 0.7370\n",
            "Epoch 281/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6482 - val_loss: 0.7372\n",
            "Epoch 282/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6476 - val_loss: 0.7375\n",
            "Epoch 283/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6475 - val_loss: 0.7370\n",
            "Epoch 284/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6470 - val_loss: 0.7365\n",
            "Epoch 285/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6465 - val_loss: 0.7372\n",
            "Epoch 286/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6463 - val_loss: 0.7370\n",
            "Epoch 287/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6466 - val_loss: 0.7370\n",
            "Epoch 288/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6460 - val_loss: 0.7364\n",
            "Epoch 289/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6463 - val_loss: 0.7372\n",
            "Epoch 290/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6464 - val_loss: 0.7369\n",
            "Epoch 291/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6459 - val_loss: 0.7369\n",
            "Epoch 292/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6455 - val_loss: 0.7363\n",
            "Epoch 293/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6457 - val_loss: 0.7362\n",
            "Epoch 294/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6451 - val_loss: 0.7367\n",
            "Epoch 295/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6448 - val_loss: 0.7358\n",
            "Epoch 296/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6444 - val_loss: 0.7362\n",
            "Epoch 297/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6443 - val_loss: 0.7364\n",
            "Epoch 298/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6439 - val_loss: 0.7359\n",
            "Epoch 299/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6434 - val_loss: 0.7357\n",
            "Epoch 300/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6434 - val_loss: 0.7355\n",
            "Epoch 301/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6432 - val_loss: 0.7368\n",
            "Epoch 302/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6439 - val_loss: 0.7363\n",
            "Epoch 303/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6436 - val_loss: 0.7364\n",
            "Epoch 304/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6438 - val_loss: 0.7362\n",
            "Epoch 305/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6436 - val_loss: 0.7354\n",
            "Epoch 306/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.6432 - val_loss: 0.7360\n",
            "Epoch 307/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6428 - val_loss: 0.7364\n",
            "Epoch 308/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6426 - val_loss: 0.7354\n",
            "Epoch 309/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6422 - val_loss: 0.7354\n",
            "Epoch 310/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6422 - val_loss: 0.7352\n",
            "Epoch 311/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6414 - val_loss: 0.7358\n",
            "Epoch 312/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.6415 - val_loss: 0.7361\n",
            "Epoch 313/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6412 - val_loss: 0.7355\n",
            "Epoch 314/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6411 - val_loss: 0.7356\n",
            "Epoch 315/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6412 - val_loss: 0.7352\n",
            "Epoch 316/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6407 - val_loss: 0.7355\n",
            "Epoch 317/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6406 - val_loss: 0.7357\n",
            "Epoch 318/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6406 - val_loss: 0.7353\n",
            "Epoch 319/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6406 - val_loss: 0.7352\n",
            "Epoch 320/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6404 - val_loss: 0.7353\n",
            "Epoch 321/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6401 - val_loss: 0.7352\n",
            "Epoch 322/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6396 - val_loss: 0.7344\n",
            "Epoch 323/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6395 - val_loss: 0.7356\n",
            "Epoch 324/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6399 - val_loss: 0.7361\n",
            "Epoch 325/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6403 - val_loss: 0.7351\n",
            "Epoch 326/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6396 - val_loss: 0.7352\n",
            "Epoch 327/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6393 - val_loss: 0.7343\n",
            "Epoch 328/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6390 - val_loss: 0.7344\n",
            "Epoch 329/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6387 - val_loss: 0.7346\n",
            "Epoch 330/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6384 - val_loss: 0.7352\n",
            "Epoch 331/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6386 - val_loss: 0.7350\n",
            "Epoch 332/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6384 - val_loss: 0.7342\n",
            "Epoch 333/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6380 - val_loss: 0.7347\n",
            "Epoch 334/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.6380 - val_loss: 0.7349\n",
            "Epoch 335/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6376 - val_loss: 0.7341\n",
            "Epoch 336/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6373 - val_loss: 0.7345\n",
            "Epoch 337/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6374 - val_loss: 0.7340\n",
            "Epoch 338/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6371 - val_loss: 0.7337\n",
            "Epoch 339/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6371 - val_loss: 0.7341\n",
            "Epoch 340/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6366 - val_loss: 0.7340\n",
            "Epoch 341/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6365 - val_loss: 0.7342\n",
            "Epoch 342/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6366 - val_loss: 0.7349\n",
            "Epoch 343/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6366 - val_loss: 0.7346\n",
            "Epoch 344/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6363 - val_loss: 0.7343\n",
            "Epoch 345/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6359 - val_loss: 0.7338\n",
            "Epoch 346/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6359 - val_loss: 0.7342\n",
            "Epoch 347/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6362 - val_loss: 0.7340\n",
            "Epoch 348/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6359 - val_loss: 0.7340\n",
            "Epoch 349/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6361 - val_loss: 0.7348\n",
            "Epoch 350/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6355 - val_loss: 0.7336\n",
            "Epoch 351/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.6351 - val_loss: 0.7333\n",
            "Epoch 352/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6351 - val_loss: 0.7336\n",
            "Epoch 353/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6348 - val_loss: 0.7335\n",
            "Epoch 354/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6344 - val_loss: 0.7344\n",
            "Epoch 355/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6346 - val_loss: 0.7336\n",
            "Epoch 356/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6343 - val_loss: 0.7344\n",
            "Epoch 357/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6349 - val_loss: 0.7331\n",
            "Epoch 358/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6340 - val_loss: 0.7334\n",
            "Epoch 359/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6343 - val_loss: 0.7336\n",
            "Epoch 360/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6341 - val_loss: 0.7332\n",
            "Epoch 361/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6339 - val_loss: 0.7335\n",
            "Epoch 362/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6338 - val_loss: 0.7334\n",
            "Epoch 363/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6335 - val_loss: 0.7331\n",
            "Epoch 364/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6329 - val_loss: 0.7329\n",
            "Epoch 365/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6330 - val_loss: 0.7329\n",
            "Epoch 366/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6334 - val_loss: 0.7336\n",
            "Epoch 367/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6330 - val_loss: 0.7338\n",
            "Epoch 368/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6329 - val_loss: 0.7331\n",
            "Epoch 369/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6324 - val_loss: 0.7330\n",
            "Epoch 370/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.6326 - val_loss: 0.7330\n",
            "Epoch 371/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6323 - val_loss: 0.7332\n",
            "Epoch 372/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6327 - val_loss: 0.7337\n",
            "Epoch 373/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6325 - val_loss: 0.7332\n",
            "Epoch 374/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6328 - val_loss: 0.7330\n",
            "Epoch 375/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6324 - val_loss: 0.7338\n",
            "Epoch 376/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6324 - val_loss: 0.7329\n",
            "Epoch 377/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6321 - val_loss: 0.7327\n",
            "Epoch 378/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6316 - val_loss: 0.7336\n",
            "Epoch 379/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6313 - val_loss: 0.7322\n",
            "Epoch 380/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6313 - val_loss: 0.7330\n",
            "Epoch 381/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6312 - val_loss: 0.7328\n",
            "Epoch 382/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6314 - val_loss: 0.7326\n",
            "Epoch 383/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6310 - val_loss: 0.7330\n",
            "Epoch 384/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6309 - val_loss: 0.7329\n",
            "Epoch 385/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6310 - val_loss: 0.7324\n",
            "Epoch 386/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6304 - val_loss: 0.7336\n",
            "Epoch 387/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6304 - val_loss: 0.7318\n",
            "Epoch 388/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6302 - val_loss: 0.7330\n",
            "Epoch 389/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6303 - val_loss: 0.7322\n",
            "Epoch 390/500\n",
            "8000/8000 [==============================] - 0s 61us/step - loss: 0.6298 - val_loss: 0.7322\n",
            "Epoch 391/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6294 - val_loss: 0.7326\n",
            "Epoch 392/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6294 - val_loss: 0.7320\n",
            "Epoch 393/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6296 - val_loss: 0.7329\n",
            "Epoch 394/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6294 - val_loss: 0.7323\n",
            "Epoch 395/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6291 - val_loss: 0.7328\n",
            "Epoch 396/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6293 - val_loss: 0.7328\n",
            "Epoch 397/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6290 - val_loss: 0.7325\n",
            "Epoch 398/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6296 - val_loss: 0.7320\n",
            "Epoch 399/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6295 - val_loss: 0.7329\n",
            "Epoch 400/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6296 - val_loss: 0.7324\n",
            "Epoch 401/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6289 - val_loss: 0.7324\n",
            "Epoch 402/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6287 - val_loss: 0.7320\n",
            "Epoch 403/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6283 - val_loss: 0.7325\n",
            "Epoch 404/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6280 - val_loss: 0.7317\n",
            "Epoch 405/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6277 - val_loss: 0.7318\n",
            "Epoch 406/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6277 - val_loss: 0.7322\n",
            "Epoch 407/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6277 - val_loss: 0.7318\n",
            "Epoch 408/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6281 - val_loss: 0.7321\n",
            "Epoch 409/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6288 - val_loss: 0.7325\n",
            "Epoch 410/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6282 - val_loss: 0.7323\n",
            "Epoch 411/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6279 - val_loss: 0.7320\n",
            "Epoch 412/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6277 - val_loss: 0.7321\n",
            "Epoch 413/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6278 - val_loss: 0.7330\n",
            "Epoch 414/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6273 - val_loss: 0.7318\n",
            "Epoch 415/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6275 - val_loss: 0.7317\n",
            "Epoch 416/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6270 - val_loss: 0.7325\n",
            "Epoch 417/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6269 - val_loss: 0.7318\n",
            "Epoch 418/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6276 - val_loss: 0.7322\n",
            "Epoch 419/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6270 - val_loss: 0.7325\n",
            "Epoch 420/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6274 - val_loss: 0.7312\n",
            "Epoch 421/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6266 - val_loss: 0.7315\n",
            "Epoch 422/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6263 - val_loss: 0.7321\n",
            "Epoch 423/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6262 - val_loss: 0.7317\n",
            "Epoch 424/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6261 - val_loss: 0.7312\n",
            "Epoch 425/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6258 - val_loss: 0.7313\n",
            "Epoch 426/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6259 - val_loss: 0.7313\n",
            "Epoch 427/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6255 - val_loss: 0.7317\n",
            "Epoch 428/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6255 - val_loss: 0.7325\n",
            "Epoch 429/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6253 - val_loss: 0.7314\n",
            "Epoch 430/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6257 - val_loss: 0.7323\n",
            "Epoch 431/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6260 - val_loss: 0.7326\n",
            "Epoch 432/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6254 - val_loss: 0.7315\n",
            "Epoch 433/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6250 - val_loss: 0.7315\n",
            "Epoch 434/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6248 - val_loss: 0.7312\n",
            "Epoch 435/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6249 - val_loss: 0.7316\n",
            "Epoch 436/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6253 - val_loss: 0.7320\n",
            "Epoch 437/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6251 - val_loss: 0.7323\n",
            "Epoch 438/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6257 - val_loss: 0.7316\n",
            "Epoch 439/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6249 - val_loss: 0.7312\n",
            "Epoch 440/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6249 - val_loss: 0.7309\n",
            "Epoch 441/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6246 - val_loss: 0.7319\n",
            "Epoch 442/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6245 - val_loss: 0.7313\n",
            "Epoch 443/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6244 - val_loss: 0.7318\n",
            "Epoch 444/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6243 - val_loss: 0.7318\n",
            "Epoch 445/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6241 - val_loss: 0.7311\n",
            "Epoch 446/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6241 - val_loss: 0.7313\n",
            "Epoch 447/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6246 - val_loss: 0.7318\n",
            "Epoch 448/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6246 - val_loss: 0.7319\n",
            "Epoch 449/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6246 - val_loss: 0.7310\n",
            "Epoch 450/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6242 - val_loss: 0.7318\n",
            "Epoch 451/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6245 - val_loss: 0.7325\n",
            "Epoch 452/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6242 - val_loss: 0.7306\n",
            "Epoch 453/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6238 - val_loss: 0.7310\n",
            "Epoch 454/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6237 - val_loss: 0.7322\n",
            "Epoch 455/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6236 - val_loss: 0.7307\n",
            "Epoch 456/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6236 - val_loss: 0.7308\n",
            "Epoch 457/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6232 - val_loss: 0.7313\n",
            "Epoch 458/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6228 - val_loss: 0.7309\n",
            "Epoch 459/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6231 - val_loss: 0.7312\n",
            "Epoch 460/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6239 - val_loss: 0.7309\n",
            "Epoch 461/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6232 - val_loss: 0.7318\n",
            "Epoch 462/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6234 - val_loss: 0.7316\n",
            "Epoch 463/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6229 - val_loss: 0.7310\n",
            "Epoch 464/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6229 - val_loss: 0.7306\n",
            "Epoch 465/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6227 - val_loss: 0.7313\n",
            "Epoch 466/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6224 - val_loss: 0.7309\n",
            "Epoch 467/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6223 - val_loss: 0.7304\n",
            "Epoch 468/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6220 - val_loss: 0.7319\n",
            "Epoch 469/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6222 - val_loss: 0.7302\n",
            "Epoch 470/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6221 - val_loss: 0.7306\n",
            "Epoch 471/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6219 - val_loss: 0.7312\n",
            "Epoch 472/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6220 - val_loss: 0.7310\n",
            "Epoch 473/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6219 - val_loss: 0.7315\n",
            "Epoch 474/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6220 - val_loss: 0.7310\n",
            "Epoch 475/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6215 - val_loss: 0.7310\n",
            "Epoch 476/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6217 - val_loss: 0.7311\n",
            "Epoch 477/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6217 - val_loss: 0.7306\n",
            "Epoch 478/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6214 - val_loss: 0.7305\n",
            "Epoch 479/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6211 - val_loss: 0.7307\n",
            "Epoch 480/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6210 - val_loss: 0.7309\n",
            "Epoch 481/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6209 - val_loss: 0.7310\n",
            "Epoch 482/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6220 - val_loss: 0.7314\n",
            "Epoch 483/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6210 - val_loss: 0.7305\n",
            "Epoch 484/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6212 - val_loss: 0.7302\n",
            "Epoch 485/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6213 - val_loss: 0.7314\n",
            "Epoch 486/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6208 - val_loss: 0.7305\n",
            "Epoch 487/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6209 - val_loss: 0.7299\n",
            "Epoch 488/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6205 - val_loss: 0.7309\n",
            "Epoch 489/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6201 - val_loss: 0.7304\n",
            "Epoch 490/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6204 - val_loss: 0.7310\n",
            "Epoch 491/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6201 - val_loss: 0.7302\n",
            "Epoch 492/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6199 - val_loss: 0.7301\n",
            "Epoch 493/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6199 - val_loss: 0.7308\n",
            "Epoch 494/500\n",
            "8000/8000 [==============================] - 0s 58us/step - loss: 0.6198 - val_loss: 0.7302\n",
            "Epoch 495/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6197 - val_loss: 0.7301\n",
            "Epoch 496/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6196 - val_loss: 0.7302\n",
            "Epoch 497/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6195 - val_loss: 0.7302\n",
            "Epoch 498/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6192 - val_loss: 0.7297\n",
            "Epoch 499/500\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6192 - val_loss: 0.7303\n",
            "Epoch 500/500\n",
            "8000/8000 [==============================] - 0s 59us/step - loss: 0.6190 - val_loss: 0.7308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XnTd_4vjBgmm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_auto_train = encoder.predict(train_x)\n",
        "pred_auto = encoder.predict(val_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cN8XgXdl_N1a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training the SOM\n",
        "som = MiniSom(x = 30, y = 30, input_len = 10, sigma = 4, learning_rate = 0.5,neighborhood_function='triangle')\n",
        "som.pca_weights_init(pred_auto_train)\n",
        "som.train_random(data = pred_auto_train, num_iteration = 5000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8czjUtVlO-1W",
        "colab_type": "code",
        "outputId": "7747e139-3b60-48f0-bb7e-6dbaa572a5f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "err = som.quantization_error(pred_auto_train)\n",
        "print(err)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6083776092072567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4bkr8N_o_Thg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Getting Labels for clusters on test set\n",
        "winlabel = {}\n",
        "for x, t in zip(pred_auto, val_y):  \n",
        "    w = som.winner(x)\n",
        "    winlabel[w] = t\n",
        "    \n",
        "#prediction on the test set\n",
        "pred  = []\n",
        "for x in pred_auto:    \n",
        "    wt = som.winner(x)\n",
        "    number = winlabel[wt]\n",
        "    pred.append(number)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "loXTPpBy_Th1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(normalized_mutual_info_score(val_y, pred))\n",
        "print(accuracy_score(val_y, pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "625OO8BRSwAz",
        "colab_type": "code",
        "outputId": "ba40bf5b-f534-4621-823f-9b283a1bb193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "val_y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "FLp-YTwHClNI",
        "colab_type": "code",
        "outputId": "c7d7bea5-d179-4912-bb74-ec2f37b5c550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "cell_type": "code",
      "source": [
        "# Visualizing the test results\n",
        "cat_to_cid = {0:'CCAT', 1:'GCAT', 2:'MCAT', 3:'ECAT'}\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "wmap = {}\n",
        "im = 0\n",
        "for x, t in zip(pred_auto, val_y):  # scatterplot\n",
        "    w = som.winner(x)\n",
        "    wmap[w] = im\n",
        "    plt. text(w[0]+.5,  w[1]+.5, t,\n",
        "              color=plt.cm.rainbow(t / 4.), fontdict={'weight': 'bold',  'size': 11})\n",
        "    im = im + 1\n",
        "plt.axis([0, som.get_weights().shape[0], 0,  som.get_weights().shape[1]])\n",
        "plt.savefig('drive/minisom/som_reuters_embeded_test.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAHWCAYAAACmHPpfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXeYFdXdgN+5/W6vLLDA0nFBRRBR\nUFSwxPIZBWMJls9oolGTaIrGFEvUGKMRleSzR8USJRJUEixYiCDSLbj0zmZhe7u7t8/M98fsbsCy\n99x7uHvv4nmfJw/rZH97zpw5ZebMnPNqpmmaKBQKhUKhSCm2VGdAoVAoFAqFGpAVCoVCoUgL1ICs\nUCgUCkUaoAZkhUKhUCjSADUgKxQKhUKRBqgBWaFQKBSKNMAR6xcCgQC33HILDQ0NhEIhrrvuOg47\n7DBuvvlmdF2nuLiY+++/H5fL1RP5VSgUCoXikESLtQ75jTfeoKqqih/84AdUVVVx5ZVXMn78eE48\n8UTOPPNMZs2aRd++fZk5c2ZP5VmhUCgUikOOmFPWZ511Fj/4wQ8A2LdvHyUlJaxcuZJTTjkFgKlT\np7J8+fLk5lKhUCgUikOcmFPWnVx88cVUV1fz2GOP8b3vfa9rirqwsJC6urqkZVCExbfB2icAEyZc\nByffLh77O+3A/749jn3LfmcHDOtnzQG3RRJM1wa362JxBga3Z5rY/da9VDRL5zYfuAQupY7O3ZdW\nw6IiK8/n1nDTk33x0v3rBgOD319fifGPEjA1bJdW8csHBgmlaRoRFjW8xuc5dgybxsiWMOfkno3d\nmSVwthL46+H9m4H9LujEn0Ofw2PHRoOw9E5o32f9tzsfjv8NZBTGjjWiUPEC7FtjpV04GsZ+D5wZ\niZyFMDo6D/IefqxK6MLODUwTurZP8SHV+ADIx8s1nCh0bWWRabcPDoLWSuvn3MFw486eSTdV/CEX\nwq3Wz+48uKUpuemZmDx4oh/fsgwwIfOkNn66OBO74GdHz5wIlcvANKHsJLhicXLz20lvvLb7I/xR\n18svv8yjjz7KTTfdxP6z3CI7byZzd849y2DJXXDafXDan+CDO+A/K8Ri7y+x/tXs1v8AHugvFvvE\nBMAAd67VQMwoPDVJLPYvh1n/OrzgyLD+ziMC4wTAb8e24/DbqR4WYeeREZxtDu4d1y4U+/Dj2+HF\nUrLObiH7rFbMpwbxf3O2x4x74vkdGI+UkXdBC/nfacWYNZSnXokdB/B53TusLM5gRmQEF7aXsa4o\ni0+aeqB1fvBbwIQ+R0HeMOvYmtlisR8/Zg3GY6+C8osg1ATr/ioWu/NdqPwQjv0ZHP0jqF4Du95N\n6BTi4QVW4SfCOAYygTLC6LzAqphxb1BBNT5O4TBOZzRNBPgnnyc9vzLt9u1fWINx2UlQNhVadsF7\nv0p+uqli3netwbhwFBSWQ6gZXr08uWm+/mgzvqWZDL8qyMirg7T/O5vXn2oUil39KOxZCuOugvFX\nw+5/w8dPJTe/0Duv7ReJeRtcUVFBYWEh/fr1o7y8HF3XyczMJBgM4vF4qKmpoU+fPt3+DU3TqKvz\nHbRM78/n812guSg5pa3jYSibz/4Rwj0sHDPWX2s9pZ33RhtGEF4/N5u2fSZ1dW0xY/d9YsVOf7sN\nIvDylGyqVonFNmzuiF3UBmF45ZRs6tZbscXF2d2WlbMiCxOTfvf6+WMkyi9nFmFuzBIq38isQYDJ\nBbd42eNo4L05xbS/lUvdWd3Htv6xFDCZ/qMM6uw+/vUINLznpe7k2Gnm2o/losYI2XomgeBuyIN6\nzS5dH2KVExPu7/oxa8tzeAFdc9Ioku6Qq2CI9aOr7RNygaCZiU8kNud4mHg8RMDeXkUB4Au7CCap\n/ncy1l7KQEc+R4RK2e1sgDxo1QPUNfq6LavhtmL62LMZEimi1uGDfGgIt1HXktz8yrTbipczAY1p\nj7eBDs+MyebTFwyO/FnsG9Pu0o1Zp1LEloVWf3H2K9b5Pjcum42vmZwg0NckSvVzWYDJyb+K0kaI\nLY972TnHQ9253dcngE/meAE743/VBgZ8/Hg2a56OMvDcQNLyC3J1KlkUF2fH9fsxB+Q1a9ZQVVXF\nb37zG+rr6/H7/UyZMoW3336bc889l0WLFjFlypSEMyyLv07D4QV7x8ycw2vir9G6D/oC/cZ1/hTH\nk3zHVHXB0P1ijbiSpXhU/OnaOtLIHWMS2GlNLWlhsYkOo9oqJHuBzgdFG8A7ENvHucTKuF7pBsBZ\nYLC4oAK8JWir8oTSzDBdZOgusjfM5v1RfYD+9HccAVGhcGmKVv4EABONxrF3xRVbuOZmND1I1NsX\n39BL44rN3TAbp28HgT4nECyeHFdsIpTq+ZTq+YTReTt3AwDDgsUx4wqNLAqNLKIYvJlTAcCIYPc3\n2AcDmXYb7hgLvAWdR8yu6dxkppsq9KD1b1bfziNm17FkEaq3+hRHlsmqnG1AIdS4gdgJBxqs8nR1\nvZUyCdQlv4x747X9IjF78osvvpjGxkZmzpzJ1VdfzW233caPf/xjXnvtNWbOnElzczPnnXdeT+T1\n69lvPPumuKtWZO730izOc55TuBxdMyGi4aj2Cse9VLAavz0COti3i78DNjCZf8zJbO7bnylbNjKk\nKvlTop20lF2I7swHTAo/vTWu2KbyGwiUnIQ9UE329ufiim0dfgW+4Zfjqf0IT+2HccUmShi969pm\n6S6O9w8TiotidF3bfuEcDg8JvreRJVXt9hvYXyTKe9mb2OluAMAhs21FT42LvfzaxnxC9ng8PPDA\nA186/swzzyQlQ/GS2dckGrS+wzF10IMaWaWiV8IENPYsgUAjWLVG7DFXs5uYukZdRecdu4ZmF3xE\n1kwwNao/hlBLR7qa6OO1lefIPpPcatDiyLM71yTs04iEoKAxl8aoDXd+7K/JOuN84QhlTSXsDttx\n9xP7Cs3Zspn3C+vY7jWY4hvOibsXE/WaBEuSO6uSW/En7KEmGo/+PU19T6Bo5U/QDL9QrHfvu9iD\ntbQNnUl75vl4a5bibN0iFOts2Ywt3Eyo+FhChePJrPwnrub1ST9fgOcLVxDVDIoiWVzQPF447pX8\ntbTZQgwLFnO6rzyJOfwvMu3WnWsSbtVoq+l8etRw54u1Abn+IjU4vCbhiEbLHoj6ATQcGXFOx8VJ\nRh+T5m2wNdDEcXtHsgKNzL5i5dQZG2wGI2LlVzRWht54bb9I8j+lTDKDTo2y+n432xc4MDqmQctO\nE5sPzSw1aK9y8K+LMrvurLIGiw00JRN1qpc7ef28TIyOttH/BLHYwsMNGj538Pp5mV13ccXjBD+z\nHt0OG7IZdPHhzPBat53GIMHB8Vc74brh2O8aiW2p9RQ04vLYg1TWHbvwXTUM18PDCbw5AICR/ys2\nZ1ap7aIi38uxjdmMbg0S1X2EMsYKxcrgbK8CdHI2zMbUOr80FrvDdzWvx+nbTiRzAGhOwMBwF8SM\nA3D6tpOx9x10TxFodmzhZvSC5J/vO9mbCNt0sqNuTm8up4UALuwxv7JenbGbZkeA/uFcTvANw08Y\nB7akf2Ut025HXhhh7QMe3v2ht6PDh/JLxJY4yKSbKoaeE2HTi24WfjejK88jzo9jSUcCFF3azN6P\niij+xTE0+jMBOOySkFDsqIsj7P3IwYq73Rgdr29Fr48MvfHafpGYG4McLJL5scTah1yse9KJpsHY\na8OMu1784j/Sx/pAxMLkulqxL5YBHu2fiRm1Ym1Okx9Wicc+0jcTDCtWs5lcW23Fxvpg4nfmemxH\nTaBgn/VZeN0AnZfm1LL5iNgfDzxVuIzwvYNh9mDrlH++E9fPdvH9hhO6jXsxfxUt95UeEJf7071c\n0jgxZprvZ25kc8aBy+JG+QuZ1j4mZmx3xPwAp62SovV/Yv85rOZR1xLNE3gCDLeRv/FB7EEr34Yr\nn+bRN4gNynqYrN2v4G6qANMgnFtO25CLMB3irwYS4anCZURsB96YOQ0b3284oduyejF/Fa2OA2+u\ncnSP0LWVRabdvjAxg9Zd1g1W3giDmcvEZj+6SzddP+oC+OvITELNVn/hKTK5coN4X5MI72dvZtO3\ny+A9a4kkZ9Zy2LxKpvlGCZXTggu8/GeJHTQoOyXK2S8m+aV3BzJ1KhnE+1HXITEgH0qkc6eQTqhy\nEkeVlRiqnMRQ5SROvAOykksoFAqFQpEGqAFZoVAoFIo0QA3ICoVCoVCkAWpAVigUCoUiDVADskKh\nUCgUaYAakBUKhUKhSAPSZmOQVfe6WP+8E0w4/HsRjrlJfEPwV8/xsm+VtS63/ySd814T38T8kT77\nbQGpmVxXI76+TybPz43LpK3KWleYPdDgsrXi6yhlzvefdzvZ8rwL3YTyK8Kc8+skr9MLt1G47i40\nvSOPmoOmw3+BniGwPaMRJWvXPNxNn4JpEskZiW/ozKSv6e2NmJgsy9zBVk8tJiZl4QJO9o0U1uUl\nSqJtQEfnuYKVBG3Wxg1O08YlDRNjbmRyMHhsQFbXhhV2t8k1lWJt3gw2EdrzZ4raWtBMaMjMwl36\nv5jZQ2PHpuj6yPDksCwiHaubXDkm398m3jfK9FEy/aoMMn3y536D63dE2RQwWTTayVGZiV3XtKgN\n+1baWTPLzaTbQky+I8Tq+91UrxHLWsUzTvatdFB+SYTRl1k7xGx4Qew+48VJXkDD7jGxe0wwbbw0\nRayzl8nzsttdtFXZ6DdZp//xOr5KO8vvdgrFypzv2qU2Kmd72HldO4uuaqfyIY9wnhMlf+PDaHqA\n9v5nECw+Hs2MkrPlSaFYb80SPPUraBl1La0jrsLd9BnemiVJzW9vZYu7ls8zqjit9TDOaB3NFk8t\nmzzVSU1Tpg38K7eCoD1KebAvhwf6EbEZLMyrSGp+AV4/34MR1vD2MckoMdFDNv55sVsoNrLnUfo3\nN7C330TqisdQ2tJEsPolodhUXB8ZFl3tJuLTyB1ukDfCINxq493rxW6WZPoomTolg0yfvCNoMn1T\nhD5iv94taTEgVy62g2YyYnqU4edad8x73he7gFvnOwCT4+8MMfk2a2u3za+IlUzLdjtgMuOddmYs\ntO7+mjbbk57n7QucgMkZTwf41hOBjvMQq+xS57vUAZrJ8RforJ8SiivPidI09jfUHzubwMCziLqt\nXX9Mh5iYItBvGvUTHyKaVYbhsLbvM5ziUotvEgPD+VzUeDQDIvnk6NZNZZtNbKvDRJFpAxPaBnFC\n6zBObhvJoLC1A5rflvwnoX0rrfYz4812pi+w2nzVh2LtJzrqF2ybdA85/S7Co1m2M58nUyg2FddH\nht3vWX3UufP9fPvv1pPizreS30fJ1CkZZPrkTDu8PdrJdwrFxo7uSIspaxlt1sFQfSWiQUyVPk7m\nfG0NVp41F+hOsHl6Tk9WtPIGwMSwe2kuvzGu2J5WGfZGOjWXBiYfZm0D6BrokoVMG0hUFylL597X\nuQM7j5hdx2LRWcZFK3+CCawuG4q73+VC3UYqro8MMspHmT4qVQpFmT65xKlR4tRY3SboI+iGtHhC\nBg6uNuubpvqK53zNr/k5yTSNuo5wbjmaHiBvw6y4YlOhMuyNGJhduryj2wfRL5qb/EQl2kCiusiD\nThztx8DktUkzmD/+WI7evYMxax+OK7bHr0+6kGAf1RsVijKkxYC8vzYr0h6fNiujj/V7wWbw10Fc\nqi/N+r3qj2H3Yiu281gy8+zOtX6vrQZadlvpuvOTf76deTZD4AyCEUq+nixrx0vkbngIPW8UrYdd\nC4AjsFco1tmyGXfdSkxXDqHC8RjufFzN65OZ3V7NkqytbHfXMcU3nIn+wUlPT6YNwIG6yMsaj0ti\nTv+L3WXlr3Er1HwCoGF3iuU5Z9NjVFU/QkWBjcLsqWiALdIknHZPXx8ZHF6rTFr2QMMmsJSPPddH\nJVqnEkWmTz6YpMWUtYw2S0b1JaNBTJU+TuZ8S6ZF4H43DQudHF5nve/wnJTcr6xdLZuwhZvI2D2/\nQ2UIhiNDKDZVKsPeyG5XIxu91RzTXsaoYAkRdGxoSf2KV6YNJKqLlGXA1Ci733KxYEYmRkdTLztD\nLM8+fR9j9zSju/IY1bwHAN0mlt9UXB8ZZJSPMn1UqhSKMn1ywDDZF4a6iDWI7A2bFDpMBrrjn6pN\nG9uTjDZLRvX1dRpEEZKhj0um2mxZq8GsOx0cu8CLqcHy6QEqvxtg7Vixr0wTIthIYcW9aB0voEyb\nk+YxPxdb9tSNylAZZw7k/ezNbPbUHHBsVLBEWJeXKIm2ge50kcnm8UGZ6EGrzTsyTK7eJaY+/cD9\nMcN2/ptR1XvRMNleXMLWoSdxQuTYmGl2d33Sla9TPiZbv5gqhWKiSs9lrQbTNx+Yx4EuWDvWrfSL\nvR010IihykkcVVZiqHISQ5WTOEq/qFAoFApFL0QNyAqFQqFQpAFqQFYoFAqFIg1QA7JCoVAoFGmA\nGpAVCoVCoUgD0mIdMsjZQeDg2TZ6CpnzfeqoTEJ7O5YjDDC46mNxK4mMwSURZAw5KbM9BZspWvc7\nMDuX5Wg0j76BqEieZWIlSJU9SbbdJkKECH8tWn7ARnMz6yeQS+z17SYm8zfuora8BhwmhduLOL9s\nWPLXAydaL9pqKFr/+wMONQ+/kmjhUbHT7Gg/WtVnmBGTrevL+cx/CWf8Mm26/a9k1b0uPnvOiU+H\n5WcF+M3d0UO6P9+ftDhLGTsIHFzbRk8gc75v/NZFeK+NpqMi7DwyQug/4lYSGYNLosgYclJleypY\nfx+YOoGiSYRzx6BhkrP58aTHypAKe5Jsu02UvxWswdSgTySLvuFs0OAfhZ8Kxa76Tz21J1Yydtlo\nxv37cBom7GNVTU3sQEkSrReFG+4FIJw5jKinBA3I3fasUJremiW4a1fw/C0/4/7dV3LkxLWUVi7t\nEXtSonTanhZc0c6O69qZ+mImvk/kpQ3J5GC2g7S4VdrfDoIBG55zsfkVJ6MvFduhpdO2sbrNZElr\n8nd1kUXmfGsWWlaSIY/4+fWuKL+cWcTW+S4m/Tb24vn9DS7o8Ny47A6DS/IsO9FRv2CbLUKBngmV\n8wHLkCOyFUmg3zQC/aYBYG+vAnrG9tR49D1dP2fsnI8bMO1iT+UysTJMaBtEo8PPEaFSdjsbqMjY\nl3R7kmy7TZRjfGXUOts42T+Sde5Kqt0+IppYmtHXijAvncKxizTatRCfANXVEShJapYTrhcNEx/s\n+jl7w2M4gzWgiXXbgX7TWPjMGezd5mLE1ADUQHtLDoH3HfSd0DOO4XjptD3N+qHBmjaTpt9D0wcO\nOKFnNgdJhIPZDtJiQJY1Nh1M20ZPIHO+esd0sz0PArlWrKiVRMbgkigyhpxOUmV7Klr5EwBMzU7T\nEb/tsdhESIU96WCY1hJhdKQ/oyPgJ8Ky7J0A9A2LiRoiOz04djnRXD4+yrGsS+7lxdBDO7ImWi+6\n4oCGo+7p/pf3w9agccUf/sjAmq08wiQaPjiRw/qk70NLp+1pRI6NtWGdiNskUpO+T/RwcNtB+p5p\nTxmb0oVD+HxlDDmQOttT87AriHpLwdQpWHdXj8UmSlrYk3qoHvuJMKdoOWhgM+HcVvER1bQZXdYl\n7hlOxta8JOb0QBKtF60DzsGwW+7lwk9/FVearz70QxaVXMrVrOTo0/4dV2xK+KKRTlD4k1Yk2A7S\nYkCWMjb1QmTOt9NKotdBbrUVK2olkTG4JIqMISdVtqecTY+R/9ldRIvG03zkLwHxPMvEytLT9qRU\ntts5RcsBcBkOrqk/UTgus6+JPms92911TG4YjvmbUT1iE0q0XuR9djeFq28mXHoajRP+AIBmik3f\nOls2M3LsMlpqctniHMceM4/h4z7rkfNNlP1tT6YfnGENV7/0zS8c3HaQFlPWMnYQOLi2jZ5A5nyH\nXhDhs1kemn6eyYx263xLLxJ7HyRjcEkUGUNOqmxPTt8ONCNI1tanQbPyatrEPpyTiZUhFfYk2Xab\nKC/nrQEN7IbG2Q1jqKYFL06hr6xdF9egja9k8Moh2Nb2h8woA05P/vvUROuFI1gHmOSu+yOmFl89\ncvq2c8Sod1hbXkp0cYSBw1pYXTkRz4Xp+z620/a0/B8OGlps2IDolAiVoUOzP/8iaSOXkLGDdGfb\nSFe+7nxjbdy+rNXg/SmZFOyzvjysG6Dzz2eahc/16wwuyULGkJMy25O/mqKKPya2dEkmVoLu7EnJ\nLCuZdpsojxYt+fKUoAnXCjwpp8qKlXC9aN1B0caHDjgkvOxJD+Pf+ndya9fjipps/nwMv6y7kE0X\nyPWNyZZLzL/XybanXV1Guo/OD/Tq/jwe0mZAVlgok4oYqpzEUWUlhionMVQ5iaNsTwqFQqFQ9ELU\ngKxQKBQKRRqgBmSFQqFQKNIANSArFAqFQpEGqAFZoVAoFIo0QA3ICoVCoVCkAWmxMQjI66tm743y\n+yodE7ipv42bSsUW0adK2/i7aR7+fm0bdYN1rvtNDncsCgnHPtJnf8GCyXW1yV1L3ElCZXUQ9HEJ\n6RejQfLXP4A9aK05NZy5NI/5KYa7IHasv56iz+9i/z38mkddSzSvPHashH7RxGRZ5g62emoxMSkL\nF3Cyb6SQGtDAYF7eJzQ4rLqQY3i4oHE8rhhNPNG4VBIlytMdW4SCtST50vqJZOGJHZyqOhVuo3Dd\nXWh6R7+mOWg6/BfoGf27j5NpPx30NjXtqntdrH/eCSYc/r0Ix9zUMyIMmTFI6Rf34+U6nburdOKV\ndKVK2/jcL5w8dWsr+SFrd4NImyasQZxzlBfQ0JwmmtMEbDw/Ifk2oUTLSlYfl6h+MWf7HOzBGnxD\nL6F94HnYIy1k7/ibWJ7X3wuYhHKPIJI52MrzlieFYmX0i1vctXyeUcVprYdxRutotnhq2eSpFopd\nkrWNBmc7x7UP4fi2obTag3yQvTVpcanklfxP0G0mg8L5DAkVYGrwasFnQrGpqlP5Gx9G0wO09z+D\nYPHxaGaUHIE6JdN+oPepaTv1i5NuCzH5jhCr73f3iC5SZgxS+sUvUOqCBwfbmVtvsKJNfJ+TVGkb\n69938oN3cxn0jzZubrSOiWoQ2/faAZMZb7djhmD+mdn49iTfF5poWcnq4xLVL7aOuqbrZ1f9Jx2x\nOWJ5PuZPXT9nbXkO2ndhCm73KaNfHBjO56LGoynQM2mzWTMmnf/G4gh/f8pCBQyJFFHr8AnHJhqX\nSib6yqh3tnNsYAibXdXs9DQS0sS2KkxVnWoa+5uunz1V7wFgOmKnK9N+oPepaTv1iyOmR8GE934E\ne3pAFykzBin94heYkmsNSHPr47toqdI2ZtTY8ETAkwt0DMjxahBLDu/8qWc2Xpctq0T1cSCnXyxc\nczOaHiTq7Ytv6KVxxf43zxqNY+MzNiWi2etUVRqYfJhlqQEHhQWmQ4FCI4tCI4soBm/mVAAwItgn\naXGpZFi0D8OiECTK+zlbABgUEiunTlJXp24ATAy7l+byG+OIS6z99DY1bad+0d5x/+vwmvhrkr+H\ntcwYpPSLil6HjD5ORr/YVH4DgZKTsAeqyd7+XFyxLWUXojvzAZPCT2+NKzZRzZ6B2aUGPLp9EP2i\nYp5fgCgGLxWsxm+P0C+cw+GhGO8nJeNSSZAozxZ9BJq1Z/fpbaPjik9VnWoadR3h3HI0PUDehlni\n+ZVoP72O/Z4xemZj569BZgxS+sXeQ6cG0d+w3zFhDaL1e1UrYPubYF359C0rWX1covpF7953ydrx\nN4zMUtoHnw/YcLZuEYrNrfgTBWt/Q6TvCTSN/52VZ8MvFCurX1yStZXt7jqm+IYz0T9YOA7glfy1\ntNlCDAsWc16L+Ec/icalkjlFyzGBTN3N9xtOEI5LVZ3K2vESuRseQs8bReth1wLgCOyNGSfTfnoj\n++sXI+2gB7Ue0UXKjEFKv/gF9oV1PmiB+qhVCOv9Jv9q1Pmfgu7fraZK2zjgvDCr33Gy6wUnfDtK\na5FB3hli7xtyhxm0bHew4PzMrnE477DkT0clWlay+rhE9Yuu5vU4fduJZA4AzQkYYl/DAs72KkAn\nZ8NsTK3z3bHYvauMfnG3q5GN3mqOaS9jVLCECDo2NKGvrFdn7KbZEaB/OJcTfMPwE8aBLebX0onG\npZLXcj/D0Excup2zGsdQTxseHEJfWaeqTrlaNmELN5Gxe35HLBiO2LpImfYDvU9N26lf3L7A0aWI\nLTst+e++ZcYgpV/8ArfsivB0nfGl47XHdK/rSpW2sbt0RUwqj5RkgtnRoDST62qSv+wp4bKS1Mcl\nrF8Mt5G/8UHswToADFc+zaNvEOtA2yopWv8nElr2JKFf7E4NGIsX81fR6jiwzeToHi5pnNhtWXUX\nl648VrQUUzuw29JM+KGAfjFldSrYSGHFvWgdH4uYNifNY34ee9mTTPshOX1csm1Pax9yse5JJ5oG\nY68NM+76npkRkBmDlH7xEEWpzcRQ5SSOKisxVDmJocpJHKVfVCgUCoWiF6IGZIVCoVAo0gA1ICsU\nCoVCkQaoAVmhUCgUijRADcgKhUKhUKQB6bvYUPG1yNhQEopNlSEnVelKGJtk0pUxL+noPFewkqDN\nWrPpNG1c0jARL93vwS1jmJKyUxlh5t1XRcOLIzFNKLhiE+ff2AenI76vUnuURI1NKebXuyI81bEs\n9LIijQeGiO3LLkOP91EdPH50BtH/2DABV5nO1asSsy6lCvWE3MuQsaEkGpsqQ06q0pUxNsmkK2Ne\n+lduBUF7lPJgXw4P9CNiM1iYVxEzTsYwJRP70fJPqZ91JKN+u4sxv91B431H8dHq2PlNJYkam1LJ\nn/dGearO6NGdiFPRRwH883YneqWdPaeEWHtGkOguB8vv7iWaqw7UE3IvQ8aGkmhsqgw5qUpXxtgk\nk66MeWlC2yAaHX6OCJWy29lARcY+/LbYdULGMCUTG/1wImgmJ00vpSm0jfU/geplA2CSUHhKSNTY\nlErK3PCrUhtz6w129JDEKxV9FEDdP52YmBxxd5BbKqMc86aXrfNdTPpt79lqVA3IvQwZG4qsSSVV\nhpyU257iMDbJpCtjXirV8ynV8wmj83buBgCGBYtjxskYpmRiqXXj8ELettl8MKoYvEfirEnvqd9O\nEjU2pYJvF1pd/Nz6nlNqpqpd2WDOAAAgAElEQVSPMlo1NMCRA+EM65VKuDWBE0ghasq6NyJjQ5GI\nTZUhJ1XpJmpskklXxrwURmdO4XJ0zSRLd3G8f5hQnIxhSibWNOHxSUezuW8pNsOguL139J6JGpu+\nUaSoj+rtqAG5lyFjQ0k0NlWGnFSlK2NskkkX5MxLzxeuIKoZFEWyuKzxOOE4GcNUorHZ+XXoQWjW\nTYY0lGCEnOTl7Y4r7Z4mUWPTN41U9FEA7lzr9yINkNEMGhru/N41oqsp616GjA0l0diUWZdSlm7i\nxiaZdGXMS+9kbyJs08mOujm9uZwWAriwx/zKWsYwJRNrm/o5zC6lz/P9GNCczw5g4NSWmHGpJFFj\nUyrZGYzyr0Zo6VgwsN5v8mxNlCtKktf1p6KPAhhyQYR1szxU3+blNLv1VXnfS8S/0E4HlFwizRDZ\nuF3GhpJQbDeGnJjIGHJSZeaRMDbJpCtjXnqqcBkR24EaTqdh4/sNJ3RbVjKGKZnYv+WtoPn+gTB7\nsKX0/vlO8m+o5LvNqfuqK2adStTYlEL+d0uYN1u+3MXHMuF1R1r2UVhmq39c4GXop9bN0tYJYT68\nx5d0e193KNtTL0eZVMRQ5SSOKisxVDmJocpJHGV7UigUCoWiF6IGZIVCoVAo0gA1ICsUCoVCkQYI\nfWp33333sXbtWqLRKNdccw3vv/8+69evJy8vD4CrrrqKk08+OZn5VCgUCoXikCbmgLxixQq2bt3K\n3LlzaWpqYvr06Rx33HH87Gc/Y+rUqT2RR4VCoVAoDnliDsjHHHMMRx55JAA5OTkEAgF0XY8RpVAo\nFAqFIh7iWvY0d+5c1qxZg91up66ujkgkQmFhIbfeeisFBYJ72H4FBgb3nthKZFkumOA4qYmbFucI\nbYgA8IdcuvYsdefBLWKbKgHwzIlQuczaoq3sJLhicQInECcRItzLov13iOMGppJL8jcZOHNlM281\nWAvtT8q38+9J+UJxi2+DV9+I8NIP2qgfqDPnyEwuHyCwDjnYTPv828nIbsUE9mo5NBzxI8aWjYgd\nGw3C0juhfZ/13+58OP43kFEonOe1TwAmTLgOTr5dKEwu3WAzvPeLA9YwM/nXUDA8uemS2PkaRpjN\nFQ9Qtm8XGiZVhf0YNPbnuASEGEGC3Gd2SBawlhNfrR1PX/JixoYNP3MbXqY6Jw/TplHS0sw5uf9D\ngTP2/tuy3OUGo2O/CLsHfttDhr4bKnzM3mPtKf2DAS6eOFJMOiLLp61RLv3Ux/o2ndWTc5mQl3wD\nUsJtTyLWwOCui6phcUd7ObuWXz3TT3gcScVY8EWEt2t59913mTdvHk8//TQVFRXk5eVRXl7OE088\nwV/+8hduu+22buO7W7c2/6VGIkvL6HNFIzYNqp8p4KlHdnDBBbEb56Kr3YRbXeQO19E0aN5q56UL\nQ5z6f7F3aKl4xsmepR7KLw2j2WDDcy4+eDDA6EvFdoZJlDkFyzHt0Cechc3UqHb7eMxYypUNk5O6\nxu+nO8K81fDf24BIWBdKa99KO68+5eaRR1soarc2eq9eE6HOHbucMhb/nozsVn7IBZSHW7nR/Tau\nNU9Ql9F9fQHI2fw4rvZ9+IZegi3STlbla4TXPEFL+Y9iltO+lXaW3JXBtD8H0DR470deCie203eC\nIZVuLArW3oqtQ91oj7TiblmPvnIWjRP+mNR0uzvf7spqb8NcDq/cyupxl+CKRhi/bi6fZbxI/+LY\nQozH8peAAxw+JzZdI5wX5gl9Gdc2nhgz9n3jFXaWlFDWHMapR9lW1Ie3axZwqu3CmLEyvH6+ByPs\nxNvHQNPAX2Pj6VPCnPNyKKlt7897o8yu0tGwbl6CwUiPrOXdETQ5fUOYozKtdtvU7KcuIvctbzLb\nnkzss4/Vwd+H4jyrHgyIPDuQh4/YwhWX9YsZm6yxICnrkJcuXcpjjz3Gk08+SXZ2NpMmTaK8vByA\nadOmsWWL+F69X0X0pb6AybdvczLxdmsXnOaXxZ64d7/nBEzOne/n23/3A7DzLTEB99b5DsDk+DtD\nTL7NunPd/Ery7x6P8ZVR3t6X81vGMyxUBEBES+5NAMBwD1xYANlxtsfKxXZcQXhhpINTBlsN2/ex\nXSj23yvv5qb/fYrLxxzPqALr/q+xUeyJr3XUNdQfO5tQ8bHoLutJXlRluL/Gbfi5VtnueV/s/lMm\n3caj76H+2Nm0D/suUbd1QxmPurGnz9ddfDZrj7+VYc6J5Nis/LZ4xMqp6O0yzDcKubJ1EkO0jqdi\nwbpV4DmWof4izoqcSmnEqg8+T/J3VNq30mrzM95sZ/qCdgCqPkx+m+/UIA7p4U2jMu3w9mgn3ykU\na68HA5m2JxMb+PMAwOTCu9xM+6P1QOZfJjYgpmos+CIxz9Tn83Hffffx7LPPdn1V/eMf/5ibb76Z\ngQMHsnLlSkaMEJh+7IZovZUNW5bBewUVQD8c1V4g9lNuxy52ZPXtPGJ2HYtFoMEaXFxdSlOTQF3y\nVd6jI/0ZHQE/EZZl7wSgb1jckpMo1/e3blSGrY1Pxeav08gP2TilyM6/fNadarTBBsS+a+2MnbzB\n0tRVUMK/Kn7MVefFju0kEZWhrGoy0XQ76Wl1Y6Ln26l8zNnwMIVtO1hdNhS9cIpI06No7kga/+HE\nt6uezTm1ANj3eoixfTYAR4UHQRgyNzxM9ag+QCkRT6lQujIYHbsw5g7sPGJ2HUsmqdAgApQ4NUqc\nGqvbeu67n1TpF816awDNHGjwWkEFeEtgbS4Q+9xTNRZ8kZj3s2+88QZNTU3ceOONXHbZZVx22WVM\nmzaNG2+8kUsvvZQPPviAH/0o9pSaCJ3aOQB3qrwXPXQN/ESYU7QcNLCZcG6rmDQhZXzxSwMtjh1X\nTUtlWOEcyRhqOPew/4sr6YQVipIat96mbkz0fKMYPHPMWOaPm8jRe3YyoXKHcKxe5OOlolVWuzFg\n5K+mCMe2EebB449kc99STti6kcu39tDL3C/S8/3uoU8K9Ytd40hEg0qx2amvJAX1Iuaod9FFF3HR\nRRd96fj06dMPWiYy+pg0bwNfq85gXz92oZHZV+xKOLwm4YhGyx6I+gE0HBliT1+d6QabO++cxdOV\nZU7RcgBchoOrGib3SJqJsr8Szex4gnEWiZXTkYe/xLA8nWDWBbxbMpbD/vNzykp20C4Q6937LvZg\nLW1DZ9KeeT7emqXCKsMD8qzHp3GTSTdn02PYQ3U0jb2V5qLxFK38SVzqxp4+X2fLZj51fEJtUX+y\nbeMxXdtwNa8nWBJ7YM3sa2LuWmr1WwaY9rPJukXsCdDZspmFfbeh27OxGzZO2lVN1GsKpSuD3WWi\nhzQat0KkDUDD7hSfrVHERqbtycTaXSZ6WMMXjlC6r4SqqA27O/3Hgv1JC/2i6/Jq+GgAGTcfiaPN\nenc24hKxeeeh50TY9KKbhd/N6NJ1jThfbA5q1MUR9n7kYMXd7q6vLssvSf781ct5a0ADu6FxdsMY\nqmnBizPpX1l/2hZmTi0EO+rZ9hDcsTvMHWXdzzEOOjXKRw+7mL/ARo3DBgMN6sdFWOXTmBjjhXTZ\nsI9xl7fy8SInxa4MHPkGzZqXypDJQHf3t6AyKkMZjVtvVDcmer51wY+ZtnsFQe9ZTPA7sIWbCRcc\nIZTmp3cuRut4Mj7stTFsPL2azP/RgdjvvT90fUxjVim57X5OryslovtoyxgjlK4MA6ZG2f2WiwUz\nMjE6ZjLLzkj+9xup0CACBAyTfWGoi1iNfm/YpNARu+3JkCr9YtYvK2m5swzbrw6jfn4pAAPPEbtB\nTNVY8EXSwvb0Yv4qWs46Et6zPnDizFpyX68Q0s4B/HVkJqFmq4J5ikyu3CDy/GWx4AIv/1liBw3K\nToly9ouCL6AleLRoyZenQ0y4tv7EpH7peeLnITZ9xemJqNj+8JjGg0cfGGwH9sWK9VfjWPkXcjOs\ndWmV5HEC16F58mNr0bpRGSZVAdcL1Y3w9efbXVnNzfmI4zetYFT1XjRMtheXsGT0ZC7wnRAzve7q\ncSweK/w3pu3AmzmbbnBN48kxY2V5fFAmetDKuCPD5OpdVn+RzLaXDA2iCMtaDaZvPrDeD3QhpSRM\nV/3ii/mraLmv9AClZ+5P9wqPI8kYC5R+sZej1GZiqHISR5WVGKqcxFDlJI7SLyoUCoVC0QtRA7JC\noVAoFGmAGpAVCoVCoUgD1ICsUCgUCkUaoAZkhUKhUCjSgLRYhwzw3LhM2qqspQjZAw0uW+vvkdhV\n97pY/7wTTDj8exGOuSnJe/cdBH69K8JTddaC98uKNB4YIrZ3N8CrDTo/3hklbMJfhti5sEisCqy6\n18Xd0RArTg+DBmflwrMjxZZOvHqOl32rrL10+0/SOe81sR2ZDAzm5X1Cg8NalpJjeLigcbyYvSUa\nJH/9A9iDNdbfcubSPOanwkuIEsUM+8jYcA+ZISvPQaebtsNuhIzSpKYL8EjfrK7dTDW7ybX7xJf/\n9ThGlKxd83A3fQqmSSRnJL6hMzEdYjsrPTYg67/GJrfJNZXi59qryqmDz/0G1++Isilgsmi0k6My\nxZ+lZPoLmdhEkemTE+1rZDAxWZa5g62eWkxMysIFnOwbiT2B5920eEJedruLtiob/Sbr9D9ex1dp\nZ/ndYpspyMTuW2lnzSw3k24LMfmOEKvvd1O9Ji2K5Gv5894oT9UZCe3q9kGLwTU7omTEeYr7Vtp5\ncKduDcYdhBvE/kjFM072rXRQfkmE0ZdZi+83vCB2E7AkaxsNznaOax/C8W1DabUH+SB7q1BszvY5\n2IM1+IZeQvvA87BHWsje8TehWBmc2/5MZqidPWVTqe5/HN5ICOfOvyY93b+f6gVDw5lt4soxMXUb\n8870JD3dRPHWLMFTv4KWUdfSOuIq3E2f4a1ZIhRrGZs0vH1MMkpM9JCNf14sdnPY28oJLGPT9E0R\n+iTgOpDpL2RiE0WmT5bpa2TY4q7l84wqTms9jDNaR7PFU8smT3VCfystRp/tCyxj0xlPB/jWE9Yd\nzdb5YndiMrEyZpFUIWONKXLC3JEOzs6P77JXLrZTUKNxdZFGcUfxhPeJNVMZi8oR/v6c0TyacYGB\n9I1a8o02m9jOOzLmJBlax/yCLZP/QEbf6TiclsWo3Z18z3V9hR0wOf+ddmYstJ74aj9J37oc6DeN\n+okPEc0qw3BkAmA4s2JEWcgYm3pbOYGcsUmmv0iFoUqmT06VsWlgOJ+LGo9mQCSfHN2a4RHtp75I\nWtTEcMcac2/XbKJJuDX5sQfDCNTTyFhjxmTYGAMsaIxv715/ncbYTz1cPTTKq59Y6ep+sXKSsah0\nmoiiGLyZUwHAiGCfuPIuY2xKhAzTRYbuomjlDYBJbVYODSOvpF+yt0vu+PsFXRuCmSIyrpSTu2E2\nTt8OAn1OIFgstqe7lLGpF5aTjLFJpr9IhaFKpk9OlbGps80bmHyYtQ2AQeHEXo2lxRNySpE0i3xj\nkLE9fZE42kgUo8ve0i+cw+Gh/nElJWNsShQDkzeOOY+Vg4dT3NZK+WfJn7LurbQOvwLf8Mvx1H6E\np/bDxP9Qet9HK+LhYPbJPVQvDEzey97ETncDR7cPol80MZ1uWgzI7lyr1NtqoGU3gIY7X+xKyMTu\nbxaJtMdnFvkmsX85dT5N2AVnYTP6WOUZbAZ/HcRrUXklfy1tthDDgsWc13KUcJx377tk7fgbRmYp\n7YPPB2zC5iQZsna8hH/nQ3zcx06g7DsAOAJ7k56uZrfKtK4CqpYDaF3H0hFny2bcdSsxXTmECsdj\nuPNxNa8XirW7rPNq3Ao1n4BlbBI7195WTt80ZPpk2b5GhiVZW9nurmOKbzgT/YMT/jtpMWU98sII\nax/w8O4PvV1TT6KmDZlYGbNIqpCxxjRFDda1Q3WH+WVzwGSVz4hpbBp0apS35tj55XsG7fmAEyr7\n6TxYZfLT0u7f0chYVFZn7KbZEaB/OJcTfMPwE8aBTegraxlzkgx622YGBxqZsaGEAaFm65gj+e+Q\nSybqVC938vp5mRgdN039T+g5KX28OH3bydj7DrqnCDQ7tnAzeoGYE1zG2NTbygnkjE0y/cXXxd5U\nnPCpxESmT06VsWm3q5GN3mqOaS9jVLCECDo2tIS+sk4bucQLEzNo3WWdQN4Ig5nLxJcuycTKWEmS\nQayN22WsMY9XR7m18sDOR8jYBJz6rwjrSr78sk0k3UQtKi/mr6LVceDv5ugeLmmcGHuDe0lzUqJ8\n6PyYEz+ZR0F7GwAtHi9Lxk9nkn5cUtMFeLR/JmbU6qRtTpMfViXfYpQwepis3a/gbqoA0yCcW07b\nkIuElz19nbFJhF5VTsgZm2T6i6+LNc8qSmo5yfTJqbD3vZ+9mc2emgOOjQqWMM03Stmeejvp2imk\nG6qcxFFlJYYqJzFUOYmjbE8KhUKhUPRC1ICsUCgUCkUaoAZkhUKhUCjSADUgKxQKhUKRBqgBWaFQ\nKBSKNEANyAqFQqFQpAFpsTEIwJPDsoh0fEnvyjH5/rb0V6KlilTp1E7+PMSGjmV9w13wkcA6SLB0\nau98oPHy1e3UDNDF9XFGlGVX7WLbh8MwgfKTN3Dco0OF16omTIrUjb0RGQ2iIv2R0T4mikydSlS/\nKKNQPOT0i4uudhPxaeQON8gbYRButfHu9cn3bvZGUqVTu3jTfwfjeNi30s7bLzn46+2tDCy0lrw3\nbBCrdpVz1vPZwnGMnN7G6PObWPv6cVT9TWx7RRlSpW7sbchoEBXpj4z2MVFk6pSMflFGoXjI6Rd3\nv2cpFM+d7+fbf7d22dr5lhqQv4pU6dRGeuDErPinVCoX23EF4a0xTi4dYVW36jViGrk1848DTI6+\nLZsJP7PuBjYtKoszB/GTKnVjb0NGg6hIf2S0j4kiU6dk9IsyCsVDTr+odzx5ZfXtPGJ2HVMcSKp0\nancOtkbx/qvji/XXaeSHbIzMtvFxyNq2M9gQn06teI+l6LM5Hqd6RxkgvjWqDD2tbuxtSGkQFWmP\njPYxUWTqlIx+UUahqPSLit6F5OasnYo+m80gJ3ffwcmTAKlQN/Z6lAZRcbCRqVNxxMooFA8p/aLD\na/XYLXugYROAhiNDKdEOBfbXqUU7Hq69fcSubdEgSwwR8OfQZIwnGnbRt2xXknL6X1KlbuxtyGgQ\nFYqvQqZOyeoXZRSKB0u/mBYD8tBzIoDGwu9m8Ob/Wqq6Eeerua+vYmcwyp/3Rr+kREt27JLmEBdv\nCtE5ebU3AtdsjT19PejUKBEnfPCGjc3rOgw7E6NUhmI3lLHnfA5ofHZvM5/ea32CP3hqi1B+ZXA1\nr8dTtwJ3zRLctcvpKXVjb2PA1CigsWBGJgsvyQTENYiK9CdgmOwImgdoH0XarQwydWrUxdY4suJu\nNyvusl6xieoXOxWKE/z/VSjqfNlud7Bjv0ja2J7+OjKTULPVYXuKTK7c8M1cPpFM/aJM7JiPQ9R9\nxaskkdhnnrbxyyMOXH4gpI/Tw6y8fgcb3xuFppkc/q0KJjw4AtPhTa5xJkXqxmSRzLKS0SCmG8pi\ndCBfp33cc2py9YsydSpR/WJ3CkWZWKVf7OWoTkEMVU7iqLISQ5WTGKqcxFH6RYVCoVAoeiFqQFYo\nFAqFIg1QA7JCoVAoFGmAGpAVCoVCoUgD1ICsUCgUCkUakBZbZxJuo3DdXWh6x9IYzUHT4b9Az+if\n2nzF4NUGnR/vjBI24S9D7FxYJF6cMtYlmXSfu91J9csuMKHPJSGuuL1n1o0mZI0xorx77m5WBQbz\n0nU6NQNNfl0S4cZBWbFjg80UrfsdmJ1rtTSaR99ANHto7FgZ21MKTVGr7nWx/nknmHD49yIcc1NY\nKC4Vdh0pmrZTtOXhAw41l55NdMC3kp60TLudvTfK76t0TOCm/jZuKhXf91sm3X/e7WTL8y50E8qv\nCHPOr8X3eEi0r3mkz35tVDO5rqZn6lSibUCWg5VuWjwh5298GE0P0N7/DILFx6OZUXK2PJnqbHXL\nBy0G1+yIkpFACcpYl2TSffN9jbZHPSy7qp1FV7Xj/z8v1WuSXwUStcZ8+suNLN9zBI/cEcGtWZ1I\n9qu7hWIL1t8Hpk6gaBLh3DFomORsflwoVsb2lCpT1L6VdtbMcjPpthCT7wix+n630LVNlV1HhsKO\nwVi3Z2FoTjQgt2ph0tOVabcv1+ncXaWTiKZBJt21S21Uzvaw8zqrzVc+5BFu84n2NS9O8gIado+J\n3WOCaeOlKWLKVJk6lWgbkOVgppsWA3LT2N9Qf+xsAgPPIuouAsB0CDwFpZAiJ8wd6eDs/PiLUMa6\nJJOu/pEDNJOh50VYP8XaZWvP+8nvQBO1xqx4aRKuINxZ4GBMf+sOu+GTvjGiLBqPvof6Y2fTPuy7\nRN3FAJh2sU5BxvaUKlNU5WI7aCYjpkcZfq416yFybVNl15Gh4djZ1B87m6YJ92DYe66fkGm3pS54\ncLCdCVnxD6sy6bYstdr88Rfocbf5RPualu12wGTGO+3MWGjVqabNYm1fpk4l2gZkOZjppseUdQdF\nK28ATAy7l+byG1OdnW4Zk2FjDLCgMf4t0mSsSzLpZjXZcHgBJ+hOwGPir0m+DSBRa4wRgewmGz/l\nEYrJ500upK6yPyBebkUrfwKAqdlpOuK3caUvY3vqaVOUv07D4QV7x0ymwyt2bVNl1zkYdF1boOGI\ne5Oenky7nZJr74iNfypTJl1bg1UvNJfV5m1xtHmZvgaguGuTK/G9p2TqVKJtQJaDmW5aPCF30jTq\nOsK55Wh6gLwNs1KdnUMT82t+TmNah1/B+97jACgsqosrtnnYFUS9pWDqFKy7K65YGdtTSkxR+11P\nqf33esiuI4s/fzxmR4KFn9/Scwn3Nnphmz+AeOrUwWoD8XKQ0k2LATlrx0vkbngIPW8UrYddC4Aj\nsDfFuTr06DQvaSFwBoGQRlZp+rbQgtJaABp257DFVwZA8QAx/WLOpsfI/+wuokXjaT7ylwDYIk1C\nsTK2p1SZova3akXaQQ+KXdtU2nUSpWDVzylc+RP8I6+g4VjrfbKyPn41nfXC7GjzRk+0ec36+9Uf\nw+7FAFrXsVjI1KlE24AsBzPdtBiQXS2bcPp2kLF7Phl7/gmA4chIca66pylq8EGLQXWHCWVzwGSV\nT2xqR8a6JJNu/tQImBr6IieHL7FeSLVNTv5XiIlaY8Z+u4KIC+bc2UrGcmseteGoEP9qjD317fTt\nwB6sI2vr02RtewEA0yb2LkrG9pQqU9SgU6Ngamxf4GDb69YUZ9lpsetUquw6MtjMCBqQv/pm8lf3\n3JOxTLvdF9Z5uU6nPmp2xYrUY9l0S6ZZbb5h4X/bvOcksWuUaF9TeLgBaLx+XiZvXm7VqeJxYucq\nU6cSbQOyHMx000MuEWyksOJeNN0yc5g2J81jfp7Wy54er45ya+WBlcwO7JO0LsXauF0m3ceroyz6\nk4tjF3gxNVg+PcDK8wNCsTJ8nTVGxPb00C17uefCfl/6v8yzYhhn/NUUVfwxsWVPMranFJqi1j7k\nYt2TTjQNxl4bZtz1VpnHrFMpsOtIUbuGop0HvgY4GMuekmlau2VXhKfrvjyYJdvStqzVYNadjgPa\nfOV3A7HbHl/f10RjtT3gkb6ZYFh1SrOZXFvdM3Xq69pAsumu7cVDegzIii6USUUMVU7iqLISQ5WT\nGKqcxFG2J4VCoVAoeiFqQFYoFAqFIg1QA7JCoVAoFGmAGpAVCoVCoUgD1ICsUCgUCkUaoAZkhUKh\nUCjSgLTay1qGhPR+KeSabWFebbJWnJ2VC8+OFF8L/P3v21l4pR/dCWc97eXZR8X3mn1yWBaRjhUL\nrhyT728TXx+YKDJqskTzaxoRnj3MSaDZ2hQ3s7CFyz4PYnNkxo6NBgju/jPFLTVoJjRk5+MsuxbN\nXRg7YSNK1q55uJs+BdMkkjMS39CZmA4BsYURJfD6fIpzPkHTTJr8o3CecbFYLPBI3yzoqAqa3eTa\nfWJllSplnQy9rb2DXJ4v2hRicUc7mJwJr40W7y9ktI+9rZxlVKLpQHqXriCJ6v1Sxe/2RLoG43i5\n/R4bC672Y+voeF2NNt69XsyNuuhqNxGfRu5wg7wRBuFW8dhEkVGTyeT37atqCTRnkzWojeyyVtob\n8nj/OrF9sIN7n6e0oYrKYd9mX9m3KG2qJVg9VyjWW7MET/0KWkZdS+uIq3A3fYa3ZolQbGT1Ukr7\nLGdT6/Vs9f2AfsWfEP14qVDs30/1gqHhzDZx5ZiYuo15Z3pixqVKWSdDb2vvIJfnn+4Idw3G8SKj\nfext5SyjEk0X0rvlCZKo3i9VDHXD1X00ihOYnzD/7eSSW7M5aj+N2863xAap3e85AZNz5/v59t/9\nccUmioyaTCa/u94ZZcW+Cme++B/r2OJhQrFm2RVsm3QP+bkn4bFbCsVWb+wna4BAv2nUT3yIaFYZ\nRsfTuOEUUwR+svhb3D3jSfqdPYB+J1mDae3mXKHY+gpLeXf+fsq72k9il3OqlHUy9Lb2DnJ5Hu6B\nCwsgO4HeWkb72NvKWUYlmi6kd8sTJFG9X6q4rMSqJK82xq9T67/eiRGB7W7A2qYWXXBnuc7fy+pS\nCpvCsYkioyaTyW+nQnCQbzaOtu3AXwn7vEBbzNgM00WG7qJwzc2gB1ldNhR3v29DHNUrd8NsnL4d\nBPqcQLB4slBMZ1kVbLNi1749lR0tU+h3mcAUcseMSUHXzqBm1zGRNHtaWSdDb2vvIJfn6/tbF2fY\n2p7VPva2cpZRiaYLh8SA/E0mvbvODlKlRAP+ddTxGO3Wu1+7Q3zDdwOT146bgRHYzoyPVxL2vY5v\nxBXC8a3Dr8Dl20b2tueIZvQjWDJFLND8b+w4/Tn4tB9wnHC6CZHC66NQJJVe0UH+l0NiyvqbhMNr\n9Zh6oOOAaQkB4olt2QMNmwA04dhEkVGTyeTXlWE9EXzeqOPYeRqg4c0W+8DDu/ddKhteYH1emMLs\nqWhxKBSdLZtx163EdCojtEUAACAASURBVOUQKhyP4c7H1bxeKHbQYRsZM/lDIkYObZ7xtNQVMnDI\nOqFYzW6VS10FVC0H0LqOdUeqlHUKxcFGRiWaLhwST8gBw2RfmAP0foUOk4Hu9Lw92uiP8Pd6aO+Y\nUtwUgAerIvxU4OvHvO8EWb7Wwd7tNhisUzdIp+k4sYFm6DkRNr3oZuF3MzA6HhZHnJ/cOZ1Bp0ZZ\nfb+b7QscXWmKqslk8jvsjM1s/MeRZJx6NNsDVrmOPHUHMCJmbHtgI+P+sw3dU8xw/07AICpoa3L6\ntpOx9x10TxFodmzhZvSCsUKxQ47azITyRax/Ow89aufIkkaavEcKOeVLJupUL3fy+nmZGB31qv8J\nsacaZa5Pquht7R3k8vxpW5g5tRDsqAjbQ3DH7jB3lMX+nmJfWOeDFr6kffyfgtjvhb8uz8UxI1PD\ngKlRdr/lYsGMTIyOqi+qEk0XDgnbU8J6vxTxPxtCrPqKMVREvyijcQP468hMQs1WJ+ApMrlyQ/KX\nBcgo0b4uv7HK6YOMCnYOPQx/bR4A2f0bGLx5M1MCR8ZM8wPPOobteJdR1XvRMNleXMKW4acyJTQ+\ndob1MFm7X8HdVAGmQTi3nLYhF4ktXdLDhN6YT4F3HTabQVOoHOdpFwove3q0fyZm1Corm9Pkh1Vi\nZZUqZV2iJKu9J9NiJJPnEz8Psekrvp1Itvbx6/K859TY+sVUIaMSTQZKv9jLUWozMVQ5iaPKSgxV\nTmKochJH6RcVCoVCoeiFqAFZoVAoFIo0QOijrvvuu4+1a9cSjUa55pprOOKII7j55pvRdZ3i4mLu\nv/9+XK7kbjChUCgUCsWhTMwBecWKFWzdupW5c+fS1NTE9OnTmTRpEjNnzuTMM89k1qxZzJs3j5kz\nZ/ZEfhUKhUKhOCSJOWV9zDHH8PDDDwOQk5NDIBBg5cqVnHLKKQBMnTqV5cuXJzeXCoVCoVAc4sR8\nQrbb7WRkZAAwb948TjzxRD788MOuKerCwkLq6sQ27U9HXm3Q+fHOKGET/jLEzoVFyV+abWLyj1l+\nap/JBxMKr67nOz/Jwi74Sv+5251Uv+wCE/pcEuKK28XX2iVq9kmFJQoSt7eYmDzaJ/uAI9fU+sTL\neFwmbVXW8onsgQaXrfULxRlGmLnGUpr7WvUoqyXKxYGJOB1iX1smmi70TmtToiYiGQvRr3dFeKpj\nKdBlRRoPDBF/3SbTX/Q2cxIkfn1k6mJvq8dRojxduBxdsxYsacCl9RPJIrbc5YsI16Z3332XefPm\n8fTTT3P66ad3HRddNRXv5989wXv1Ya7Z0UqBU6MxYpKd7aG4WGzNpwyLl9VSe29fJs/xYdPgw8tL\n+fzsfZx2XD+g+7J6dWGEtkedfHSTjzYDZjyQTehSGCCwu+KeZbBmFpw3B9DgtcvdHDnDHTN23nch\n4oPCUYANGjZqfPjzbKY/J37OifDcqWCEO/aytkHbXo23L8/m0jet/7+7crozN4rVNDrXYNp4cpSX\nWxtjd75v/wLaqqDsJCvd3YvtrJuVzSl/iJ3nl7cspHmkkyEL++A0omw5p5H3m9dyab9zkppurGub\nju3vuf8EubsqhEODqAmZGS6Ki2OLOLa168z4pJljch1sCkTIz8ugOE9soLh/u5+n6kJoWDuGejzO\nA8qmu3KS6S9k8pwqurs+3ZVTov2MbGyq+D/+jY7JMIpxYGMzNbxevI4bOSXuvyU0IC9dupTHHnuM\np556iuzsbDIyMggGg3g8HmpqaujTp0/Mv5GO69bsfoO5Ix0saDR4sd7E5wtSV5f8nV1aXs0CzeSI\nU6BNC/Eh2excYKNumC/mGr/mRU7QHAw5N8LL9QYzHsjms3+EcA+LfRf5+XwXaC5KTmnr2L9YLHbL\nQqsRnv1KG+jw3LhsNr5mckJdbFGDDLuXWumeu7ANovDisdnsfN+krq4tZjmZrVmAydl/b6ctGuKD\nmUUYTU6heljxciagMe1x63yfGZPNpy8YHPmz2E/nDXdMxvQFmTY7iyZjO1uA+qg96el2d23Tdd1o\nVlDnwcF25tYbrGgzafeHhfIZjJi8Ve5gdZvJuw3Q1OynLiL2tFkQifKrUhtz6w12hCAYjHSlGauc\nZPoLmTyniq+7PrHKKdF+RjY2VRztGEi9s51jA0PY7Kpmc24NASNMXYPv4K9D9vl83HfffTz++OPk\n5Vm7Hk2ePJm3334bgEWLFjFliuDG+WnGmAwbU3N7Xi0WqXXg8ILmMlleuA28Ou4qMb1fVpMNhxdw\ngu4EPOJ2nv3NPna3uNlnf+tSVin0hCUKDrS35A6x0o3X3jLwZJPKGdtAaANKi3BHX+MtgP9n78zD\nq6ruhf3uM5+TeQ6BMIXBAA4goqBYB+pYHKuoiLW1dai3t7X3a69tb61e7a29ttraXqvVOmId64Ci\nguKAIrOiDDKPBkhC5pOc+ezvj52EAJKzzl452efgep/HpzRPfvmtvfYa9rTW6y0x8oZbxWKjy3Ph\n9XIKdt7P/IGbjb/35FEpz2v23FrJ1Dw7M004SMucGlUec5PZBUUObqkwd2cqM17IlNkqzJ4fmbaY\nie24KlrKiYFhBInybq6x5/3gkNhWuweTsLbfeOMNmpqa+MlPftL9s7vvvpv/+q//4rnnnqOiooKL\nLrrIVPKvNTosyFnPNncDmq7h012AoF5NP8y/k4zNSLNPkn2zq477FVeUB08+Ab8jQuW+eobsdEN/\n7ACc6edWceQg0xYzsB0HifJ48ceggTNu4yz/GFN/J+GEPGPGDGbMmHHIzx977DFTCRX7DTub9Qam\n7B3JoqBN2LDTFauFwBkEQuJ2np5mHz0mbvZxeHXCEY2WnRDtAMO6JCDblcTu0omFNBo3QcRv5LU7\nRfPqgMamj8IMXX802w94n9w77jydcKuGv7br6YCGu0AsdsQJ61izYBd+u87QlhKmv/IBbeMbgRNT\nmtfsuVUo+hqZtpip7fiJ4sXoQFbMzTWNifv64cisZyh9TFM0zgctcfZ22kw2BHSWtaV+onGd2wi6\nxrCnj8b+3CAAKr8p9o6k4PQI6Bqx+U7GLTQ2iPdPEYsdPC0KusaWOQ42v2pci4mYfYZPjwAac6/0\n8eZ3jC/uU22JAsPeAhpzLsli7kzjkb6ovcVW0PlR11lT2P4jo46d+WKi9VGXG8f7zo1eFtxsfLRT\nPVPseKM/30xosE7eZg9Fv8vCNsBPrKIs5XnNnlsr2ROO8Wx97BATUSICcZ2tQf0AC9GukNigvS0Y\n5S+7o7R0plnbofN4rVg9yYwXMmW2CrPnR6YtZmI7fiXvM+Kajitu57zGsezDjx9z7/S+1nKJh/ZG\n+fWuAxuYHdgjaE4yy7s5G1h/bzbcP9R4BPsf2zjq39o5o210wg8mHtobZf4fXJw4x4uuweKLAyy9\nNCBcZrNmHyssUXB4e0uieno3ZwPrvRPY/4xb56jAJ5zRNloo7+xJPlq3G9er+SPjXLVIbPnR0wVL\naXUc+OohN+pmZpPYVbPZvHD4c5uuH3WZNRHJmJO+szHMmy2HDnkipjWZ8SLTjHRw+POjn5fY9iRj\nEMs0+9iDxR+iawe2KU2HG/edqmxPmU66Dp7phqoncVRdiaHqSQxVT+Io25NCoVAoFBmImpAVCoVC\noUgD1ISsUCgUCkUaoCZkhUKhUCjSADUhKxQKhUKRBqgJWaFQKBSKNCD1rsEksEKFKKNEMx0bj1I7\n919UFH+KZtPZ1zSagmlXojvEzDEyKsT7v+/koXMC1A+J8ctHs/nJ31K/xs8qFdsDpT3NQTo/rBOv\nJ5m8MgpFmdhMxGyflxkrbtgc5uUmY7XneXnw+CjxtcBmdYSyZc5E+v1441H+fLyTSJuPuA1cuX5u\nWRIUHlfNjheyOt2epM0d8gctcW7YGsXXjyXaGtS5eH2EUhN7zcvE1i9fyOiSxdwS+QGXaNcwsmAV\n0U8+FIqdf72bSJtG3og4+SPjhFttvHOzmM913tN27pnZTnnn+FP/mZ11s1PbSfYstbPiXjeTbwsx\n5fYQy+9xs3eF2EmWiX1khBfQjBX6mg7Y+MdosY4pk3fRb1z4a2wMmBKj4uQYbbvsLL5LrJHIxGYi\nZvu8zFhxx85I92ScLM/Wx7irJoYZvYQV45uVWHG8T8xswlmTzSfntzP/unZcO3N5+/JGodgHB3aO\nF+id/9l4sFJsvFj2aSt1d5cz/nY/E+7w03DXQJZ93mzqGNKmeRQ74blRDs4v6L8iZdlh3hgn3y5K\nvovJxH6y6Cx+etNDTBg1lEaMrSjrNuQJxe5Y4AR0LnypgwueN+6etr0lNiHvec3BD27J47vj9xsa\nNryQ2gF/13t20HRGXhxlxIXGFng73xW7CJCJDbfaAZ0LX2vnWy8YV7qhJrFzJZN3yxzj/JzzaICz\n/x4AYNNLYudHJjYTMdvnZcaK4W64vlTDhMSIgS64b6ididnJ24esGN+sxIrjbfx4KDo6hVdFWDvV\n2C1v28ohQrHxiDFenPvPdqb9wxgv4iGx8SI6vxA0nUnTXVRfYFzs7V3gSf4ASKMJ2QoVoowSTSbW\nXWOnvMnOpbV/ZaX+ZxYu+QYbVokpLGVUiK6ddop323H0aCuB+tSqzaxWsQ2cBINPhWS0WDJ5ZRSK\nMrGZiNk+LzNWzCpzctcQcxc5ZnWEYJ3q1SqsOF53QEMDTnQuIOaEuKYTCSQ3MQ6bBqOmQzLjhYxO\n92DSZkL+2qHDvLJrmKldycknfMjwqoXWlKM/VKOZqGLLQAWcQqGANXlTAGNoszv6SUzxlTrd5Dmy\nvypIUwYf9QXOKa1s14/mee04/to8j8phnwMnJYyVUSH6SnWaN0Okx3dCWeWpnW2sU7EZ+sVt70Cg\nAUhCvyiTV0ahKBOrUHzdcbjDREMu2nd7cRJH0zU8Oe0g9NbfGC/WvQCBOjAzXpjR6R5M2twhW6FC\nlFGiycRWHreBb/3bE0TXbmOSvpOC/CY6SkuFYmVUiEOvDNMwIM4n840G2locp+CaUIIoOaxSsXlK\n4oDGmzOzeP/fjcdH3gFi+kWZvDIKRZnYTMRsn5cZK77oiHDHzgjtnb++PgD31YjVsVkdoWyZMxEr\njnfw1C2Ahusv+9W0OafvFIq1e43x4v2bs1h6hzFeOLLFzq2MTvdg0sb2ZIUKUUaJJhO7pDlI/YYX\nuIC12NGZxyjudF/K+8flC5lUzKoQrVLApULFJlJPD5Rm0VO/mMyyJ5kyyygUZWIPR7raecz2eZmx\n4lvrQiz7imYgol80q4uULXO6IdKerDjeh3cHeete3wFq2uWXtlNzguiyJ3PjRSKdbjKkzYSsMEjX\nwTPdUPUkjqorMVQ9iaHqSRylX1QoFAqFIgNRE7JCoVAoFGmAmpAVCoVCoUgD1ISsUCgUCkUaoCZk\nhUKhUCjSgLTaGGTG+hDvdX68NyULXhmT+iUB560NsaJzZckxHnjn6PRfhmDKShKPkr39Rf50xkzC\nHcYyAFdunO9vFltWI2Mhenm6lz3LjLXPFZNjXPRKQDjWqrwytieZvFbFWoVZ85KMSeiX2yM80rl8\naVaxxh+Hie+qZJWxSSavTFs2ZbTrHGvWNOzlO/olfKGV8bchUS4tNbedZDI8+1c7vx0YonZQjD+t\n9HHVjWJriUGu/8gY+HqSNnfIt2wNd0/G/cX3N+2fjDOFR6s7rSR23fgPG48fnXidnbd2IXN/Po5w\nh4+C4UGKBu0m3GoXMkXJWIjWPOZkz1IH1TMjjJkVYffHDmHDlFV5ZWxPMnmtirUKs+YlGZPQX3ZH\neaQ+bmrHWKuMTTJ5ZdqyWaOdt3Yhu+o3MZkb8NuNZT9lzauSLXrSLF2q8bOxASoLOzduedLZL/1W\nxsB3MGkzIY/wwOWFkNOPJRrpgXPzwNMf+zn3EcEGw0py8RvtXPiScRXWUZt4a7jAgDPY+OlJgM5F\nz+zg6jv/AIiZomQsRJtecgA6J/93iCm3GbuCiRqmrMorY3uSyWtVrFWYNS/JmISGuOEXA20MM/Eg\nzCpjk0xembZs1mgXGHAGu4/+Ff8c5eK8XGNDnYigk1iG5kV2fvDTPK4evb+e+qPfyhj4DiZtLqFv\nrjAOoGplardy7Ml/Vhq9cvCK/svZVwwY3/Uv8TuMLitUZd09BMdMQdQU1dNC1JVT1EIUaDCudlzd\nT9l1YcOUVXl72p4gOduTTF6rYq1iVpkx4L3cmFz/G+uzMRaY05j8VowXFBlD3nP7ku/zMnllkMkr\n05bLnBplTo3lfvHHvl2M9dmYsu5+/G0FPGS7nPqcY5L+G8nSZdGzdc5qDg/90m97Gvi6YkUNfAeT\nNnfIiv6jbcQ1eOo+tq4AVs0TyeTtS9uTzPFaFas4crDIXNY64lrW5k0GoLT1s/5Jmi791iRqQs44\njFa2cyFseAWMVpO45TlbNuD0GI+P6tonsHfPKAxTVOJYd57xO/5aaNlh5HQXiLV2X6nxe8Fm6Kg3\nYkUNU1bl7Wl7irQnZ3uSyWtVrOLIRaYtm8XZsgF3/VJ0Vy617iEA5LdvTWlO2H+ssc5t52Mh+qXf\nOrzG77XshIb1RqzIuPqVf8tUVApY5Q/zRB0EO49jSwhu3xHmdpMycRGWtoZ4uBbCnTl3hOE/tob4\n4/D0/dI6a2Cc9hoHr8/I6p6Hs4cmfqTkbNtC9UntrHr7G7wxwwEd1wJipqhRl0dY+UcP79zoJd75\n66IWotFXGB9ILLnLTTycXKxVeQdPi7L8Hjdb5jiId0qeRG1PMnmtirWKLzoiPL+PQ8xLtwzs/d1d\nUzTO5+0cYhKaJPAByrZglNcboaWzy6zt0Hm8Nsq1ZYmHQpm8MsjklWnLgbjOnjAHGO2KHDolCeKc\nbVvQdr/HomgZgYAXyGedfSDhFNdV6ZkRGmY72Pu5BoWGzc45TeyLcpn+M3x6hPVPu5l7pa+7jkUN\nfAeTNnKJU1eHWP8Vz91FTCpmOX5ViF1fUW+pzJmIlFmMYmGyd7zA/d+8mmCbsfzAUxzne+vEPjOX\nsRDNuczLlwvtoMGQM6Oc/7T4C5bD5RWpJ5m8MrYnmbypiE1XGUBv5qXekDEJfWdjmDdbDh3yRGxP\nVhmbZPOabcuHs8PtnFbce3uKhVnwxXtcGTjNdJnNIGuzk+l7hzPwKdtThpOug2e6oepJHFVXYqh6\nEkPVkzjK9qRQKBQKRQaiJmSFQqFQKNIANSErFAqFQpEGqAlZoVAoFIo0QE3ICoVCoVCkAWpCVigU\nCoUiDUibjUFATjFmShNmITKqyQcHZXcvXre7dW7YJa76MqsJM6V87ESmvA+UZ0PnxhGaXeemPea0\nZslilTJSJtasZk9Gz2eWCBH+Ubz4gD3mrto3kTx8Kc9tlbpRBpm8ZseaZXe7ePN9jeeub2dfZUy4\nrnR0FmVt5cWmMM+tHkosbuPPw2xcWZx62Ukm6lp7kjazloxizKwmzCpkVJOvXuohHtbwlur4ynRi\nIRuvXSHWwcxqwh6q7FQ+onf+Z+OhoWL2FpnyPj/NC3ENZ46OK1dHj9l48VyPUKwMVikjZWLNavZk\n9Hwy/LNwBboGpZFsysM5oMG/ilKv6LNK3SiDTF6zY82epXbmPePgwdtasecYFwLtG8SsTxvddbzS\n0co/PxtGls0o9V5nS/KFSJJM1LUeTNpMyDKKMbOaMKuQUU3uWWpowi55s52L5xh3izUfpVYTFgsZ\nysfzn2/nrCeNnLEOsbqWKe++NUbeS99u55K5Rmzdp6l/qGOVMlIm1qxmT0bPJ8MJbUOobi/n0pYJ\nVIWKAYhoYls6ymCVulEGmbxmx5pd79lxBWH2KAdnDjUm1bZPxPp8ZbiASwKjeG6Uk3MKjNhgP5zb\nTNS1HkzaPLKWUYzJaMKsQEY12bWnc15l10/07p8lQlYTNuQ043/nJ6F8lClv16PqwuH7Y+kH851V\nykiZWLOaPRk9nwxjIhWMiUAHERblbAOgPJyX8rxWqRtlkMlrdqzpqNcoCNk4s9jO621GXUUbbIh0\nQJ/uYorHRdyj80BbC5BHUTQr2aInTSbqWg8mbe6QFRJkmmYv08oLmVFms+o5i/R8HUR4ongxaGDT\n4cLWY/svuSIxB7cFLYkLcXQW5Kyn1W5cCOTHxV5xpRUW6FrT5g5ZIYbdpRMLaTRugogfQMPuFLva\nd3h1whGNlp0Q7TBiHT6RWB3Q2PAKBDrVZKK3qjLl1ew6ekyjfk3X1a+GZk/9LbKvVKd5s6FiM+7m\nk1NGhls1/LVdTyQ03AViZZaJ7anZ02Pimj2zcX3BE8WLAXDFHVzXMKVfcirEOKBddH6f5CwWbxcL\nszexxV1PeaQiRSU8FJn+I9Pn+7IPpc0dclM0zgct8UMUYyIE4jpbg/oBmrBdofR1wa7yh7lla/gQ\n1aQIg06PAhpzLsli7kzjMdCQc8TezwyfHgE05l7p483vGF+zimjCHNlxQGPB9Vl8/CsjpzNf7PWA\nTHnLJsUAjVcv2h9bcUrqX0uMvsKopyV3uVlyp/HiLhllJGi8c6OXBTd7+y128LQo6Bpb5jjY/Kpx\nnS2i2TMbJ8uz+StAA7uucX7DWPbSQgviX8SaRWac2RaM8pfd0UPUjalGJq/ZsWbwtCgRJ7w0x0bt\nWmOa2Dc+IlRXO1yNrLTXYa8ZQShotOP1SdSzWWT6j0yf78s+lDa2JxnFmKx2q7/pTTUpYlJ5aHAW\nsaDxPMXh07l+u/hSoMNpwhJhSvnYB+X9W0UWetSItTl1bqzZrzVLpXEmFcrIVMceTrOXqK5kVJNm\n+VvxwkMfCepw075TU5q3t3EmUT31pm5MJTJ5ZbS2v3tQ477jDwy2A9Hzetcvvpuzgcf2wLwvhh4S\nm2pVpVWa2N76XjKkzYSsMFBqMzFUPYmj6koMVU9iqHoSR+kXFQqFQqHIQNSErFAoFApFGqAmZIVC\noVAo0gA1ISsUCoVCkQaoCVmhUCgUijQgrTYGscLYJJPTKjuVjJXkD49q/PGoIDEn/PQLN7deIxYn\nY2ySKa9VsTLIGGdk6O/jjRPnxfxPaXAYbSE37uGyxgm4UjysyJqirDLDZZSRLh5l0XXbWf3RaNo0\nN8vODzL839r4fZXYFphmTVFg3kjXldesdUkmb19Z6dKmRVhhbJLJaZWdSsZK8vJSnf8dF+wu89a5\nDiEriYyxSaa8VsXKIGOckcGK412YvZkGZzsntQ/jZP9wWu1BPsjZlNKcIGeKssoMl2lGul1PrOWz\nueP51/eivHutn9OfzmLg+3uEYmVMUWaNdF15zVqXZPL2pZUubSZkK4xNMjmtslPJWEnCy+zM/HUO\n3yrZX2YRK4mMsUmmvFbFyiBjnJHBiuM9uqOCc5rHMD5QSXnUEEP4bakXL8iYoqwyw2WakW7FSyeh\no3PuZVHiZxjqxPhHZUKxMqYos0a6rrxmrUsyefvSSpc2E3KZU6PK07/Fkck51mfj9DxznUsmb08r\niSsXkrGSlG13Ur3Bha0ztd2FkJWkp7Epb5iRU9TYJFNeq2Jl6Gmc8ZYYeUWNMzJYcbxF8WyGRYqJ\nEufN3DUAjAyWpjQnGKao0zpGmTJFWTHOWJnXLIEGDQ24I/w3jtPWEHHr+L8sFortaYrSOuclwxSV\nmJ5GuuyBkIyRrqd1ye5Ozrokk7enla5wtBFr1kqXOS1EcXjMWkn6K+eREJuJ9MPxRonzTOFyOuwR\nBoRzGRfqH5mAMkX1D60jruULVxXokONrEQ+UMEVJYZG5rK9QE3KG4Ss1WlmwGTo6zUvJWkninVv5\nxsMIWUnsLuN3GjdB7adGTrtTLKdMea2KlcGdZ+Tw10LLDiOvuyD1ea063hcKVuK3hagKlnBRy3Ep\nz9dFT1PUDSne//rrSPHgegACHbk0BYpwhjV8A+uEYmVMUQ6v8XstO6FhPRhGuuStS5H25KxLMnk1\nu/F79WugZrER2/WzZEmbr6wDcZ09YQ4wNhU5dCrdqbvMl8nZFI3zeTuHWGMm5SS+xpHJO/oK44Od\nJXe5u796FrWS5J4RZst8ja01gA/qB8doPNOwnPTGoNOj7HjLxZxLsronc1Fjk0x5rYqVYdTlEVb+\n0cM7N3q7H+v3R14rjne5bwfNjgAV4TxOaauigzAObCn/yrrbFBXfb4ry4hT6ytqKccbKvGY5dvpq\nNr9bzmO/b2Oo3TAnbZwS4/HaKD8r6T128LQoH//ZZZiiHDaojHeaorSE4+Pw6RHWP+1m7pU+4p1D\njIiRrivv8nvcbJnj6I4VtS7J5C2bFGPvYievXpRFvPNRtVkrXdrIJawwNsnkTJWdSmTjdrNWEpky\nyxibZCwqh4tNZT3JImOckUGmrszwdMEyWh0H1mluzMPMxkl9nqsnMqYo2b5nlkwz0hELc9+/NxF5\nezi6BosvDvDxpcZHinoC2xMc3hQlMtaYNdKBnLlMJm9vVrpkSJsJWWGgTCpiqHoSR9WVGKqexFD1\nJI6yPSkUCoVCkYGoCVmhUCgUijRATcgKhUKhUKQBQhPyxo0bmTZtGrNnzwbg1ltvZfr06cyaNYtZ\ns2bx/vvvp7KMCoVCoVAc8SRcn9DR0cGdd97J5MmTD/j5T3/6U04//fSUFUyhUCgUiq8TCe+QXS4X\nDz/8MKWlqd8ST6FQKBSKrysJ75AdDgcOx6G/Nnv2bB577DGKior49a9/TWFhYa9/p9fPv+NRWDMb\n9qwAdCgaA8d+F5wCOrV4lN2Pz6bAtwJN02kLj6HkCsFYYFVrlKtXtbHWH2P5lDwm5otvyP/c7iDf\n+dxPKA5PHJPFNYO8wrG9kehT+fdug5V/B3SY+EM47Tfif/tON/s1ih74L0FD3+/y6N6T2Z0PtzaJ\n57xvMLTuMv6dNxR+sk089o6e601t8Jsey6gT1dNjp8KuRcYWekO+Ade+J57XqliZc9sbvdVVqnL2\nho7OfNaxmt3E0RlFKdM5BrvFn7Uku0ylv5AZp85d2sxbDcZuF98osPP+5ALp8qRyjJIZL2SQ6bd9\nhaktdS688ELycL5uqgAAIABJREFU8/Oprq7m73//O3/961+57bbbeo3pbd2ad8+7ZO36kOYxt6DF\nQuSv/yvtjjI6Bp6dsCyRpe9RVvgRn9f9Bw5biKPL/8ze+eXYJ52VMHZrUOesdWGOyzJG/abmDuoj\nYgPCBy1xrtgYId8OIaCtLUh9vdiuML2RaI3fnqV2Ft7p44y/BNA0WPBvXoomtVM+MfFu5oZG0Ym3\nNI6mQUetjUfPDDP92d4NPfOvdxNudZE3IoamQfMmO89cHmLa/yV2jS76jYvWXW4GTImiabB7kYM5\nPw4y+b8SL9h/erIXcGD3GMcWC9q4/6goV34YSFhPax5zsvNDD9VXh9FssO5JFx/cF2DM1YnPkVWx\nMue2N3qrq1TlTMQGdy1Lc7czvflobGi8mv85+W1exgb7Zy/sryJd19fKjFO3bA3zVsP+rSYi4Zj0\nMaZyjJIZL2SQ6be90S/rkCdPnkx1dTUAZ5xxBhs3bjTzZ7oJDDiDfZP+RDR7CHGHIcCOO7OFYj99\n72zuuuRhBpw/iAHfMByUdRvEzC9W6RdlkFGMmdUoyqjJZHSELVsMrdklPbRmTYJe1UzUPsqcW7NY\nkROgMlzAjMbjGRQpIDdmPFnqD3VjJiIzTo3wwOWFILCjb58h06a+TvrSr8JUz/vRj37Ez3/+cyor\nK1m6dCkjR47sk8LkrbsfZ9tWAqWnECyZIhTTpdwq3GzErpx3OltbpjJgVuK7tzKnRplTY7k/+X1H\nx/psjAXmNKb2TuJgeirGIDnFWE+NooGYRrGnmqwrTlRN1lNH2BWbrI6wZPT+WFF66gi7Ys2oG/sz\nVubcmsWKnAA+3YUv5iKOzkfZmwEYHO79tdfXFZlx6uYK48RWrey/ix2ZNtUX44UZZPptX5JwQl6z\nZg2///3vqampweFwMG/ePK6++mp+8pOf4PV68fl8/O53v+uTwrSOuBZX22ZyNj9J1DeAYNlUsUB9\nf+z42JOwagBwUp+UKS3pS8VYeu5tnxoyQftohT7OImVdHJ0FOevZ5m7g+PbBDIiKPdlSZAAZrkEE\nLBkbE07I48aN46mnnjrk52efnfj9rijOlg3Yws2ESk4kVDSBrF2v4WpeKzQhDz7qC5xTWonEjyPs\nmUCsfi6Vwz7nSJ2QD1CbxZJTjNldOrGQRuMmiPjB0CgmvsN3eHXCEY2WnRDtMOIcPrEnA+48nXCr\nhr+2605bw10g+FRB00HX2PsJhFqMWDSxWF+pTvNmQ0doPAVITt1oRazMuTWLFTm7WJi9iS3ueqa2\njWCche+OFX2LTJuSGi8kkOm3fUla6BedbVvw7X6bmKcYNDu2cDOxQjHh+LDjNjCxej5r5+UTi9o5\npqyRJu8xQg83rdIvyiCjGDOrUZRRk8noCIvGxWlY7eDVi7K6r7JLxos9tstE7aPMuTWLFTkBdrga\n+cK7lxPahzA6WEaEGDY0y7+yTkdkxqlV/jBP1EGws/9sCcHtO8LcPiR172Vl2tTXSV/6VaSH7SkW\nJnvHC7ib1oAeJ5xXjX/YDHSHwDKiWJjQGy9R6P0cmy1OU6ga5zcvF4q1Sr/YGyJfesooxsxqFGXU\nZDI6wgfKsyBu5NVsOjft3a81S6V+0apYmXN7OBLVVSpyJuLdnA1s8NQe8LPRwTLOaBt9mIjUk65f\nWcuMU6euDrH+K5pfncQ4leoxKt30pTIo/WKGk66DQrqh6kkcVVdiqHoSQ9WTOEq/qFAoFApFBqIm\nZIVCoVAo0gA1ISsUCoVCkQaoCVmhUCgUijRATcgKhUKhUKQBabEOWZYnx2fRVqOBBtvHRZg5J8Bx\nWWLXGsvudrH2KSfoMO67EU74WeItN/uCl6d72bPM2Ju2YnKMi14R1C5J8uCg7P22J7fODbvEli89\nOT4Lf42GDjSXxjh/aXu/1PGyu128/YHGs9e3UzsoxvwxTuG8XWUGyKmMM2ul+PIJmVir6O+2HCPG\nk4VLCdqMNaZO3cbMhkl4Se3ewzo6i7K2sslTh47OkHAhp7WN6pc1zC83xPjRtihhHf46zM7lxeJD\n6Gt3Odn4lIuYDtXXhpn+S/GlQKs74ty8Ncr6gJ5UHzAbGyfOi/mf0uAwxofcuIfLGifgEpwyHq7K\nJtL5IbYrV+f7m8WXSWYifXW8GX+HvOg3Lvw1Nj4/K8iOaSGGrXax5T6xAWHPUjsr7nUz+bYQU24P\nsfweN3tXpL5K1jzmZM9SB9UzI4yZZSxIXzc79ddGhu1Jw1uq4yvTiYVsvHZF4vWIXXW885gITeMj\nFNQ52PG/YusYZep4z1I7855x8I/ftFJZZKzOa1gnFttV5gFTYlScHKNtl53Fd4ltFi8TaxVWtOXX\n89YQtEepDpYzLjCAiC3O3Pw1Kc0JsNFdx2pfDd9sPYpzWsew0VPHes/elOf9oCXODVuj+ExU68oP\nbey638O2H7Yz/7p2dv3JI3x+tgZ1Ll4fodREEzQbuzB7Mw3Odk5qH8bJ/uG02oN8kLNJKHb+9W4i\nbRp5I+Lkj4wTbrXxzs2pF0RYRV8eb8ZPyFvmONHR+fE9YY653VjIve9VscqwynRjlVnErO2py8Dy\nnScDDPuLcadYPyf1dbzrPTuuILw11snVI42muneFmPFGxhpjlXFGBiva8kT/YE5preI0/6huMUSH\nLfVPmKwyRckY3lo+dICmc/JlMdZONcoqen5kbE9mY4/uqOCc5jGMD1RS3rnHuGgdy9jhMpG+PN6M\nn5DDbcYe4GMG2HAUGI+zYq3J23Xs7v4z3fQ0i7hyob/MIj1tT3nDjLwitqcuA0t1hQ17YVcdi+WU\nqeOOeo2CkI1ROTZsndcNwYbkrTHeEkjGGiMTaxVWtOWBsQKODg0kTIx5eesAqAqWpDQnGKaowlhW\nv5uixvpsnJ6X/KQIYGswzo/mgpgTbB7x81Pm1KjymBuqzcYWxbMZFikmSpw3c42nHiODpUKxPe1w\n2QMhGTtcJtKXx5vxE7I06WIlscq6ZDZvfxmMMtUUYwUWtOUwMZ4oWkxM08mOuTi5o6pf8makKUo/\nzL/TlChxnilcToc9woBwLuNCSgCSajL+o66edpBwHWhoOArEBARWmW6sMouYtT0dYGDZ01nHeWIG\nFpk67hkb7Xxa5i1NvTXGKuOMDFa15aeKlhDV4hRHsrmseULK83WRaaaorvOjh8AZhHio/6xaZnmh\nYCV+W4iqYAlntVULx8nY4TKRvjzejL9DHnV5BNB49Yce6m433ie5Z4TZFUrc2AdPi4KusWWOg82v\nGtcm/WG6GX2FUeYld7lZcqfxcVR/mEUGnR4FNOZcksXcmVmAmO2pq45fu95L08+NOO+3U1/Hg6dF\niTjhgzdsbPjcuCW3TYoK5e0q8zs3ellws9EuROtYJtYqrGjLb+esJ2yLkRNzc1ZzNS0ECJD6d8hd\npqiJHftNUTFSP+A3ReN80BI/xPAmQtkZEdA1GuY6GbfQ6POeb4i1qUBcZ2tQP8D2JNIHZGKX+3bQ\n7AhQEcnjlLYqOggTRqw9DZ9u9J+5V/p48zs+QNwOl4n05fEeEXKJB0/2Et1svNvZNDHMM7e3CdtQ\nrDDdwOHNIqneuN2s7emRiT5CO43rt/pBMR54qLlf6vixR23859EHLgmrdMHOacUJ60nGGmOVcUaG\nw9VzqtrUI0WLiNgOfBrljNv4fsMpfZ6rJ6kyRSWqJxnD26LWOPf+t4MT53jRNVh8cYBdVwaE+o+M\n7cls7NMFy2h1HPgiNDfmYWbjJKH2JGOHy0QOd7zK9pThKJOKGKqexFF1JYaqJzFUPYmjbE8KhUKh\nUGQgakJWKBQKhSINUBOyQqFQKBRpgJqQFQqFQqFIA9SErFAoFApFGqAmZIVCoVAo0oC02anr4aps\nYw9hEwrFBwdlE4lByKez9IIAv7orKhwrozWT1QqajZVRA96/O8pva2LowM8qbPxsYOqlFjKqyQfK\ns+na80Gz69y0R3w94wOl2fv/j6bzw1rxWLOaSshMdaMMMn3ICsZ/GqKmc4+LUjusmSBmLgM5/aJM\n35PJawZZ/aL5xFEWXbedzR9VoQPVp63jpL8NR3d4hcKt0tr2FWnRc7r0VZ99M8i2qWGGrXax5ldi\nnaRLKfjmTX5WTQ9w+tNZLP2pWKyM1kxWK2g2VkYN+Gx9jLtqYpjbHt8cMqrJ56d5Ia7hzNFx5ero\nMRsvnusRin16shfQsHt07B4ddBvPTBXr1GY1lZCZ6kYZZPqQFZy1Zv9knCwy+kWZvieT1ywy+kUZ\ndj2xls/mjmfUxX7GXNrEyldPouafa4VirdLa9iVpMSHvWGAoFP/9d2GOudO4ommeJ+o0dqCj8z9X\nxznzB8aONC0fi40OMlozWa2g2VgZNeBAF9w31M7E7P4zWcioJvetsQM6l77dziVzjSv1uk/F6qll\nixF7SY/Ypg1i59msphIyU90og0wfsoKRHhjnMedUkdEvyvQ9mbxmkdEvyrDipZMAneNvy2HiT42d\nwtbPHyIUa5XWti9Ji8uHWNDoIOMG21izL4aOji74lC8eMWKPG25j/b4YrW4dW1Bca1bm1FjuF5NR\n9KSn7g6S1wqaje2pBjQQVwNO7VTHPbcv9fsNd9FTNWmQhGqy81F14fD9scluWVzSvZui+IZ0PTWV\nXbEimkqQOz+ZiEwfsoL/G2E86ShbnvzkMtZnYywwpzH5fbNl+p5MXrMUxbMpimeb0i/K0DVelOy8\nH2fbVmyOh9i7dQiQeEKQGmvShLSYkL8Ss/Wog671k0Wlj7SClmofrSCz+ohBJpZZoZDASv1i64hr\ncbVtxmaLk5tXB5jUa2ZYv02LCbmnvirQqVDUssWuBnsqBduawBnWCBWmfobrK61gsrGZpgaUUU1q\ndh09plG/puvOU0OzCx6rpoOusfcTCLUYsWjJt6lkNJWQeedHoTgcZvWLMhQPrqd5cxmBjlza4xOI\nhl2UD9kOHJsw1iqtbV+SFu+Qu/RVL1zjZe+vDH2V81IxvV+XUnD2d7xs/F/jox37t8RiZbRmslpB\ns7EyasA94RjP1sfYFzWOcW2HzuuNqX3UKKOaLJsUAzRevWi/LrLiFLHyFo2Ld8e+eY0RWzJeLNas\nphIyU90og0wfsoK5+0KctSbU/YCqMQbf/kLs8bWMflGm78nkNYuMflGGY6evBjQ+u7uZVXcb73+G\nnt4iFGuV1rYvSRvb0/3H+rDtNa4PklUo/u54L/Y2W7fW7ONLA0KxMlozkNMKyqjyzKoBb90e4dH6\nQztynYA+TobDqSZF+FtFFnq004Xs1LmxZr/WLFE9PVCeBXEjVrPp3LRXfOmSWU0lpJ+6MZV2Htk+\n1N8MWxGi/StGvLoT3CnVL8r0PZm8ZpHVL5omFmbpzVv5YsFoNE1n3NlrmHjfSOFlTzJjTSpQ+sUM\nR6nNxFD1JI6qKzFUPYmh6kkcpV9UKBQKhSIDUROyQqFQKBRpgJqQFQqFQqFIA9SErFAoFApFGqAm\nZIVCoVAo0oC02BgEDEPO66d08P4sYx/NES74WGTpRDzKQ5VZxCLGnqVOd4jrt7WKfSYfDeJd+Eey\nfLUABMP5dJz4E+LuwgSBBvcPysbeuRNe1KPz450mTUTo/LBOPFbG/HLa6hDrOlcCCNdxJ2atPt0m\nL6C5NMb5S9uTMnmZtS7J2J5kbFwyPPtXO78dGKJ2UIw/rfRx1Y3i68RP+izE1s5iDnLAJ+PFz62M\niUgmdsb6EO91to0pWfDKGLEyyximrDI23bA5zMtNxqKW8/Lg8VGpPz86OouytrLJU4eOzpBwIae1\njcKe4F7MbBzImaJkYmXKLBPbl6TFHfKi37j4cFTYmIw7F2HZN4kV7aVTO4hFXDg8YZzeEJGQh1e+\nKbbu07XySbJ8tWzcN4ttTZfgdTfjWvWMUOz957pxhDVqRkbYdkwEZ1DcRPRotWEiwq4b/2Hj8aPF\n1tnJmF+uWL9/Mk4Ws1afLpPXrnER9o2NUFDn4IufJ2fyMmNdkrE9ydi4ZFi6VONnYwNUdu40t/ZJ\np3DeC9btn4yTRcZEJBN7y9Zw92ScDDKGKauMTXfsjHRPxv2Zd6O7jtW+Gr7ZehTntI5ho6eO9Z69\nKYsDOVOUTKxMmWVi+5K0mJC3zHGS16Bxqmv/Lbt7u1jz27uxAtCZ/mqYi2Z/CcCe9QOFYj9679/4\n7wsfJe+sEygYb+yV2lIrtmeq7TPDULXut228cKthDxA1EQUbDBPRxW+0c+FLxpVgR63Y8cqYX0Z5\n4NRsc49FzFp9ukxeVz8eYPhfjQul5vniJi+z1iUZ25OMjUuG5kV2fvDTPK4evf/ciuYd5YGJPnMd\nWsZEJBM7wgOXF0JOkoWWMUxZZWwa7obrSzVKTDQjmbyV4QJmNB7PoEgBuTHjglTE2mQ2DuRMUTKx\nMmWWie1L0uKRdbgNhte4+MNxbio6LSwOQWNTF0e578cZ3go8Qjwmdlhd1qXSz3+OFgtSt7OCxUu+\ny2kXJN5xy9a5i1y8DAJ+45GH4FbJ3QwY3/Uv8StnGfPLfw817i4rTJhuzFp9vsrkRUDs3MpYl7ow\nY3uSsXHJ4K6xU95kx9bZfB0ehPP+YbhxbstNnFsZE5FM7M0VRgVXrUyuzDKGKauMTbPKjAvJlxv7\n9/z4dBe+mIs4Oh9lbwZgcDjxKzmzcSBnipKJlSmzTGxfkhYTcl/QZQcB0JKZGXVoqv4x3vollOgf\nMEl/FJiVmkIq5Okve4tVNq6vswVMkRLi6CzIWc82dwPHtw9mQFTsKaDZOJAzRcnEypRZJravSIsJ\nuachR4sBdoj6dERGX5s9RjxmZ8eSXAKNEwANh1vsSnLcxHlU5dcTtl9GqORS3DUfUj7gC0T0tV0m\nIteXkBfsNFSJmogwjm3nQgg0gnGcR6YRqKfJK7TXqCdbltidjYx1Scb2JGPjkqErb6zzKUAsRL/k\nVRzZLMzexBZ3PVPbRjAuKD65mY0DOVOUTKxMmWVi+4q0eIc86vIILQVxvvu4jr3DmIR3Hh3hhk2J\nH+8MOnonoDHvahcf/Mh4BFZ57E6hvIOHf874b35I+7uLaHt3KTZ7nJjgF9Z5kwwj0NG/yOOSP+Qa\nPzxN7EIga6BhInp9RhYLbjRsQtlDU29+Wdgc4or1Iboy7Y4gVMdg3urTZfJ66SovjbcYx+q6KDmT\nlxnrkoztScbGJUPpmREayuNs+NzoA63FcZzTxNrU240hLlgX6r6sq4vCrA1i51bGRCQTu8of5pat\nYYKdTWFLCG7fkfh4ZQxTVhmbvuiIcMfOCO2dqdYH4L6a1Fvadrga+cK7l4kdQxgdLCNCjJjAxb/Z\nOJAzRcnEypRZJrYvSRu5xOSHo2w57tBGltCGEgvz8NAsIiHj99y+AN/f7Bdb9hT24/v4T/jcdaBB\nMFxAx4k/Flr2dOv2CFkX5lK4x3i/Uz8oxgMPNQubkx4ozWL/E4D9y55SaZwZ+0mI+q/oxyJllrH6\n/K3aR7zBuPbrqifR2MNZl1Jte5IxeZlFpo5HrgzR8hXjh4jFSMZEJBN76uoQ67/iq/9EsTL11Fv/\nSWU9fWtdiGVf0fxSXcfv5mxgg6f2gJ+NDpZxRtvow0QkjktUT72ZohIhE2v2WGVje0PZnjIcZVIR\nQ9WTOKquxFD1JIaqJ3GU7UmhUCgUigxETcgKhUKhUKQBakJWKBQKhSINUBOyQqFQKBRpgJqQFQqF\nQqFIA9SErFAoFApFGpAWO3VJEY/y/oztbF9VBUDpKesI3z2Yi8qS+9zcDPd/38lD5wSoHxLjl49m\n85O/ia9VldG4WaWPM6u8W3a3i7nva7xwfTv7KmNJ5bVKg/jk+Cz8NcYa5pzKOLNWihnEZDRuMWI8\nWbiUYOdG6U7dxsyGSXhJLOOwUh9nVqEI5tuUVbpIGe3jL7dHeKRzPfGsYo0/DhOTrID5Pm+2Xcho\nEGWwqg9Y1W8PJuPvkDfdt451H4xny2mt7Dmzge1zT6LsufUpzzvvaTv3zGynvHPsqf/MzrrZYo1V\nRqdmlT7OrPJuz1I7855x8NBtrUSyjMEoulGs8FZpEBf9xoW/xsaAKTEqTo7RtsvO4rvEDlxG4/Z6\n3hqC9ijVwXLGBQYQscWZm78m5XllMKtQBPNtyipdpIz28S+7ozxSHze1FbtMnzfbLmQ0iDJY1Qes\n6rcHk/ET8uLZk9HRmfrrbNw/MO5iat4emvK8e15z8INb8vju+P1dbMMLYj1VRqdmlT7OrPJu13t2\nXEH4w1A7Yzq3h42uErtwsUqDuGWOE9A559EAZ/89AMCml8SudmU0bhP9gzmltYrT/KO6TTMdNrEn\nAlbp48wqFMF8m7JKFymjfRzihl8MtDFM/OFBNzJ93my7kNEgymBVH7Cq3x5Mxk/I4TZjA8rL/P/H\nXdF7sTmi7N48JOV5XTvtFO+24/Ds/1mgXqyTT82zM9OMGBVDH3d6npnre7m8ZU6NKk/yzaWjXqMg\nZOPqCgd6Z+p4k9jf6alBtLv7T4MY7rzj8xaCtwRAJyxiHMHQuBXGskxp3AbGCjg6NJAwMeblrQOg\nKliS8rwy3Fzh4q9VJmYZzLcpmXZsRR8AuKDIwS0VJm6tkevzZttFUTybYZFiUxpEGazqA1b124PJ\n/HfInbSOuJZntqzHZotTWlIH9L86q9/UgJnGQZuzJlVNGagjlNG4hYnxRNFiYppOdszFyR1V/ZJX\nceRitl3IaBBlsKoPWNVve5Lxd8jFg+sBaGvKZUnreKJhFxVV21Oe11dqzA6RHt/6ZJVnyIzRj/RU\nGWqdT3G04uQ1iJH2/tMguvOMHP5aaNkBoOEuEM/bU+M2qWNoUrmfKlpCVItTHMlmVuNJScXK5FUc\nuZhtFz01iBe1HJe6Ah6EVX3Aqn7bk4yfkCd8ezWg8dZ/NjPsAWN2tE1uFlaqmWXolWEaBsT5ZL7x\nKKm1OE7BNanX3VmljzOrvBs8LUrECY+9pBHYYNTVtmMiQnmt0iCOutxQRr5zo5cFNxvvk6pnin1B\nL6NxeztnPWFbjJyYm7Oaq2khQACxd1FW6ePMKhTBfJuyShcpo33cFozyl91RWjpTre3QebxWrC3L\n9Hmz7UJGgyiDVX3Aqn57MJlve4qFeee7W/hy8VFomk7JGav59+8NoV3zCikJzSKjgOtNp5ZK/aKM\nxk3meH/+fxqPTzrUsyeS93AaxFQbZ2ZP8tG63bhezR8Z56pFYsueZDRujxQtImI78Nw64za+33CK\nVN5U1pVZhSKYb1Op0kUmqieZPvCdjWHebDl0qBUps0yfN9see9MgprI9paoPpDK2tzIr/WKGo9Rm\nYqh6EkfVlRiqnsRQ9SSO0i8qFAqFQpGBqAlZoVAoFIo0QGhC3rhxI9OmTWP27NkA7Nmzh1mzZnHV\nVVfx4x//mHC4f7YzVCgUCoXiSCXhhNzR0cGdd97J5MmTu392//33c9VVV/HPf/6TIUOG8OKLL6a0\nkAqFQqFQHOkknJBdLhcPP/wwpaX7d2lZunQpZ555JgCnn346ixcvTl0JFQqFQqH4GpBwpy6Hw4HD\nceCvBQIBXC5jb9+ioiLq6+v7pDAyFiOzyNhbZKwxMsiUWQZTtppokIK1f8QerEUHdpPLO4N/zPkD\nzG0tJ0qYMP8oXnLAz2bsm0Ah2QljZUw3OjqPTLMRWZ0FgHNCG997Uxc2zjw8wUP0S6MdOYaEuG55\nSCjWbJn7whJlRR+S6Xs3bA7zcpOxuOS8PHh8lPjySKtMa2Yxe36ttIeZNbzJWJesslsdjHQ20VVT\niT7/XrAvzA1bWyl0ajRGdHJyPJSUeGWL1yub22Nc8mkzJ+Q5WB+IUJDvoyRfrJM8+WWQu2pCODSI\n6pDlc1FSkniwF6G3upIpswz3bOngkfoQGsZulh6PU+yT/mX/QA/Wci0zqLR3cFfsNc5qfJ6SY26V\nLlNv+X/PWwAUkoUdjXr8/KtkFb/k3IR/93U+p4F2zuQo7NiYb1/HkpLtXMr4hLFP395E5PNcSs8N\nYAP2vpnLO4/s4+pfFCeO/X+tRL90UfqNMDYb7H3Pwzv3Brn6d4nrOVGZD1dXn/Mlq6nhak7EhsaT\nniWM8JQyEbH94K3oQzJ97z+/8HdPxgAut+OAuumtTcmMUakcL3rD7PlNFJfsch5Rdi6CFffCRU8A\nGrxyjZtjLnEzSGDzqydYTJAo46nEjo0V2g7mlXzBD0i8hlmmz/clpiZkn89HMBjE4/FQW1t7wOPs\nw5Fo3Zq9I85zoxzMaYzz9D6dtrYg9fWp3RkmGNF5q9rBcr/OOw3Q1NxBfUTsCjA7GOO+oXae2xdn\niV+nvSPcJ2vzEq3xkymzDIWRKL8YaOO5fXG2hiAYjIgd77DrWFsW5/yIzt6aT6ANWsnGKVlXiepp\ngquSWqefs9vHsNyzjfocP1E9Tv2+xHlH2EootecwLFJMnaMNCqAh7Ke+JXHsnkdzAJ3z74vSrod4\n/k0vO5/1Uv99gdhns4zYh0L49RAvVBez82kf9T+VK3NvdZWneZlhO56cmNuw2xTB3vYW6jvEzo8V\nfUim75XFIlxfqvFyo059FMKhaHdsojYlM0alarxIhNnz21tcKtchr37JBZqLsjP9nfvY5/DZv0K4\nqxLfJR9rH0ilwxA97HA2QD60xgLUN6a2z/dGv6xDnjJlCvPmzQNg/vz5TJ061cyfOQAZo4lZZOwt\nMtYYGWTKLIOsrebbm37Bj9qeYg1lLCi5so9LdyjHhQdzdvsY/IRZkb0LgKJIllCsjOkm0mKcG3eh\nzophmwEdfbfYI9FIm9Ydu7IrtkWsjZkts6wlyoo+JNP3ZpU5uWtI8uJ4sM60JoPZ82uVPUzG8CZj\nXbLKbnUwCVvImjVr+P3vf09NTQ0Oh4N58+bxhz/8gVtvvZXnnnuOiooKLrroov4oqyKDaar+Mcu3\nLOLswEe46mZD6fdSntNPmKeKl9D1nP3yluOFY2VNN13WGABbOLkJ64DYJOLMlllZoo5szJ5fy9qF\nhOFNxrp6XiKDAAAgAElEQVRkld2qJwkn5HHjxvHUU08d8vPHHnssJQVSHFl4d7+DPViHf/hVzM65\nmDMDHzMosIn2fsj9VOdHXfa4jesF9sLtSU/TzVlt1cJx7jydcKvGpkATJ2wfxXI03AVim9R3xza1\ncELD6KRiZcrc03IzLtj/g5AitZg9v1a0i56GNz2WvOGtp3XpsuYJSeU223/6krTZqUvGaGIWGXuL\njDVGBpkyy2DWVuNqXounfgm7ti3kWP8SHMSptxem/Nw+VbAUNNB0OK9hDF/SSCN+oVgZ003ZdU2A\nRs73TmDHd40PYI66Wuwr0bIr24zYKyaz8zojtnqmWKzZMstaoqzoQzJ974uOCHfsjNDeeYjrA3Bf\njZjJyyrTmgxmz69V9jAZw5uMdckqu9XBpI1cQsZoYpZUGZtkSKVxRgbTtpqwH9vqeymI7gNgF/mc\nwg/ZYyuQOreJ6ulvxQuNR9U90eGmfacm/Nu9mW4S8W7OBtZfMAQWdH5VfW4dR724S9g4s/7oatjs\nM35wlJ+jPt0gFGvWziNjuQFr+pBM3/vWuhDLvuLxTDqb1mQwe36tsofB4Q1viZAxRcn0+d5QtqcM\nR5lUxFD1JI6qKzFUPYmh6kkcZXtSKBQKhSIDUROyQqFQKBRpgJqQFQqFQqFIA9SErFAoFApFGqAm\nZIVCoVAo0gA1ISsUCoVCkQb0/+aqvWCFUk0mp0ysjMbNKgVcfx+vjBJNVsX2ZGgVgQpjIxF3o5er\n9fHCKjaz+jgZ5Z0Vujw9HqG95jHK6zei6Tr1hZW4Kn+AzZF4z/AwYf6RtxTdafRZLQ4zGsX0mF83\nrGgXVuoIHyjt0QY0nR/Wiu3rp6Pz0hfbqauuBYdO0ZZiLh1SJVRPMuMFwMNV2UQ6V4K5cnW+v9nc\nXoRpc4f8bH2Mu2pimNm6/Y6dkQOUav2RUyb2g5Y4N2yN4jNR+zKxmXa8C7M30+Bs56T2YZzsH06r\nPcgHOZuEYl/PW0PQHqU6WM64wAAitjhz89cIxb7VvpXAID/DF1cx4qMRhIoDzAuL5d2z1M6Ke91M\nvi3ElNtDLL/Hzd4VYge+0V3Hal8N32w9inNax7DRU8d6z96Ux5qlveENBu9Zy84x1/LlUTOprNtK\nR8MbQrFPeFeCS8e3M4fsbXlghxeyV6W0vJmKFe1Cpu/J8PRkL6Bh9+jYPTroNp6ZKqa4XPblPupO\n3cWxi8Yw/v1xNEzcw7La2sSByI0X8693E2nTyBsRJ39knHCrjXduNicwSZsJeaAL7htqZ2K2mNmj\nJ8PdcH2pRrIyFZmcMrHFTnhulIPzC5KvfpnYTDveozsqOKd5DOMDlZR3bmzvt4WEYif6B3NKaxWn\n+Ud1W2o6bGJ3qr7nK9EvmMC0oQM5epSxsL8pLBa76z07aDojL44y4kLjanvnu2INszJcwIzG4xkU\nKSA3ZgxCoscrE2sWW+m5bJ78PxR6xuG1FQDQ5hYbiMqer0K/czizHOMZXZALQFzrlz2KMg4r2oVM\n35OhZYsd0Lnk7XYumWvcZTZtELsNiL5SjD52KieekMuYE412uHev2C5fMuPFjgVOQOfClzq44PkO\nALa9ZW5CTptH1lM7tWbP7ROrhJ7MKjMenb7cmFyDkckpEzvWZ2MsMKcx+b1hZWIz7XiL4tkUxbNN\nKdEGxgoYGCswpWJjTS6OBU50VyvzCo282e8PgG8lDu2pj4Pk9HE+3YUv5jKlvJOJNUtXzrx19+Pw\nb2H5kOG4i74BAls0575fieNfTgI3NvJJvqHHdH1aCCNSWuSMxIp2IdP3+oKS7p09xS/SIts8OLY7\n0VxtfJxrHKt7cQkcmzhWZryIde64mV2+v8yx4OF+u3fS5g5ZofgqZJRoMiq2uDPanZePCih8r1K8\n0BL6OBnlnRW6vDg6rx93Mi+Nn8TxO7cxbPdq4dhYVrBbj6m32Kn6W3J2nq8TVrSLdNARJotui+/X\nl/7PCHyb8oVjZcaLvkJNyIq0pqcS7aKW45KK7alim9V4knBcVrlOfPEi/LYQw/wl6FOnCCvgeurj\nIu3J6+N6Ku8mdQwVjpONNYOzZQM7WuewNredopzT0V2FuJrXCsVmlevou95DB+wxG+Sfk1Q9fd2w\nol3I9D3TdL622PsJ7HgPupVtAmSV68TuXcsWdz1TGkag/2q0aXVjMuOFw2vkaNkJDeuNMjt85tpy\n2kzIVijVZHLKxMpo3KxSwFlxvDJKNBkVW/v1m9Cq28mvyaf8n6OgNMiAs8WeQcno42SUd1bo8jo6\n1nD8+nf55m474/YFsYWbiXrLhGLX/mIRmlvHFrIx9unxMKaFvHNbUlreTMWKdmGVjrBoXBzQePWi\nLN68xvhav2S82DjjuqIW7Qe7GLpsGLbnKiAryqCzxPq8zHgxfHoE0Jh7pY83v2OY2kZeKvbu+mDS\nxvaUKqVaqnLKxPamcUtXBVyqjrc3zCoFwVoVm1l9nIwK0Qpd3ge+NVRtns/ovbvR0NlSUsbGUecw\nNXBMwlgZPWaqSFeLUaraRW/I9D1ZHijPgrjRODSbzk17xZYQydSTzHgB8I9RWYSajTJ7inW+t84o\ns9IvZjjpOiikG6qexFF1JYaqJzFUPYmj9IsKhUKhUGQgakJWKBQKhSINUBOyQqFQKBRpgJqQFQqF\nQqFIA9SErFAoFApFGpA2W2eCnE1odUecm7dGWR/QmT/GyXFZYtcaMjllMGunAmssU2YNRiBhQolH\nyd7+Iu6mVaDrRHJH0Tb8KnRH4s3mZWw1VpiTZPOaPd4IER6JfIJebmw7qzU7uSp2LHn4UpZTFpl6\nihLl0c7dmMBYeXX1vklk40nbMmdi3ifHZ+GvMZYB5VTGmbWyQzhWZqyRiZXhwUHZxDtT2d06N+z6\nGtuetgZ1Ll4foTTJuVQmpwxm7VRgjXVJxmAkY0Lx1i7Es28JLaNvonXkdbibPsNbu1AoVsZWY4U5\nSTav2eN9KvwZVITIXV5K/pJyKIzwgi5mubHKCCRTTy8UfErMpjM4XMCwUCG6Bi8XfpbiEmdmmzLL\not+48NfYGDAlRsXJMdp22Vl8l9jgLDPWyMTK8OqlHuJhDW+pjq9MJxay8doV4jdYPUmbCVnGJpRl\nh3ljnHy7KLlpSianDGbtVGCNdUnGYCRjQgkMOIN9k/5ENHsI8U7Hbtwp5suVsdVYYU6SzWv2eMue\nGY1+wQSuHHQU1aONnJGAWNuyyggkU0+T2oYwwV/J+a1HMyxUDEBIM7erUjJkYpsyy5Y5Rp8/59EA\nZ/89AMCml8T6vMxYIxMrw56lDkDnkjfbuXiOcWdc85G5J61p88haxiZU5tQoc2os94ttsdYXOWUw\na6cCa6xLMgajvjCh5K27H2fbVgKlpxAsmSIUI2OrscKcJJvX7PFmfV6MY4GTkKuJJYXbAPC+Xwbn\npS6nLDL1VBUtpSoKQaK8m7vRiA2l97nNtLzhztdT3u40OuFWsViZsUYmVoZ45/VcXrd/Ru/+WbKk\nzR2yIs2RMBjJ0jriWtpGXIOn7mM8dR8Jx8nYaqwwJ8nmNXu8MWeUJ4oXG9aljwoYumBkynPKIlNP\nQaI8XvwxaMb2iGf5x6SwpPvJxDZlCTJjjYXj1AGYvA5QE7IiITIGIxkTirNlA+76peiuXEJFE4i7\nC4RtQiBnq+lvc1Jf5DVzvFnlOvriReiAK+yAJMxWZnP2BTL19ETxYnQgK+YW3qu4L8jENmUGd57R\nfvy10LIDQMNdkHpbmqxpzSx2l5GjcRPUfgqgYXd+jW1PgbjO1qBOfadNaHdYZ1cocYXI5JTBrJ0K\nrLEuyRiMZEwozrYt5Gx7FkfbFhz+7djCzcS85YkDkbPVWGFOks1r9ng33LwCrbod2143Yx8/HkqD\nFJ4ttk+xVUYgmXp6Je8z4pqOK27nvMax7MOPH5M2+STIxDZlllGXG33+nRu9LLjZeG9dPVOsz8uM\nNTKxMgw6PQpozLkki7kzjW9dhpxjLm/ayCVkbEKLWuNcvOHAE17pgpXHps72JENvdqpEG7dbYV0C\n8wYjOLwJJSGxMNk7XsDdtAb0OOG8avzDZqA7vAnrScbYJGONkUEmr1k7j4x1SdaKZRaZenqw+EP0\ng/y6mg437js1pdKETGxTh0OknmZP8tG63bjfyx8Z56pF4sueZMYamVgZHhqcRSxodCSHT+f67cr2\ndESgTCpiqHoSR9WVGKqexFD1JI6yPSkUCoVCkYGoCVmhUCgUijRATcgKhUKhUKQBakJWKBQKhSIN\nUBOyQqFQKBRpgJqQFQqFQqFIA9JmL2tZrNAomlUZgnldpCxm9GRx4jy5cSMdo5vAruPensOsQdXC\nmr2Xp3vZs8zYg7ticoyLXgkIl/eB0p4yCZ0f1pnTmiVDjBhPFi4laDMW9zt1GzMbJuEl8Qb5sXiI\nF3I+oMlrrO3ODoW4rOlEPI7E2xVaocqLEOEfnTtXdXHVvokp1y/K1LEMVpVZNvYff24g+shA0DXs\nN+3kmpsLhevKrJJQRmUo029lxgsZTB9vNMi9b6/k90XHo2saP2teyn+eOo64O/k9w4+IO2QrNIpm\nVYZgXhcpi1k92Vt7dxA4uY4Ri0cwcuEowuObmNewXSjnmsec7FnqoHpmhDGzIuz+2MG62WIT+SMj\nvIBm7Nyg6YCNf4xO7EKW5fW8NQTtUaqD5YwLDCBiizM3X0xJ+J5zIU0+D8c0+5jQ6Mbv8fCeZ4lQ\nrBWqvH8WrkDXoDSSTXk4BzT4V9EqoVgZ/aJMHctgVZllYv+1dgfR31ZRcdceBv12D7E7RvLKhh1C\nsWb7vIzK8NHqzn5r143/sPH40WL9Vma8kEHmeJ9dtIy7i47vnn+ycpvRP37ZVDmOiAnZCo2iWZUh\nmNdFymJWT+b712D0sVM5c0IJ40407vya9ojtJ7PpJUNNdvJ/h5hym2G32vCC2JVIuNUO6Fz4Wjvf\nesG4wg41pb7OJvoHc0prFaf5R3WbcTpsYlfL1UzklNYqTo6ewKBwPgCtHrEBxQpV3gltQ6huL+fS\nlglUdeoII5rYtn8y+kWZOpbBqjLLxBbOHQqazvRzixk33fiZf76YIMJsn5dRGQYbjH578RvtXPiS\n0W87asX6rcx4IYPM8bZ98Q2m/ymb47P3zwW1W8xJVo6IR9ZWaBTNqgzBvC5SFtN6sq0+HNud6K5W\n5hcaV/XZi8pgXOLQQIPx913dT7B0AvXJXTgN7N6JsX/0LQNjBQyMFRAmxry8dQBUBUuSis1adz/v\nnjga8DIoPkQo1gpV3phIBWMi0EGERTmGfrE8LDbYy+gXZepYBqvKLBPrqPXi8ELMFeOd4nXgrSRn\nl9g5Mtvn+0JlOGB817/E+21fjBdmkDnekZtc6B87eat9DTCMms1DWbduIqUkPx8dEXfIiiQwqSfT\nbfs1e/xPFYUbJQbP/nuQYZowMZ4oWkxM08mOuTi5oyqp2D+fMh6/x0tlQz1nbtsjHGuFKq+DSLd+\n0abDha3HCsfK6Bdl6lgGq8osE6vrdMeiQ3ksVzjWtJIww1WGSSOpfYx6BwJQMXw7I4a8ZqoIR8Qd\nskKMnnoyPSauJ8sq14nduxa/LcSwlhK2/uoosm8Ve8znK9Vp3gzB5i6Rt0ZWuWhr1wGNbe9AoMGI\npR8MOQBPFS0hqsUpjmRzWfME4ThnywaeHLybiM1OcSSbaz55j6i3jGDZVKH4nqq8ccH+cQs/UbwY\nAFfcwXUNU5KK7alfPKutOqlYs3Usi1VlNhubVa4TC0IsBMWhXPYF7WQPFHutINPnzcQZGP1250II\nNEIy/VZuvDCPzPEOqVqCc4rGa9oYQCfYkUXl0JXonJ10OY6ICXlPOMYHLRyiJPxWYereNzZF43ze\nziEqw0k5iR86BOI6e8IcoIsscuhUulN7KTh4WpTl97jZMsdBvLM/i+jJ2mduQzt2F/kryxiwdBRb\ns6JUnBVE5AHL6CuMDzOW3OUm3vkER1TF5imJE6x38Gan0gzAOyD1j/nfzllP2BYjJ+rmrOZqWgjg\nwi70VetH2Vtpd2VREITza7PpoINwVplQ3i5V3gnt+1V5NrSUfmX9bP4K4/ubuMb5DWPZSwtenEJf\nWXfrF8P79YsObEJfLMvUsQxWlVkmdu8FW+CeMXieq2REy2D2AeXfDIDAZ6xm+7zZOICsgXHaaxy8\nPiOr+64ze6hYv5UZL2SQOV7f2DU0HaNT2zwcXG42ZuUx13UU55koxxFhe7JCoyijMuxNF5lqk4oZ\nPZmsZm/OZV6+XGgHDYacGeX8p8X9sw+UZrH/mdX+5ROprKdHihYRsR14bp1xm5DM/pGij4jYDmyL\nzrjG9xsS3yGnStGXjvpFmTqWwaymEmTbhVxs+O6hcP9Q41z9xzZcP90uXFdmlYSHixPpe4frtyLI\njBcymK2nW7d28GjDwRdHOnUneJR+MdNRajMxVD2Jo+pKDFVPYqh6EkfpFxUKhUKhyEDUhKxQKBQK\nRRqgJmSFQqFQKNIANSErFAqFQpEGqAlZoVAoFIo0IK3WIcsYm8yal27YHOblJuND8/Py4PFRqVsq\n1ZMZ60O81/mh4pQseGVM/+Q1Y1LR0XnkxgCRD429mZ1nNfK9+3wpXR8rS5AgjxUvO+Bnl+w7hjLy\nE8ZmosUoSpRHu3ZywlhwcvW+SWTj6TVOxjAlE5uJticZZI43SpSHOz5BrzSW/2j7nMzSxic8t8Sj\nZG9/EXfTKtB1IrmjaBt+FbpDTPQgY3vqM1OUpvPD2tSbovR4hA/q3mHHSAdxTaNyV4gzsk7D5shK\nHCxZzz1JmxFVxthk1rx0x85I92Tcn9yyNdw9GfcnZk0qrz/mJ/JSGYWnBSj6RoDI0wN449nWfiix\neR4vWgYaeOJ2vDEHaPBy0edCsZloMXqh4FNiNp3B4QKGhQrRNXi58LOEcTKGKZnYTLQ9ySBzvE81\nroUhQbJfH0jOy4OhNMLz7esSxnlrF+LZt4SW0TfROvI63E2f4a1dKJRTxn4kE/v0ZMMUZffo2D06\n6DaemZp6U9QXuxfxxf9v77zjrKrOhf3sU+ec6X1kcGDoQ1FAijQLloh+RsWGIMTEGEu412s+jV6N\n0TRbignJ57VEjaJG7HCTGFEwFoShqTCUgRnaCNN7O3Xv7489MwwEOWvOmmGfkfX8Bec372+t/e61\n9tr1fcbFc9qqQUx+fwC7hyWyrUbM0iaT56OJmQVZxtgUrXlpiBt+kKWReYLvEwyLg2vSQKCoV68S\nrUml9ukMwOCyX9g575fmGX7Fqghn5xYzrnUA2b5Evls3g8F+U9BgCA6t/mgxmtI8iIktp3JJ0zjy\nO6xNfi1yYQMZw5RMbH+0Pckgs73uh0ZiXDqReeOGMn6aOe/8gcgXEu2nzKZmyu8JJQxC77jS050J\nEaJMZOxHMrGNpaYpau77rcz9u3llXF/c96ao+nfOxhgzi9PGjyB/tJmrqlaxY5xMno8mZm5Zyxib\nojUvLcw2d9bbdX0/IbvzwwHmbaqhm05su9GaVELV5jBxpxl8lFQCnlSMrYlA35e0i5YZvmHggwZ8\n7PBWAeANi90O7Y8Wo6GhLIaGwEeI1Um7AMjzRzZFyRimZGL7o+1JBqnt/SwNSmzozzXwaYa5bx1v\nDoDvi4Unb1+Cs3kP7Vkz8WWK1SqXsR/1hikqs6s43YkxRQX3xuHY5ySl5CGWj8wCBuB/fwL0wHcS\nTZ6PJmaukBUW0YN50mkhIqhhq+nbZ329QQM+/pph3rrGgO/Unykc2x8tRj5C/CXjM9DMsowXtowW\nipMxTMnE9kfbkwxS2+s6vG+NT1KJf148tmnYDTQPW0Rc1WfEVX0q3qak/Sjq2N6kB8c3w6bz1uRz\nKM4ZwMziHYzVxR5xdRJ1nruhFuSTCG+WOTN8DdBWDaImFXeyARqUGLVMKh0OIRvuVCtnmRh/7Xyp\nSxerzdyd7kagyxvH9yi2u9VnYZ34SYAsL2SsxQDiw+4e1YTubpia0ja4R23KxFqVJ5l9K0O02+vN\nMuCLNeiAt80NZ00XmrfOxmLc1YUYriT86RPR3am4GrYJtdndfhRs7Zn9SCaWjpcSKzbD/g8BtK7f\nIhHt8Q0gb9QOUl5dRamngem1w5jwSRWn5ostyDJ5PpqYWZDLA2FerQ7/m7FJhPqQzkeN+r+ZlyKx\noy3Izw4Eae34053t8PjBvr8N+0VLgDv2BPB1jJVSPzy4v++fn42cFwQ01v3SzbpfmG91i5hUsm+v\nAUMj4e7TOLBoEACjFvZ9f2X4c9qnXVfGF9SOpIRKKmgQiu0yAgUPG4ECiJlfuqw+4cNWn/YoROU9\n5Z3kL9E1A5du5+K6MdTQQguRi/J3GqYmtR02TIUFVXkysVblSWbfyiCzvW1PbEYraMW+z0vmnZMg\ny0f+DZHfCnU2l5K491UczaU4WvZhCzQQ9uQItZl3fggMjdIVDkqWm4+sRO1HMrHpY3VAY/nl8by7\nyHwemzlB3BQVzfENwHZBCXWXBBm5OZnkt4PEZTViZItZ2mTyfDQxI5eQMTZFa176P9v9rD/GG/V9\naYkCOGurn53HOFZWTe5721M0JpXVicXs/F3CEbaZUYtbpS1EMkTK08lmMXoy4xOMo64kNANuqTnr\nuLmSMUzJxPZH25MMMtt7vH17XMIBEva/jru+CAydQHIBLfnXCn+OI2N7itacBPBETjzo5uTVbAa3\nVvS9KWp1/A6KvdVH/DayLZ3ZrWMiBx8nz8r21M9RJhUxVJ7EUbkSQ+VJDJUncZTtSaFQKBSKfoha\nkBUKhUKhiAHUgqxQKBQKRQwQVWGQwsJCbr/9doYPHw7AiBEjuP/++3u1YwqFQqFQnExEXalrypQp\nLFmypDf7olAoFArFSYu6Za1QKBQKRQwQ1WdPhYWF/OxnPyMvL4/GxkYWL17MjBkzpDvzRVOI679o\nZltLmA3Tk5mUIq5ffLSklf/e1Y4BPDgsjgdGiBX3lmlTBqvajYYwYR5nFW0dtatd2Lmd2ULqOAOD\nlWxnK4fQMRhBFpdymrC68WfdvyXW4AHBcuU+fDzGqiN++wEzyBHUL/6ZT6nA/LQjFQ83c5awftGK\nXEUb68fPo3xwxG+3MotMkiK2KYNMjq2KlcHA4PGz2mhe4wUD4s9u4Y4P4yPvWz2EUbSU9x/OYst7\nMwlhh3n13PVErvAcenSgQftB89/ePIMf7xcYT3qQlbXvsDXJjm7TGNEY4NLkS7ALSBN0PcArW96k\nfJQbQ9PI2d/GvPxLcTkjjykdnV9dVYX+cSoAtm/VcPfSbKH9Y+hBvir6ExnlO9EwqE0fRM7ptwv1\nmZAPPvk5tJab/3enwoz7wJseOZQQj/E+oY6iODY0/ovZkfWYxyCqUTh48GAWL17MnDlzKCsrY9Gi\nRaxcuRKX6+sPOpG+W9vjM7hwe4Dx8eYRuL6hjeqg2IB7tTrMPftCOIAQ0NoWEPpOTqZNGY7Xbix+\n47c8+UvaXEEK2nOwGxpF3nL+ElzLVQ0TI8YWuyspTNrHpQ3jsKGxPGULKc0exvgi1w9+YbwHcKA5\nzYFuBG38blCIhRvbI+bpyfSPwQZxYTuaodHuCPGMvoZbaiMXBvlXwi4qPM2c2ZKP3dBYk7iHN3yb\nuaC5IGKsVbk6XuzxcvV0+idgg/iQE5uh0ewM8JT+KTfXzorYpgwyOe6r2L6ce6teaqf5kyzyvtOM\npsH+vyTy2h/LOX/e8RcLT/lqav9ZwdpXv4v/7u1cG/iUdx7/Aa/NOMD5F6ZGbPcfP3HhO+imfnyA\nBh2GbHGx4nYf035y/EIde9s/pDDPy2XlWdjDId4aWEdW2fsMjzs/Yp7Wlq5kz5lJDH0+HSchdn63\nkXc3/5Ppp86J2N9lL9agv5lP4jW1aAY0vZTLk2eWcN01katmtVQvJ69sKyWn3YQ9HGBY0V/YG/ca\nCdlXR4xNKn4KV2s5zUMWYAu2klD2DoGNT9NYsDhi7F9TNxBy6OT5U7EbGnvj6ng6/CkL66aemO+Q\ns7Ozufjii9E0jby8PDIyMqisrIwceBzi7fDeaCdXpffciBytulGmTRmsajdaZNRxMoq+1kMdKrb3\nWrlihVmtp/mAWM76o37RChXi+JaBDGxPYVH9NPL95tWALlg7WAaZHFsVK0PDa6mAwYUPwLQONeCh\n1yIfrNtPmc3b796BgcHoy2HMrA1m7HtiV1+Vf3cCBvlPtPH6PabDfPdbke/WZHtncG3dGQxwjCLJ\nMPvZFCdWwfCrhy/AGD2Lc84Zw9iZXgBqWrxCse3/kwsYXPVzF7N+Zeap8X2xRc2WNYeSaQ+RFjcW\nj808WWl2i0lwmkbeTM3UJfgzpxJ2mbG6wBU9RK8+PRZRXSGvWLGC6upqbrzxRqqrq6mtrSVbsO7n\n15Ht1Mh2amxoEatb2p1o1Y0ybcpgVbvRIqOOk1H0dZI9tvNf4gtFf9QvWqFCnOLPBz804WdLvHm7\nLinU965rmRxbFSuDv8a89nEkGKxPKgHSodINAvXGta+cOJ1B5tf8llUDRoInDNsTQaAGd7jjQtae\nAu3JAAaBpsj97RxPiduXsLpDRzjAMU6kSYLb46HERvqBh/h0ZCaQS+0LE+GRyLGdqldnms6/0orA\nk422NQmRhjv7nLx9CY6WUjYMGoI7/WzowWE2feOP0cI+Qp4cmodcLxQTrfr0WES1IM+ePZs777yT\nVatWEQwGefDBB497u1rR/5FRx8ko+mToj/pFK1SITfh5OaOwK08LGiLX7O4NZHJsVawsXQpTwNGD\nG5ShkJMVo2bz7eJVrA0ZOJpcCK2OEugYvDX5HEq8DczatYP8gIYvW/BRhl3nqWln0OgKM7N4B4Td\nwFThtjv3D0ENe40b0W3VMfjb+BnorenM/Xw9rdpW8T4D9QW346leh6fyIxJLX6R5+A1CcdGqT48m\nqgU5ISGBJ598MqoGFf2T7uq4qwWeh3anu6JvrMDz0MMYgMbBdeCrB3PFEHyri6P0iwLPjrvTXdF3\noaI7ck0AACAASURBVMCzye5Yk6voY1/OKARA0zVu6eNnx92RybFVsdHizTJoKIHd7fWceWgE6wTV\ngM7GYnKGpNNQOpgvc9MYX5SBEXQQnyO2QLmTDQJNGuFqSK4A0HCnRp5DzsZiVqdXU+rRmdU8jLP2\nf0jIYwgtbsMmb2fv78upc4YZXJfJhE8+onnCFkQWZHeyQaBZozkQZFBVDvtDNtypYpe4zsZidmk7\n2TYklZm2czFcJbgatgn12XPoA+y+KlqGzKc1/ko8lZ/gbNol1C4cqT5dVCd+4nE0MfPZU7tusMdn\nUN2hUDwUMCjzi92ijFbdKNOmDFa1Gy0y6jgZRV/yUFPFtuLKeFbeaKrYUkaJTc7+qF+0QoX4fNpn\nXXm6qHYU+6imGoF7mpLI5NiqWBkyrm8ANDLvnEzdfXkAjFoQ+dm1s7mUGd96CQwN76MDqf7QPIFI\nX9Au1O6Qq00lYf3/jWfub8xnornXRh6PZdo+ilJ1ptQnMrrWRyjcjN8rphT03LqNukuCZH0WR8ZD\nXlNleIrYY4GEOw6BoeH67zG0zzefVY1cKGZsamsr4oydq7ngkJ2xNT5sgQZCHrFHqa6GbcRVr8Nd\n+THuqrWAju4Wu+0crfr0WMSM7WlNk84VxUc+CD/VBZtOj/wiQbTqRpk2ZTheu7H4lrWMOk5G0Qfw\nRHb84bexNIPbKs2Xu76J+sW+UiEeL1cyeZJBJsd9FduXc291YjE7vz0IVpkv/TCnilFvlEXet+EA\n1WV/puKJkWxefi5hm43QXfvZsbCVx52Rb4uuadJZPSuetHLzPZvqgWH+9/mGiMe44+kII+XplZR1\nNDqPXPRTgk6ua5gWsb8vp66n8bHcI1SvyXccEtq3H3mLGFqykpEVh9AwKM3MZteIi5jVflrEWAIt\npO54HLvP3GbdlUrD6NuFFuVI6tOeEDMLssIkFhfkWETlSRyVKzFUnsRQeRJH6RcVCoVCoeiHqAVZ\noVAoFIoYQC3ICoVCoVDEAGpBVigUCoUiBlALskKhUCgUMUDfKk56yJJDIX51MIwB3DXAxl25fW9A\n2tqm88M9IXa2G6wc7WR8vPg5ikyszLauf8TFtqVOMGDsd4NMvqtnJUNPJAYGa+L3sDuuCgODQYE0\nzmkeIWyqsaJdmdgQIZ7rqNIF5pcb19dMETK/BAnybEeBgU7m10wimch1gHV03kj5nFqH+VlYkh7H\n1XUTI1pyZPqr6wHeTviYKq85dlN8Qa5qmIrTEfnN0mj7C6bJ6/nOoi8dzK05jWxBk1e07crEyvL2\npR7K15ufLg2YFubyd8S+Q4YTf7yQGccttLA0Y/MRv11cM4pB9G15U5l9KzOHjiZmrpBfrQ7zy4Nh\nTqRuYY/P4IqdQbKiWPdlYmW2tbzQzsbfuZn2Uz/TH/Sz4dduKjbGzG78N3a5q9jqPcgFTaO4qGk0\nu+Kq2BlXEdPtysS+nvo5YZtBXiCVfH8ahgZvp30pFPtK2kYMDbKCCeQEEkGDN9O/EIr9OKGEWmcr\nZ7bmM6NlCE12Hx8l7u7T/n5m/4yqeBfT6lKZVZ1Eg8fFp+4NfdpfgL+km+VQ43Q7nrADNHg7fUuf\ntysTK0PR807KCx0ULAgyemGQQ5852P6S2EmAFccLmXG8NH0zaKDpYAsDGvwjfWef9hfk9q3MHDqa\nmDmSR2tskkHGumSFnQqg7EM7aAbDrwgx7DKzwtCB1TF1o+MIZAxGVrUrEytjfpncPIiC1hyubJzI\n0I7YoCZWRSpai5FMfwu0SVzUMJrx+mnkhMwqUE1usbEoZWyyyORllSlq91sOwGDGz/1M7zBFFb8u\ndiVgxfFCZhzntafgDTi5pe4ssoMdasoTsCTI7FvLbU99QbTGJhlkrEtW2KkA2qo1HB6wd7g8HB6D\ntsoTdxLTU3rD9nSi25WJlTG/jA4OYHQQ2giyJnEvADkBMUFEtBYjmf52thm/fQlLp44EPAwNi4k0\nZKxLVpm8rDJFtdea89vVpU42aK8Wm/NWHC9kxvElbWZVrSpaKI9rAcAW7vvjm8y+7U3bU8xcISt6\nQLeHMyemzpocVtmerDAngZz5pY0gL2SsBQ1sBlzWdLpwbLQWI5n+htB5csZkWuI8nFpbzaQDe/q8\nv2CdyctKU9QR9GSNsuB4ITOOK2jhzYzNXfv25voTIzyR2beW2p4U1hGfYxDyQcgHRhjCPo2E3Nhe\nlWUMRla1KxMrY355IWMtAC7dwY2103sUG63FKNr+OhuLefXUSlrspvN53uYPCXmyhXV3MtYlq0xe\nVpqifA2gBwFBUxRYd7yQGcdvd77UFcW+lUFm337jbE/RGptkkLEuWWGnAsg7PwSGRukKByXLzfOp\nQRf0va0mWmQMRla1KxMrY355NWUjaGA3NC6pHUMFjTTSJhQbrcVIpr8b4g9Q74bcdhdnVzppo43W\neDEjkIx1ySqTl1WmqJHzTGPTul+6WfcLUwpRsEDsGaUVxwuZcfw/aR937duptYPYzH5K6fuXQGX2\n7TfS9hStsUkGGdtTX9mpRAq3b/q9iy3PONE0OP3WABN+GN0LBCcCWdvT1xEpT31lTorE8cwvkegr\nQ9XxciXT35dTC2lyHPniS1LIzYL6yFcIMsYmK/Ik22dZVlzt4auP7aDBoPNCXPKy+AG/t48XfWla\n64/2MWV7+gajTCpiqDyJo3IlhsqTGCpP4ijbk0KhUCgU/RC1ICsUCoVCEQOoBVmhUCgUihhALcgK\nhUKhUMQAakFWKBQKhSIGUAuyQqFQKBQxQExV6rp4m5+NHd+PnxYHH4wT/wb53n1B/tzxbe/CDI3f\n5ovVtrVKv9ifFIoAT+Qk0FkbQ7Mb3FreKhz75MAE9I7Ns7sNbi4Tj30iK+HwfzSD2yrFY1/9k51f\n5fqpHBjm95u8zL9FrPjKyaSMDBDg2Yx1R/x2bc1E0kj4mojD6HqAmvKnyK/cj2YYfJV+CvEDbxbS\nL8psq64H+Ej7BweS49E1jdymZs4Nni/c7ls79lFVUAkOg/TSDK4cNFSsXXRe3LWLtpH1YDdw70tk\n4cACMf2iHuLze/ey5e1hYMCEuds4/ZdDMRyeiKEyOsNo8+zHz3MZhV1tasBVNePJJClim2HCPBu3\nnnCC+b2zzW9nUfNkPEQ+JstoEDv73B3RPsvQm8eLmLlC/v7uw4txT/njoRB/rtZ7LAWxSr/Y3xSK\nr53vAV3DmWjgSjIwwjbemCPm+lx+ZRx6QMOTZeDNNgj7bfzvPLETrZeneQANe5yBPc4Aw8ZfZ0U+\ngAEUFmrcNaadU9M6qqG96BTO8cmkjFyavgE0SAnFkRb09EiVV1H/NqMOlrBl3DXsGD2X4ZUHqK5f\n3qf9BSgKrWJnVhqTGzOYUZtMaUY6W/WPhGLXf1VD1VllnL5mNBP+NZbaSeWsr6yMHAj8s2I/7TOq\nGLZ2GMM/HkFgQj3v1e4Tiq37ZxFrn5vI9PuamHFfLZ8+N43694uEYmV0htHm+flks064o9aFszLO\nbDNVTCn4JtsIJwbJ2XYKuVty0ePCvOMQ21YZDeILHVrO+LCTxJALNHgrPToNYk/ozeNFzKwCw+Ng\nTjLERSH2GOSG/861kd/Dol5W6Rf7m0KxpsgOGFz5fitz/26euVZ9LupjNdVxc99t5YoVZuzBT8XO\nYhpLzXbndmu3vlgs3w1r7Nz0o2SuH3l4iIvm+GRSRp7RfCpD2jK4rmEKQzrUcSFNrEyoO/MSNs24\nn6HOKSTZMgFojOv7HOfGzeKihtGM1iaQqacAUO8RG1OhdzIwxsxi6uQkRk81r9gqKsQqV3nfzMMY\nM4vzJmYydqp5sKkvF6urVLJlCmgGQ+YlM+xS83bRnnV5QrEyOsNo8+z5cz7G39O5oflMRrhSATBs\nYtuatmwIxg8L+HbqcMadYu6fVkEdoYwGcXzLQAa2p7Cofhr5/nQAdK3v61715vEiZlaBu081B3je\nxp5vyLfTzc1YVtOzWKv0i/1Nodh5qzptSOcPBqLlqPWOeZh86uFYvYeV+zK7KlaKTy73QTs59XZs\nHSPcEYdwjk8mZeT4QB4EoIUAGxPKAEgPxgu12amsS9r+B9Jb9rBh0BDC6bNA4OmLzLZ2tpu4fQmr\nR2YCuWQ7xoLAVAzujcOxz4nmauazJLNd99pMEJER7fHi2OfEcDWxMs284ktYkw1jI4d2zvm0kiU4\nm/fgcD9FU3MeEPmYJaMzjDbPzsdHQIkNX1Ut21PLAdBKPZASuU3H+nQcbzoJP9jI+xnbgY48CVQY\nldEgTvHngx+a8LMl3uxzUkjsTp4MvXm8iJkF+aSjnykUe5UTde4hkeOTSRnZQoClGeu6ivpf03iG\ncJshdJ6ffDoZDRnM/Xw9rdoefNm5fdrfznafmnYGja4wM3fvYJJfE27XsOld7fLQMLy7UxBZGDtj\nOxV9PDSUtF2ZwrEY0DTsBlzNJWDo2H0VQKpQqIzOMOo8ZzbzckYhaGDokHzJ2bBG7LliOC7AC+lr\nCWsGHIgjZ9lImCKWJxkNYhP+rj5jwIKGvq8zDr13vIiZW9YnE92VaMHW2Fcoanazb9VFcHAtgNb1\nWyTsLvPv6nZD5edmrN0puK0dt5sqNsP+D81YBG9BdeY43HE1HvbToxx31y9OaRssHCeLTLvRxi7t\neKnLrtt6VMTf2VhMUetrVHls+NMmYrjScDVs6/P+OhuLede9ikZnmKG+TM7eVyHcbnyOQfh32yh1\nVzO9dhjGfSOFx0VnbIvNT35jJsZ9o4RjE1OrzfmuJ9ESN5FQwEVKyn6hWDhSZ3hzD0UL0eTZm2VA\n5ScAaLoG9kt6pHw0Sv5FSNNJ9yVgDDqvR3Ovuwbx8sbxwnGAuRh39LmvhRTd6a3jRcwsyIVNfr6/\n20+gY7/tD8D/3SN2RrXXF+KPh0I0dtyy2tZm8JfKyM9YrNIv9jeFYvaUMKCx/PJ4/r7AvJ05YKbY\nrfqB54YAjRVzD8cOukhsW9PH6l3tvrvIjM2cINZu1nlBanN0ireYl+NNGTrO88XeZD+ZlJFLUwu7\nznMurh3NV9RRR4tQm9W+zczetpYJVe3MLndgCzQQ8IjdXpTZ1mL7Lr5KcjO0WePcCiehcDM+b7ZQ\nrGteJdpNZQxen49t2QCIDzHwQrFx0bpgL9pNZaRszuaUl0dBfIgBF4pZl4ZN3g6Gxt7X6tizrBGA\n/HMahWJldIbR5rl65So0DdAh55FxcGEFubfWCrVZ+V9b0FJDxDXFMfSVsTC4hayL+lYjCvB82mdd\nV8YX1Y5iH9VU0yQUK0NvHi9ixvZ0xhd+yo7xbFFEv/idXQHebfz3zYgUa5V+Eb5eiRarJpX/GRCP\nETIXN5vT4JaD4p8fPZUXT9hnxjq8Bj/Y14PPnnLiQTdjNZvBrRVmbKQ8yeyfvlJG9mW7x4s9Xq5k\ndHfLkj5jxs51jKw4hIZBaWY2H4+eztXNM6X6G4lXUtbR6DxyEU0JOrmuYZpUu32qXwwH2PqzEjYv\nK0DDYNL8rYy5b4TQZ08y+yjaPB+vzUh5+nP6GoK2I0+cnbqN79dGHhdWaTlliDSmekLMLMgKk1hd\nkGMNlSdxVK7EUHkSQ+VJHKVfVCgUCoWiH6IWZIVCoVAoYgC1ICsUCoVCEQOoBVmhUCgUihhALcgK\nhUKhUMQAMVWpS8ae9HZtmP/YGyJgwJ/y7VyTIbZpMtalty/1UL7erK08YFqYy99pF46VaVfGvBSt\nPUnG2CSTp2hjrTAngZyZxwrTTVj3s9r2Nw4mJWFoGjlNTZwbPI84R+RKQ4YeZOkHJbRe0IjhMIhf\nk8DCSUOwOcRKb744IZ6Wg+Z3Komn6izcJPatqhFqZ1PwHbZlp6NrNoZX1zDDOB/NnRE5WA+RsO8N\n3PVfgGEQTBpB85D5Qp8fGaF2/rH/Q6onONE1jaxd7VySMk2s3ZAPz8e/Jd5rfh7jC6TQNvW/0N2R\nSyzKjItosWr+yNi4woR5Ma0Qn838btlp2FhQO0XIMiXDN9L2JGNP+qhR5+Y9Ibw93BoZ61LR807K\nCx0ULAgyemGQQ5852P6SqHAh+nZlzEvR2pNkjE0yeZKJtcKcBHJmHitMNxvD71GSmcno5gQm1Mex\nLyODTXwo1OZHn+ykdUE1ec8MJf9PQ2m7tJ6PNuwSil3zgIuWgzZOmR5mwIwwzWV21v5SbPKXNb3D\nhrxcLqpI5NIDNrbmDmBv+0qhWE/lx8TVrKNx5K00Db8Rd/2XeCo/For9ZPO/OHBmAts/GMC6TRmU\njU1m47a1QrGuTS8S761kV81C9tbPxeNuwPXFX4ViZcZFtFg1f2RsXH9LLsJnD1Hgy2Fs+ykEbTp/\nTxGzTMnwjbQ9ydiTMpywbISDS1J7tjky1qXdb5kWoxk/9zP9p2ZFseLXBQ8oEu3KmJeitSfJGJtk\n8iQTa4U5CeTMPFaYbgbGzWJm01CmGNPIDptxDXFiOa557nSM0bO4YH4mM642+/lVtZh7tnSFEzC4\n6Ll2vvW0eddj91tiVzIZ6Vdybd0ZZHunkWSYeWryRPY3A7SfMpuaKb8nlDAIveNKXneKxW555BLq\nzpnB2KxRHGo1Y8tbxWpRf/rhYn5+2XMkXziZ1Almnxsrxeody4yLaLFq/sjYuCa15DGzaSjntIzo\nkju02freM/+NtD3J2JPGeG2MAVbU9axcmYx1qb3W/DtX11w2aK8Wi5WyPUmYlzrpqT1JxtgkkyeZ\nWCvMSSBn5rHCdJMbTiU3nErC9j+wY2QWkEuKcyQi1QoDu+OgxEb6gYdYPjILGICxciB8WyC2o66E\npyutBgHBKoed+yd14495c8IEIJds71lCtqdOkreb1qX2rJn4MqcLxcRt8WBr8jKv6k5yzxjFLgZQ\n8eRkmBU5tnPOZ235MVrYR9WBAaxd913O+XbkiSQzLqLFqvkjY+PqHMsBwryXbFqmhvoyhdqVQdme\nepPetC71xGLU321PMsamExRrhTkJ5Mw8VphuAoRZMmM8fofGzN07mOzX8GUPE2vUrvPW5HMo8TZg\n/HwYrg09lJJHiY7Ba2fNoyS+hVm7tjOiZg/Nw28Qju+0LiWWvEjIewq+bIFVFcCu88r0b9Oe2sLM\n4h0EE1zAmWKxBtQX3I6neh2ZxkdMMZ4DFgqFyoyLaLFq/sjYuAKEuyxTCWEXM9qGCrcrg7I99QIy\n1iVvlvl3vgZoqwbQemRDibZdGfNStPYkGWOTTJ5kYsEacxLImXlOtOnG2VjM/8atxG/XyAgm9Myc\nlN4KT2yj1NPA1PJh8MBIEtPEBATuZHM/tlRC434ADXeq2L71HPqAtca7lHpbmNU8jHN27cTZJPbs\n2tlYjLu6EMOVhD99Iro7VXh7h03aQvryVbSntPC3osGMW1fJiMmfC8WOnfQec77/PAF7Lg2ZV6KH\nbeScskMoFuTGRbRYMX9kbFwAS9PXEdJ0MoIJLKwTPFHqBXrL9hQzV8jtukF5gCPsSekOg1PdkS+J\n6kM6W1qhoiO2uN1gfbPOlMTjn2/knR9iw6/dlK5woHfcohO1Lo2cZ75ktO6X7q63jwsWiN3HlWk3\ne0qYirVOll8ej95xq1rUvJQ+Vqd2q4Pll8d3XZWL2JMGnhti/z9drJgbj97x56LGJpk8ycR2Glgm\ntx42sNjQhN58lIntMvPoh808HpxCb1l3mW4Ch003DmxCb9N2mW70w6abeNwR37L+0rGNqsQMclqC\nXFQTTyjcTJt3XMT2AHL+80sOzW8i4/Vc6penQXyIgqv2A+kRY0dcE2TTb+P44BZP1+MP0X1bZitj\nS9ZQzqyEcXX7CNg19LjIbQI4m0vxHnqfcFwGaHZsgQbCaWJ3MDIWf8mOSzIIfZiAw99OfHoTFe15\niDyBzhuyBW9+CaWrBxAOOzglUyfsFLutKTMuosWq+eOaV4k2sYzBhfnYNvXMxvV+4k4CtjCJITcX\nNhTQSDsu7H3+lrXM9h5NzMglZOw8T1WEuL/syIXFDpQLmKK+zrokwoqrPXz1sR00GHReiEteFlOx\nHa9dkcLtMualr7MnRULG2CSTp6+LjZSnvjInRULGONNXppvj5erZtE8IHHWHxR2G79UJmITid1Ds\nrT7it5Ft6cxuHRMxFuClKV6a9pkHrZThOvPXiH32tNpbRHF83RG/jWpN4dy20yIHhwMk7H8dd30R\nGDqB5AJa8q/FcHgijqllriLqko9sd++hFB5zCrQbaMH72e/xuqtAA18glbaptwt99iRlmYoSGSuW\nVXNPxjIlg7I9fYNRJhUxVJ7EUbkSQ+VJDJUncZTtSaFQKBSKfohakBUKhUKhiAHUgqxQKBQKRQyg\nFmSFQqFQKGIAtSArFAqFQhEDqAVZoVAoFIoYIGYKg0SrBYTDij4D2Dc2yIIV7cLqxmgVcN3bhROn\nFQQ5deMzQxMIdnyx4Eoy+H6JWJ6t0kX2N/2iDAECPJux7ojfrq2ZSJpA6YloFX0y2yqlBdRD/Ova\nfez7YigYMGzqDma9kC+kQSTkI3Xbb7H7zG8/dWcyDWPuEPqml6ZDZOx45IifGvKvJ5Ql8E2vTLsW\nYcVYtmruWaGphN7VPsbEFXK0WkA4rOj78iIfhy71kb/VReWrYrYaGQWcVVpBGXXjyh+4CTZrJA/T\nSRmuE2iy8cEPIw8aq3SR/VG/KMPS9A2gQUoojrSg54SoG2W2VUYLuPvx7Wz/aAIDprSSN6ORLe9P\nZc8TYiUsk0pfwO6rpHnIAlpPvRx7sJHEPa8IxabveBSAYFwuYWcqGpC89+U+b9cqrBjLVs09KzSV\n0Lvax5i4Qu6uBSQAr5+XKKQFhMOKvh/9NsCmFoOGFR6q3nHBjZGvpLor4AjD82MS2f2Wi2k/iVyt\nq7saEB22v+ii+HUno6+PXFJSJra7uhEDVi021Y05kyJfse5fZW7vZW+1QRhenJDI3n+6gOPHyrTZ\nXRdJEF6dlSisi5TJU6cSLS0c36VC66k+LppYGc5oPpVKZwvfah3Nhri91LnKCGliKq9xbQMY5E8j\nP5hBlcO8BSLSZ5ltjbZNgLUvTQMMZv0xAUfbIXa+Czv+OZj8/4wc2zTy5q5/u2rMWtK6U0z7WDv1\nD13/Ttr6exzBekSvS2TatQorxrJVc09mPMowqSWPOkcb4/y57HfWUuQtj1r7GBMLcic91QLCYUXf\nyAwbnxPGwCAkqOiTUcBZpRWUUTeGO6rvJeQcbjcsUMXSKl1kf9QvyjA+kAcBaCHAxoQyANKD8UKx\n0Sr6ZLZVRgvYOfdyKkwNos3xFId2DQLEH2ekbzRVhiFPDs1DrheOA8goNFd+A6gd/8jx/7gX2z3R\nWDGWrZp7VmgqoXe1jzFxy7rXkdH7WdVurKsbY0UX2Q/0izK0EGBpxrouheI1jWcIx0ar6JPZVlkt\nYNOwG2getgibTSct51CPYusLbqc9+2zs7RUklr7Yo9jmUy7A0Mxa9+lf3H3C2rUCK8ayVXPPCk0l\n9J72MTYW5Ci1gHCkok+vBQ0NZ7bYJZiMAs4qraCMutHhMf+u8QDU7jTbdXgjx1qli+yv+kUZlna8\n1GXXbcIKxU6iVfTJbGu0bWbkmVKK5vokqlomEgq4OGXYfqFYz6EPSNjzCnp8Lq2DrwRswvrF1M0/\nJX39j/DnXUrtlF8DoAnespFp10qsGMtWzT0rNJXQe9rHmLhlHa0WEA4r+lY+6KauxcAGuK4MUOaP\nrG6UUcBZpRWUUTcOuTTIzpfd/P06b1fs8Csjt2uVLrI/6hdlWJpaaJ6L6nBx7Wi+og4vLqG3rKNV\n9Mlsq4wWcOJVWzlUdD7r7mwiHLABiQya2RgxDsDVsA1ncynB+IGgOQFd+E1ne7ABgJTPf46hib3A\n2RvtWoUVY9mquWeFphJ6V/sYM7anaLWAAC9eEUfTZ2bSd08K8NcHm4XVjdEq4MAarSDIKSOfHRGP\nv8HMc1yGwfe2i+VZpk0ZXWR/0y/K0FfqxuPlSmZbpbSA4QCffmcPJYUj0TSDUTOLOPPp4WKfPQVa\nSN3xOHafeZWtu1JpGC2mMqShmIzi/3fkTx2fPUWcezLtWkRfjOVYnXtWaCrh+NpHpV/s5yi1mRgq\nT+KoXImh8iSGypM4Sr+oUCgUCkU/RC3ICoVCoVDEAFE/7X7ooYf48ssv0TSNe++9l9NOO603+6VQ\nKBQKxUlFVAvy+vXr2b9/P8uWLaO0tJR7772XZcuW9XbfFAqFQqE4aYjqlvXatWs5//zzARg6dCiN\njY20tLT0ascUCoVCoTiZiGpBrqmpITU1tev/aWlpVFdX91qnFAqFQqE42eiVL6ZFvpzq6evfJzMq\nV2KoPImjciWGypMYKk99Q1RXyFlZWdTU1HT9v6qqiszM6IppKxQKhUKhiHJBnjFjBu+99x4A27Zt\nIysri4SEyOX9FAqFQqFQHJuobllPnDiRMWPGMG/ePDRN44EHHujtfikUCoVCcVJxwkpnKhQKhUKh\n+HpUpS6FQqFQKGIAtSArFAqFQhED9LkPWZXYjExhYSG33347w4cPB2DEiBHcf//9Fvcqtti1axe3\n3XYbN9xwA9dffz3l5eX8+Mc/JhwOk5mZya9//Wtcrp77R7+JHJ2re+65h23btpGSkgLAjTfeyDnn\nnGNtJ2OAxx57jE2bNhEKhbj55psZN26cGlPH4Og8rV69Wo2nY9De3s4999xDbW0tfr+f2267jVGj\nRvVoTPXpgqxKbIozZcoUlixZYnU3YpK2tjZ+8YtfMG3atK7flixZwvz585kzZw6/+93veOONN5g/\nf76FvYwNjpUrgB/96Eece+65FvUq9li3bh27d+9m2bJl1NfXc8UVVzBt2jQ1po7iWHk688wz1Xg6\nBh9++CFjx47lpptu4uDBg3zve99j4sSJPRpTfXrLWpXYVPQGLpeLZ555hqysrK7fCgsLOe+88wA4\n99xzWbt2rVXdiymOlSvFvzN58mT+8Ic/AJCUlER7e7saU8fgWHkKh8MW9yo2ufjii7npppsAeS/P\nfAAAAtVJREFUKC8vJzs7u8djqk8XZFViU5ySkhJuueUWrrvuOtasWWN1d2IKh8NBXFzcEb+1t7d3\n3fpJT09X46qDY+UK4KWXXmLRokXccccd1NXVWdCz2MJut+P1egF44403OOuss9SYOgbHypPdblfj\n6TjMmzePO++8k3vvvbfHY6rPnyF3R31hdWwGDx7M4sWLmTNnDmVlZSxatIiVK1eq51eCqHF1fC67\n7DJSUlIoKCjg6aef5k9/+hM//elPre5WTPDBBx/wxhtv8Nxzz3HhhRd2/a7G1JF0z1NRUZEaT8fh\n1VdfZceOHdx1111HjCORMdWnV8iqxKYY2dnZXHzxxWiaRl5eHhkZGVRWVlrdrZjG6/Xi8/kAqKys\nVLdoj8O0adMoKCgAYPbs2ezatcviHsUGn3zyCU8++STPPPMMiYmJakx9DUfnSY2nY1NUVER5eTkA\nBQUFhMNh4uPjezSm+nRBViU2xVixYgXPPvssANXV1dTW1pKdnW1xr2Kb6dOnd42tlStXMmvWLIt7\nFLv8x3/8B2VlZYD57L3zbf6TmebmZh577DGeeuqprreF1Zj6d46VJzWejs3GjRt57rnnAPNxbVtb\nW4/HVJ9X6vrNb37Dxo0bu0psjho1qi+b65e0tLRw55130tTURDAYZPHixZx99tlWdytmKCoq4tFH\nH+XgwYM4HA6ys7P5zW9+wz333IPf72fAgAE8/PDDOJ1Oq7tqOcfK1fXXX8/TTz+Nx+PB6/Xy8MMP\nk56ebnVXLWXZsmX88Y9/JD8/v+u3Rx55hJ/85CdqTHXjWHmaO3cuL730khpPR+Hz+bjvvvsoLy/H\n5/OxePFixo4dy9133y08plTpTIVCoVAoYgBVqUuhUCgUihhALcgKhUKhUMQAakFWKBQKhSIGUAuy\nQqFQKBQxgFqQFQqFQqGIAdSCrFAoFApFDKAWZIVCoVAoYgC1ICsUCoVCEQP8f48kcbB4wEhlAAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}